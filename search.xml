<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[分布式消息队列 Kafka]]></title>
    <url>%2F2019%2F09%2F25%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Kafka%2F</url>
    <content type="text"><![CDATA[概述 下载 架构及核心概念 部署及使用 容错性测试 API 编程 Flume &amp; Kafka 整合 踩坑 概述官网 将数据流变成一个消息系统 高效处理数据流（近乎实时处理） 安全，多副本存储于分布式系统中 消息中间件：生产者和消费者 下载官网 建议 0.8.0 到 0.10.1 0.8.0 —— 看老师使用过 0.9.0 —— 实验环境运行成功 0.10.1 —— 学习环境运行成功 配置环境变量就可以开始运行 架构及核心概念基础组件 producer：生产者 —— 生产馒头 consumer：消费者 —— 吃馒头 broker：篮子 topic：主题，相当于馒头的标签，标志消费者吃那个标签下的馒头 基本架构 Kafka is run as a cluster on one or more servers that can span multiple datacenters. （Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行） The Kafka cluster stores streams of records in categories called topics. （Kafka群集将记录流存储在称为主题的类别中） Each record consists of a key, a value, and a timestamp. （每个记录由一个键，一个值和一个时间戳组成） 四个核心 API Producer API 发布消息到 1 和或多个 topic Consumer API 订阅一个或多个 topic，并处理产生的消息 Stream API 充当一个流处理器，从 1 个或多个 topic 消费输出流，产生一个输出流到 1 个或多个输出 topic，有效将输入流转换到输出流 Connector API 允许侯建或运行可重复使用的生产者或消费者，将 topic 连接到现有的应用程序或数据系统。 主题和日志Topic 是发布的消息或者种子的名字。对于每个 Topic，Kafka 集群维护这一个分区的 log 每个分区都是一个有序不可变的队列，且可以持续添加（只是局部有序，全局无序，如果要全局有序就只能有一个分区） 分区中以唯一的偏移量标记每个消息 消费者持有和操作的都是偏移值，好处是不会影响到其他消费者，也更加自由灵活读取消息 分区设计目的 处理更多消息，不受单台服务器的限制 分区可以作为并行处理单元 分布式Log 的分区被分布式到集群中的多个服务器上，每个服务器处理它分到的分区。根据配置每个分区，还可以复制到其他服务器作为备份容错（下面有测试） 每个分区有一个 leader，0 个或多个 follower，Leader 处理此分区的读写请求，follower 被动复制数据，如果 leader 宕机，follower 被推举为新 leader（下面测试有体现） 一个 leader 也有可能是其他分区的 follower，目的是为了负载均衡 生产者向某个 Topic 发布消息，也负责选择发布到 Topic 上的哪个分区 选择算法：轮流选择，权重选择等（由开发者决定） 消费者消费模型有两种：队列和发布-订阅 队列：一组消费者从服务器读取消息，一条消息只有其中一个消费者处理 发布-订阅：消息被广播给所有消费者，接收到消息的消费者都可以处理此消息 消费者组Kafka 为消费者模型提供的单一消费者凑相关模型 所有消费者在一个组中就是队列模型 不在一个组中就是发布-订阅模型 部署及使用 单节点单 Broker 部署及使用 123456789101112131415161718192021222324252627# 配置 $KAFKA_HOME/config/server.properties 下的文件broker.id=0listenerslog.dirs（不能是tmp，重启之后会消失）zookeeper.connect# 启动 Kafkakafka-server-start.sh config/server.properties# 创建 topickafka-topics.sh --create --zookeeper hadoop000:2181 --replication-factor 1 --partitions 1 --topic cty_topic# 查看所有 topickafka-topics.sh --list --zookeeper hadoop000:2181# 发送信息（生产馒头）kafka-console-producer.sh --broker-list hadoop000:9092 --topic cty_topic# 消费消息（吃馒头）# 写 --from-beginning（从第一个馒头开始吃）# 不写就是从新蒸好的馒头开始吃kafka-console-consumer.sh --zookeeper hadoop000:2181 --topic cty_topic --from-beginning# 查看所有 topic 的详细信息kafka-topics.sh --describe --zookeeper hadoop000:2181# 查看指定 topic 的详细信息kafka-topics.sh --describe --zookeeper hadoop000:2181 --topic cty_topic 单节点多 Broker 部署及使用 123456789101112131415161718192021222324252627282930313233343536# 这是官网复制的# 在同一台主机上部署多 Broker（按需求改）config/server-1.properties: broker.id=1 port=9093 log.dir=/tmp/kafka-logs-1config/server-2.properties: broker.id=2 port=9094 log.dir=/tmp/kafka-logs-2# 启动多个 Broker# daemon（守护进程）kafka-server-start.sh -daemon config/server-1.properties &amp;kafka-server-start.sh -daemon config/server-2.properties &amp;# jps（这里是启动了三个）22915 Kafka23109 Jps22981 Kafka21829 QuorumPeerMain23048 Kafka# 创建 topickafka-topics.sh --create --zookeeper hadoop000:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic-cty# 查看 topic 详细信息kafka-topics.sh --describe --zookeeper hadoop000:2181 --topic my-replicated-topic-cty# PartitionCount 分区数# ReplicationFactor 副本数# Leader 领导者# Replicas 副本顺序# Isr 存活节点Topic:my-replicated-topic-cty PartitionCount:1 ReplicationFactor:3 Configs: Topic: my-replicated-topic-cty Partition: 0 Leader: 1 Replicas: 1,3,2 Isr: 1,3,2 多节点多 Broker 部署及使用（使用方法和单节点多 Broker 一样只不过分发到其他机器上了） 容错性测试1234567891011121314151617181920212223# 先删除一个 Broker 查看是否还能继续生产馒头和吃馒头# 使用 kill -9 pid 强制关闭一个 Broker[hadoop@hadoop000 kafka_2.11-0.9.0.0]$ jps -m22915 Kafka config/server-1.properties22981 Kafka config/server-2.properties23048 Kafka config/server-3.properties...[hadoop@hadoop000 kafka_2.11-0.9.0.0]$ kull -9 22981[hadoop@hadoop000 kafka_2.11-0.9.0.0]$ jps -m22915 Kafka config/server-1.properties23048 Kafka config/server-3.properties# 查看 topic 的信息（还剩 1 和 3 存活，且能继续生产馒头和吃馒头）Topic:my-replicated-topic-cty PartitionCount:1 ReplicationFactor:3 Configs: Topic: my-replicated-topic-cty Partition: 0 Leader: 1 Replicas: 1,3,2 Isr: 1,3# 让 Leader 嗝屁（还是能继续生产馒头和吃馒头）# 注意：主节点嗝屁后，消费者会去找新的主节点，找的过程中会有报错# 就是找不到蒸馒头的人了，等新人一来就又继续吃了Topic:my-replicated-topic-cty PartitionCount:1 ReplicationFactor:3 Configs: Topic: my-replicated-topic-cty Partition: 0 Leader: 3 Replicas: 1,3,2 Isr: 3 API 编程KafkaProperties.java 123456789101112131415/** * @Author Chentyit * @Date 2019/9/25 14:54 * @Description: 设置一些参数 */public class KafkaProperties &#123; public static final String ZK = "192.168.43.169:2181"; public static final String TOPIC = "cty_topic"; public static final String BROKER_LIST = "192.168.43.169:9092"; public static final String GROUP_ID = "test_group1";&#125; KafkaProducer.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @Author Chentyit * @Date 2019/9/25 14:57 * @Description: Kafka 生产者 */public class KafkaProducer extends Thread &#123; private String topic; private Producer&lt;Integer, String&gt; producer; public KafkaProducer(String topic) &#123; this.topic = topic; // 用于保存参数 Properties properties = new Properties(); // 设置参数 properties.put("metadata.broker.list",KafkaProperties.BROKER_LIST); properties.put("serializer.class","kafka.serializer.StringEncoder"); properties.put("request.required.acks","1"); // 实例化一个生产者 producer = new Producer&lt;Integer, String&gt;(new ProducerConfig(properties)); &#125; @Override public void run() &#123; // 发送的数据 int messageNo = 1; while(true) &#123; // 构建发送的数据 String message = "message_" + messageNo; // 发送消息 producer.send(new KeyedMessage&lt;Integer, String&gt;(topic, message)); // 打印消息 System.out.println("Sent: " + message); messageNo ++ ; try&#123; Thread.sleep(2000); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; &#125;&#125; KafkaConsumer.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * @Author Chentyit * @Date 2019/9/25 15:45 * @Description: 消费者（吃馒头） */public class KafkaConsumer extends Thread &#123; private String topic; public KafkaConsumer(String topic) &#123; this.topic = topic; &#125; /** * 创建连接器 * @return */ private ConsumerConnector createConnector() &#123; // 用于保存参数 Properties properties = new Properties(); // 设置参数 // 不设置 group.id 会报错 properties.put("zookeeper.connect", KafkaProperties.ZK); properties.put("group.id", KafkaProperties.GROUP_ID); // 返回一个消费者 return Consumer.createJavaConsumerConnector(new ConsumerConfig(properties)); &#125; @Override public void run() &#123; // 获取一个消费者实例 ConsumerConnector consumer = createConnector(); // 保存 topic Map&lt;String, Integer&gt; topicCountMap = new HashMap&lt;&gt;(16); topicCountMap.put(topic, 1); // 第一个 String：topic // List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt; 对应的数据流 Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; messageStream = consumer.createMessageStreams(topicCountMap); // 获取我们每次接受到的数据 KafkaStream&lt;byte[], byte[]&gt; stream = messageStream.get(topic).get(0); // 使用迭代器获取数据 for (kafka.message.MessageAndMetadata&lt;byte[], byte[]&gt; messageAndMetadata : stream) &#123; String message = new String(messageAndMetadata.message()); System.out.println("rec:" + message); &#125; &#125;&#125; KafkaClientApp.java 12345678910111213141516/** * @Author Chentyit * @Date 2019/9/25 15:12 * @Description: */public class KafkaClientApp &#123; /** * 启动两个线程 * @param args */ public static void main(String[] args) &#123; new KafkaProducer(KafkaProperties.TOPIC).start(); new KafkaConsumer(KafkaProperties.TOPIC).start(); &#125;&#125; Flume &amp; Kafka 整合 avro-memory-kafka.conf 123456789101112131415161718avro-memory-kafka.sources = avro-sourceavro-memory-kafka.sinks = kafka-sinkavro-memory-kafka.channels = memory-channelavro-memory-kafka.sources.avro-source.type = avroavro-memory-kafka.sources.avro-source.bind = hadoop000avro-memory-kafka.sources.avro-source.port = 44444avro-memory-kafka.sinks.kafka-sink.type = org.apache.flume.sink.kafka.KafkaSinkavro-memory-kafka.sinks.kafka-sink.brokerList = hadoop000:9092avro-memory-kafka.sinks.kafka-sink.topic = cty_topicavro-memory-kafka.sinks.kafka-sink.batchSize = 5avro-memory-kafka.sinks.kafka-sink.requiredAcks = 1avro-memory-kafka.channels.memory-channel.type = memoryavro-memory-kafka.sources.avro-source.channels = memory-channelavro-memory-kafka.sinks.kafka-sink.channel = memory-channel avro-memory-logger.conf 1234567891011121314avro-memory-logger.sources = avro-sourceavro-memory-logger.sinks = logger-sinkavro-memory-logger.channels = memory-channelavro-memory-logger.sources.avro-source.type = avroavro-memory-logger.sources.avro-source.bind = hadoop000avro-memory-logger.sources.avro-source.port = 44444avro-memory-logger.sinks.logger-sink.type = loggeravro-memory-logger.channels.memory-channel.type = memoryavro-memory-logger.sources.avro-source.channels = memory-channelavro-memory-logger.sinks.logger-sink.channel = memory-channel 先启动 avro-memory-kafka.conf 12345flume-ng agent \--name avro-memory-kafka \--conf $FLUME_HOME/conf \--conf-file $FLUME_HOME/conf/avro-memory-kafka.conf \-Dflume.root.logger=INFO,console 再启动 exec-memory-avro 12345flume-ng agent \--name exec-memory-avro \--conf $FLUME_HOME/conf \--conf-file $FLUME_HOME/conf/exec-memory-avro.conf \-Dflume.root.logger=INFO,console 最后启动 Kafka 1kafka-server-start.sh config/server.properties 在终端查看消费者信息 1kafka-console-consumer.sh --zookeeper hadoop000:2181 --topic cty_topic 踩坑 在 server.properties 中的 listeners 用于外网访问 Kafka 集群，如果需要在本地调试传消息到 Kafka 集群，就需要这个参数，而且 listeners 的参数必须规范，后面的 IPv4 地址必须要按照规范来，不能用主机名代替，不然外部无法连接，设置规范 1listeners=PLAINTEXT://192.168.43.169:9092 Flume 下沉到 Kafka 需要看官网，下沉的版本号有要求，比如 flume1.6 只支持 kafka 0.9 以上版本]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式日志收集框架 Flume]]></title>
    <url>%2F2019%2F09%2F25%2F%E5%88%86%E5%B8%83%E5%BC%8F%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E6%A1%86%E6%9E%B6-Flume%2F</url>
    <content type="text"><![CDATA[Flume 概述 安装 Flume 架构及核心组件 Flume 配置文件描述 监控一个文件实时采集新增的数据输出到控制台 跨服务采集日志 Flume 概述官网 FLume 是有 Cloudera 提供的一个分布式，高可靠，高可用的服务，用于分布式的海量日志的高效收集、聚合、移动系统 设计目标：可靠性，扩展性，管理性 安装 安装 JDK 下载 flume 安装包 解压安装包 更改配置文件 修改 conf 下的 flume-env.sh.template 复制一份到 flume-env.sh 并修改文件中的 JAVA_HOME 为 jdk 的真实路径 Flume 架构及核心组件 Source：收集 指定数据的来源 Channel：聚集 为数据提供一个临时缓存的地方 Sink：输出 从 Channel 中将数据读取出来，输出到指定位置 Flume 配置文件描述 a1：agent 名称 r1：source 的名称 k1：sink 的名称 c1：channle 的名称 12345678910111213141516171819202122232425262728# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the source# 组件类型为 netcata1.sources.r1.type = netcat# 要绑定的主机名或IP地址a1.sources.r1.bind = hadoop000# 要绑定的端口号a1.sources.r1.port = 44444# Describe the sink# 需要记录组件类型名称a1.sinks.k1.type = logger# Use a channel which buffers events in memory# 组件类型名称，必须是内存a1.channels.c1.type = memory# 通道中存储的最大事件数a1.channels.c1.capacity = 1000# 每次通道从源或汇给接收器的最大事件数a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动命令 1bin/flume-ng agent --name a1 --conf conf --conf-file conf/example.conf -Dflume.root.logger=INFO,console 接收到的消息： 1Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F 0D hello. &#125; Event 是 Flume 数据传输的基本单元 Event = 可选的 header + byte array 监控一个文件实时采集新增的数据输出到控制台Agent 选型：exec source + Memory Channel + Logger Sink 1234567891011121314151617181920212223242526# Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the source# 组件类型名称为 exec a1.sources.r1.type = execa1.sources.r1.command = tail -F /home/hadoop/data/data.loga1.sources.r1.shell = /bin/sh -c# Describe the sink# 需要记录组件类型名称a1.sinks.k1.type = logger# Use a channel which buffers events in memory# 组件类型名称，必须是内存a1.channels.c1.type = memory# 通道中存储的最大事件数a1.channels.c1.capacity = 1000# 每次通道从源或汇给接收器的最大事件数a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1 跨服务采集日志技术选型： exec source + memory channel + avro sink avro source + memory channel + logger sink exec-memory-avro.conf 12345678910111213141516exec-memory-avro.sources = exec-sourceexec-memory-avro.sinks = avro-sinkexec-memory-avro.channels = memory-channelexec-memory-avro.sources.exec-source.type = execexec-memory-avro.sources.exec-source.command = tail -F /home/hadoop/data/data.logexec-memory-avro.sources.exec-source.shell = /bin/sh -cexec-memory-avro.sinks.avro-sink.type = avroexec-memory-avro.sinks.avro-sink.hostname = hadoop000exec-memory-avro.sinks.avro-sink.port = 44444exec-memory-avro.channels.memory-channel.type = memoryexec-memory-avro.sources.exec-source.channels = memory-channelexec-memory-avro.sinks.avro-sink.channel = memory-channel avro-memory-logger.conf 1234567891011121314avro-memory-logger.sources = avro-sourceavro-memory-logger.sinks = logger-sinkavro-memory-logger.channels = memory-channelavro-memory-logger.sources.avro-source.type = avroavro-memory-logger.sources.avro-source.bind = hadoop000avro-memory-logger.sources.avro-source.port = 44444avro-memory-logger.sinks.logger-sink.type = loggeravro-memory-logger.channels.memory-channel.type = memoryavro-memory-logger.sources.avro-source.channels = memory-channelavro-memory-logger.sinks.logger-sink.channel = memory-channel 先启动 avro-memory-logger 12345flume-ng agent \--name avro-memory-logger \--conf $FLUME_HOME/conf \--conf-file $FLUME_HOME/conf/avro-memory-logger.conf \-Dflume.root.logger=INFO,console 再启动 exec-memory-avro 12345flume-ng agent \--name exec-memory-avro \--conf $FLUME_HOME/conf \--conf-file $FLUME_HOME/conf/exec-memory-avro.conf \-Dflume.root.logger=INFO,console]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面试题02]]></title>
    <url>%2F2019%2F09%2F24%2FJava%E9%9D%A2%E8%AF%95%E9%A2%9802%2F</url>
    <content type="text"><![CDATA[Java 多线程模块 Java 反射模块 Java多线程模块51. ThreadLocal 是什么？有哪些使用场景ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本而不会影响其它线程所对应的的副本 ThreadLocal 使用场景：数据库连接和 session 管理等 52. synchronized 底层实现原理synchronized 是由一对 monitorenter / monitorexit 指令实现的，monitor 对象时同步的基本实现单元，在 Java 6 之前，monitor 的实现完全是依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量级操作，性能也很低。 Java 6 的时候，JVM 虚拟机提供了三种不同的 monitor 实现： 偏向锁，轻量级锁和重量级锁，用于改进其性能 53.synchronized 和 volatile 的区别是什么？ volatile 是变量修饰符；synchronized 是修饰类、方法、代码块 volatile 仅能实现变量的修改可见性，不能保证原子性；synchronized 则可以保证变量的修改可见性和原子性 volatile 不会造成线程的阻塞；synchronized 可能会造成线程的阻塞 54. synchronized 和 Lock 有什么区别？ synchronized 可以给类、方法、代码块加锁；Lock 只能给代码块加锁 synchronized 不需要手动获取锁和释放锁，使用简单，发生异常会自动释放锁，不会造成死锁；Lock 需要自己加锁和释放锁，如果使用不当，没有 unLock() 释放锁，就会造成死锁 通过 Lock 可以指导有没有成功获取锁，synchronized 无法知道 55. synchronized 和 ReentrantLock 区别是什么？ ReentrantLock 使用起来比较灵活，但是必须有释放锁配合动作 ReentrantLock 必须手动获取与释放锁；synchronized 不需要手动释放和开启锁 ReentrantLock 只使用于代码块锁；synchronized 可用于修饰方法、代码块等 ReentrantLock 标记的变量不会被编译器优化；synchronized 标记的变量可以被编译器优化 56. atomic 原理atomic 主要利用 CAS（Compare And Swap）和 volatile 和 native 方法俩保证原子操作，从而避免 synchronized 的高开销，执行效率提升 Java 反射模块]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面试题01]]></title>
    <url>%2F2019%2F09%2F20%2FJava%E9%9D%A2%E8%AF%95%E9%A2%9801%2F</url>
    <content type="text"><![CDATA[Java 基础模块 Java 容器模块 Java多线程模块 题库来源于 Java知音 Java 基础模块1. JDK 和 JRE 的区别 JDK（Java Development Kit），Java 开发工具包，提供了 Java 开发环境和运行环境 JRE（Java Runtime Environment），Java 运行环境，为 Java 的运行提供了运行时所需要的环境 JDK 包含了 JRE，同时包含了编译 Java 编码的编译器 Javac，包含了很多 Java 程序调试和分析的工具 2. == 和 equals 的区别 ==：对于基本类型和引用类型，效果是不同的 基本类型：比较值是否相同 引用类型：比较引用是否相同 equals：本质就是 ==，只不过 String 和 Integer 等类重写了 equals 方法，变成了值比较 Object 中的 equals 123public boolean equals(Object obj) &#123; return (this == obj);&#125; String 中重写了 equals 1234567891011121314151617181920212223242526public boolean equals(Object anObject) &#123; // 先判断两个对象的地址是否相同，相同直接返回 true，否则继续判断 if (this == anObject) &#123; return true; &#125; // 判断另一个对象到底是不是字符串 if (anObject instanceof String) &#123; // 转化为字符串类型 String anotherString = (String)anObject; int n = value.length; // 判断两个字符串的长度 if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; // 字符串长度相等就一个一个的判断字符串中每个字符是否相等 while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 3. 两个对象的 hashCode() 相同，则 equals() 也一定为 true 吗？两个对象的 hashCode 相同，equals() 不一定相同 hashCode 相同表示两个键值对的哈希值相同，哈希值相等并不代表键值对相等d 4. final 在 Java 中有什么作用？ 修饰的类叫做最终类 修饰的方法不能被重写 修饰的变量叫常量，常量必须初始化，初始化后值不能被修改 5. Java 中的 Math.round(-1, 5) 等于多少？等于 -1，round() 是四舍五入（直接理解成向上取整） 6. String 属于基础数据类型吗？不属于，基础类型只有 8 种：bit，short，int，long，float，double，char，boolean 7. Java 中操作字符串的都有哪些类？有什么区别？ String StringBuilder StringBuffer StringBuilder 和 StringBuffer 都继承抽象列 AbstractStringBuilder String 声明的是不可变的对象，每次操作都会生成新的对象，然后向指正指向新的对象 StringBuilder 和 StringBuffer 存储数据的字符数组没有被 final 修饰，值可以修改，AbstractStringBuilder 提供了一个自动扩容机制（默认初始长度为 16）长度不够的时候会自动扩容，扩展容量为原来的2倍加2，拼接字符串的效率比 Stirng 高 StringBuilder 执行效率高，但是线程不安全 StringBuffer 每个方法都用 synchronize 修饰，加锁和释放锁消耗资源，效率比 StringBuilder 低，但是线程安全 三者执行速度比较：StringBuilder &gt; StringBuffer &gt; String 8. String str = “i” 与 String str = new String(“i”) 一样吗？不一样，因为内存分配方式不一样 String str = “i”：Java 虚拟机会将其分配到常量池中，如果池中有 “i” 就直接返回地址，没有就创建再返回地址 String str = new String(“i”) ：直接在堆内存中开辟新空间 9. 字符串反转使用 StringBuilder 或者 StringBuffer 的 reverse() 方法 10. String 类的常用方法都有哪些？ indexOf()：返回指定字符的索引 charAt()：返回指定索引的字符 replace()：字符串替换 trim()：取出字符串两端空白 split()：分割字符串，返回一个分割后的字符串数组 getBytes()：返回字符串的 byte 类型数组 length()：返回字符串长度 toLowerCase()：将字符串转成小写字母 toUpperCase()：将字符串转成大小字母 substring()：截取字符串 equals()：字符串比较 11. 抽象类必须有抽象方法吗？不一定，但是包含抽象方法的类一定是抽象类 12. 普通类和抽象类有什么区别？ 普通类不能有抽象方法，抽象类有抽象方法 抽象类不能被实例化，普通类可以 一个类继承抽象类，必须要重写抽象方法，如果不重写，说明子类也是抽象类 13. 抽象类能用 final 修饰吗？抽象类被定义就是用来被继承实现的，被 final 修饰的类不能被继承，所以 abstract 和 final 不能共存于一个类中，抽象类不能用 final 修饰 14. 接口和抽象类有什么区别？ 结构：抽象类用 abstract 修饰；接口用 interface 修饰 继承：抽象类可以继承抽象类，实现接口，继承普通类（前提是被继承的类必须要有构造方法）；接口只能继承接口 实现：抽象类的子类使用 extends 继承；接口使用 implement 实现 构造方法：抽象类可以有构造方法；接口没有 实现数量：抽象类只能单继承；接口可以多实现 变量：抽象类中的变量可以是普通变量；接口里面的变量只能是公共静态变量 方法类型：抽象类中的方法可以有实现，也可以是抽象方法；接口的只能是抽象方法 访问修饰符：接口中的方法默认使用 public abstract；抽象类的方法可以使用 public 和 protected 修饰，如果用 private 就会报错 接口是设计的结果，抽象类是重构的结果 15. Java 中的 IO 流分为几种 按功能分：输入流和输出流 按类型分：字节流和字符流 区别是字节流按 8 位二进制字节为单位传输，字符流以 16 为二进制字符为单位传输 16. BIO、NIO 和 AIO 有什么区别？ BIO：Block IO 同步阻塞式 IO，传统 IO，模式简单使用方便，并发处理能力低 NIO：New IO 同步非阻塞式 IO，BIO 升级，客户端和服务端通过 Channel 通讯，实现多路复用 AIO：Asynchronous IO 是 BIO 升级，也叫 NIO2，异步非阻塞 IO，异步 IO 的操作基于事件和回调机制 17. Files 的常用方法都有哪些 Files.exists()：检测文件路径是否存在 Files.createFile()：创建文件 Files.createDirectory()：创建文件夹 Files.delete()：删除一个文件或目录 Files.copy()：复制文件 Files.move()：移动文件 Files.size()：查看文件个数 Files.read()：读取文件 Files.write()：写入文件 Java 容器模块18. Java 容器都有哪些？Java 容器分为 Collection 和 Map 两大类： Collection： List ArrayList LinkedList Vector Stack Set HashSet LinkedHashSet TreeSet Map: HashMap LinkedHasMap TreeMap ConcurrentHashMap Hashtable 19. Collection 和 Collections 有什么区别？Collection 是一个集合接口，提供了对集合对象进行基本操作的通用接口 Collections 是一个包装类，包含了很多静态方法，不能被实例化，是一个工具类，时间对集合的查找、排序、替换、线程安全化等操作 20. List、Set、Map 之间的区别是什么？List、Set、Map 的区别主要体现在连个方面：元素是否有序，是否允许元素重复 比较 List Set Map 继承接口 Collection Collection 常见实现类 AbstractList(其常用子类有ArrayList、LinkedList、Vector) AbstractSet(其常用子类有HashSet、LinkedHashSet、TreeSet) HashMap、HashTable 常见方法 add( )、remove( )、clear( )、get( )、contains( )、size( ) add( )、remove( )、clear( )、contains( )、size( ) put( )、get( )、remove( )、clear( )、containsKey( )、containsValue( )、keySet( )、values( )、size( ) 元素 可重复 不可重复(用equals()判断) 不可重复 顺序 有序 无序(实际上由HashCode决定) 线程安全 Vector线程安全 Hashtable线程安全 21. HashMap 和 Hashtable 有什么区别？HashMap 是继承自 AbstractMap 类，HashTable 是继承自 Dictionary 类，不过他们都实现了 map，Cloneable（可复制），Serializable（可序列化）三个接口 HashTable 比 HashMap 多提供了 elments() 和 contains() 两个方法 底层结构： HashMap：底层是哈希表数据结构，是线程不同步的，可以存储 null-null 键值对，替代了 HashTable，正因为可以存储 null-null 键值对，当使用 get 获取到 value 的值为 null 时，无法判断是不存在 key，还是这个 key 本身就是 null，所以不能通过 get 来判断 HashMap 中是否存在某个键，应该使用 containsKey() 方法来判断 Hashtable：底层是哈希表结构，是线程同步的，只支持 key-value 键值对 容量以及扩容： Hashtable：初始容量是 11，每次扩充为原来的 2n + 1 HashMap：初始容量为 16，每次扩容为 2n 存储结构的哈希值： HashTable：直接使用对象的 hasCode，hashCode 是 JDK 根据对象的地址或者字符串或者数字算出来的 int 类型的额数值（知识点链接） HashMap：哈希表 + 链表（可能会转化为红黑树） 22. 如何决定使用 HashMap 还是 TreeMap？ HashMap：在 Map 中插入、删除、定位一个元素这类操作 TreeMap：对一个 key 集合进行有序遍历 23. HashMap 实现原理HashMap 基于 Hash 算法实现，通过 put(key, value) 存储，get(key) 来获取 当传入 key 值时，HashMap 会根据 key.hashCode() 计算出 hash 值，根据 hash 值将 value 保存在 buket 里，如果哈希值相同（哈希冲突），当 hash 冲突个数比较小的时候，就用链表，多的话自动转化为红黑树 24. HashSet 实现原理HashSet 基于 HashMap 实现的，HashSet 底层使用 HashMap 来保存元素，相关操作直接调用底层 HashMap 的相关方法实现，HashSet 不允许有重复值出现 25. ArrayList 和 LinkedList 的区别是什么？数据结构实现： ArrayList：是动态数组的数据结构实现 LinkedList：是双向链表的数据结构实现 随机访问效率： ArrayList 比 LinkedList 在随机访问的时候效率要高，因为 LinkedList 是线性的数据存储结构，每次访问的时间复杂度都是 O(n) 删除和增加效率： 在非首尾的增加和删除操作，LinkedList 比 ArrayList 效率高，因为 ArrayList 增加后删除操作要移动被操作位置以后的元素 总结： 频繁读取使用 ArrayList，频繁更改使用 LinkedList 26. 如何实现数组和 List 之间的转换？数组转 List：使用 Arrays.asList(array) 进行转化 List 转数组：使用 List 自带的 toArray() 方法 27.ArrayList 和 Vector 的区别是什么？线程安全： Vector 使用了 Synchronized 来实现线程同步，线程是安全的 ArrayList 是非线程安全的 性能： ArrayList 性能要优于 Vector 扩容： ArrayList 和 Vector 都会根据实际的需要动态调整容量，Vector 会增加 1 倍，ArrayList 会增加 50% 28. Array 和 ArrayList 有什么区别？Array 可以存储基本数据类型和对象，ArrayList 只能存储对象 Array 有固定大小，ArrayList 可以自动扩展 ArrayList 的内置方法比 Array 多 29. 在 Queue 中 poll() 和 remove() 有什么区别？相同点：都是返回第一个元素，并在队列中删除返回的对象 不同点：如果没有元素，remove() 会直接抛出 NoSuchElementException 异常，poll() 会返回 null 30. 哪些集合类是线程安全的？线程安全：Vector，Hashtable，Stack 线程不安全：HashMap（在 JDK 1.5 后，Java.util.concurrent 并发包中有了对应的安全类 ConcurrentHashMap） 31. 迭代器 Iterator 是什么？Iterator 接口提供任何 Collection 的接口，可以从一个 Collection 中使用迭代器方法来获取迭代器实例 迭代器取代了 Java 集合框架中的 Enumeration，允许调用者在迭代过程中移除元素 32. Iterator 怎么使用？有什么特点？123456List&lt;String&gt; list = new ArrayList&lt;&gt;();Iterator&lt;String&gt; it = list.iterator();while (it.hasNext()) &#123; String obj = it.next(); System.out.println(obj);&#125; 特点：更加安全，可以确保在当前遍历的集合元素被更改的时候，会抛出 ConcurrentModificationException 异常 33. Iterator 和 Listlterator Iterator 可以遍历 Set 和 List 集合，ListIterator 只能遍历 List Iterator 只能单向遍历，而 ListIterator 可以双向遍历 ListIterator 实现 Iterator，然后添加了一些额外的功能，比如添加，替换，获取前后节点索引 34. 怎么确保一个集合不能被修改可以使用 Collection.unmodifiableCollection(Collection c) 方法来创建一个只读集合，一旦发生改变，就会抛出 Java.lang.UnsupportedOperationException 异常 Java 多线程模块35. 并行和并发有什么区别？并行：多个处理器或多核处理器同时处理多个任务 并发：多个任务在同一个 CPU 核上，按细分的时间片轮流执行，从逻辑上看是同时执行的 36. 线程和进程的区别？一个程序至少有一个进程，一个进程下至少有一个线程，一个进程下也可以有多个线程来增加程序的执行速度 37. 守护线程是什么？守护线程是运行在后台的一种特殊进程，独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件 在 Java 中的垃圾回收线程就是特殊的守护线程 38. 线程有几种实现方式？ 继承 Thread 类 实现 Runnable 接口 实现 Callable 接口，通过 FutureTask 包装器来创建 Thread 线程 通过线程池创建线程，使用线程池接口 ExecutorService 结合 Callable、Future 事件有返回结果的多线程 前两种 无返回值：重写 run 方法，run 方法返回值 void 后两种 有返回值：通过 Callable 接口，要实现 call 方法，这个方法返回值为 Object，可以保存返回结果 39. Runnable 和 Callable 有什么区别？Runnable 没有返回值，Callable 有返回值，Callable 可以看作是 Runnable 的补充 40. 线程有哪些状态？ 初始：新创建了一个线程对象，但还没有调用 start() 方法 运行：Java 线程中将就绪（ready）和运行中（running）两种状态统称为 ”运行“，线程对象创建后，其他线程调用了该对象的 start() 方法，该对象的线程位于可运行线程池中，等待被线程调用选中，获取 CPU 资源，此时处于就绪状态（ready）。就绪状态的线程在获得 CPU 时间片后变为运行状态（running） 阻塞：表示线程阻塞于锁 等待：进入该状态的线程需要等待其他线程做出一些特定的动作（通知或中断） 超时等待：不同于 waiting，它可以在指定时间后自行返回 终止：表示该线程已经执行完毕 41. sleep() 和 wait() 有什么区别？ 类不同：sleep 来自Thread，wait 来自Object 释放锁：sleep 不释放锁，wait 释放锁 用法不同：sleep 时间到会自动回复，wait 可以使用 notify() 或 notifyAll() 直接唤醒 42. notify() 和 notifyAll() 有什么区别？notifyAll() 会唤醒所有线程，notify() 只会唤醒一个线程 notifyAll() 调用后，会将全部线程由等待池移到锁池，然后参与锁的竞争，竞争成功则继续执行，不成功则留在锁池等待锁被释放后重新竞争 notify() 只能唤醒一个线程，具体唤醒哪一个线程，由虚拟机控制 43.线程的 run() 和 start() 有什么区别start() 用于启动线程，run() 用于执行线程的运行时代码 run() 可以重复调用，而 start() 执行嗲用一次 44. 线程池创建方式最核心的是最后一种： newSingleThreadExecutor()：它的特点在于工作线程数目被限制为 1，操作一个无界的工作队列，所以它保证了所有任务的都是被顺序执行，最多会有一个任务处于活动状态，并且不允许使用者改动线程池实例，因此可以避免其改变线程数目； newCachedThreadPool()：它是一种用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置的时间超过 60 秒，则被终止并移出缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用 SynchronousQueue 作为工作队列； newFixedThreadPool(int nThreads)：重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有 nThreads 个工作线程是活动的。这意味着，如果任务数量超过了活动队列数目，将在工作队列中等待空闲线程出现；如果有工作线程退出，将会有新的工作线程被创建，以补足指定的数目 nThreads； newSingleThreadScheduledExecutor()：创建单线程池，返回 ScheduledExecutorService，可以进行定时或周期性的工作调度； newScheduledThreadPool(int corePoolSize)：和newSingleThreadScheduledExecutor()类似，创建的是个 ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程； newWorkStealingPool(int parallelism)：这是一个经常被人忽略的线程池，Java 8 才加入这个创建方法，其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序； ThreadPoolExecutor()：是最原始的线程池创建，上面1-3创建方式都是对ThreadPoolExecutor的封装。 45. 线程池都有哪些状态 RUNNING：接收新任务，处理等待队列中的任务 SHUTDOWN：不接收新的任务提交，会处理继续等待队列中的任务 STOP：不接收新的任务提交，不再处理等待队列中的任务，中断正在执行的线程 TIDYING：所有任务都销毁了，workCount 为 0，线程池的状态转化为 TIDYING 时，会执行钩子方法 terminated() TERMINATED：terminated() 方法结束后的状态 46. 线程池中 submit() 和 execute() 方法有什么区别？ execute()：只能执行 Runnable 类型的任务 submit()：可以执行 Runnable 和 Callable 类型的任务 47. 在 Java 程序中怎么保证多线程的运行安全？ 使用安全类，java.util.concurrent 的类 使用自动锁 synchronized 使用手动锁 Lock 48. 多线程中 synchronized 锁升级的原理是什么？synchronized 锁升级原理：在锁对象的对象头里面有一个 threadid 字段，在第一次访问的时候 threadid 为空，jvm 让其持有偏向锁，并将 threadid 设置为其线程 id，再次进入的时候会先判断 threadid 是否与其线程 id 一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了 synchronized 锁的升级。 锁的升级的目的：锁升级是为了减低了锁带来的性能消耗。在 Java 6 之后优化 synchronized 的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。 49. 什么是死锁？当线程 A 独占锁 a，并尝试去获取独占锁 b 的同时，线程 B 独占锁 b，并尝试获取独占锁 a 的情况，就会发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象 50. 怎么防止死锁？ 尽量使用 tryLock(long timeout, TimeUnit unit) 的方法（ReentrantLock、ReetrantReadWriteLock），设置超时时间，超时可以退出防止死锁 尽量使用 Java.util.concurrent 并发类代替自己手写锁 尽量降低锁的使用力度 尽量不要几个功能使用同一把锁 尽量减少同步代码块]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java知识点day02(常用关键字)]]></title>
    <url>%2F2019%2F09%2F19%2FJava%E7%9F%A5%E8%AF%86%E7%82%B9day02-%E5%B8%B8%E7%94%A8%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[static修饰：类的变量，方法，方法块 修饰变量时：如果该变量时 public 时，则可以使用 类名.修饰变量名 调用该变量，static 修饰的变量可能会有线程安全的问题，当 static 修饰了共享的变量，在现场交互中就有可能造成安全问题，解决办法： 将被修饰的对象换成线程安全的对象 手动加锁 修饰方法时：表示该方法与类无关，任何类都可以直接访问，但是被 static 修饰的方法只能调用被 static 修饰的变量，static 修饰的方法没有线程问题，方法中的局部变量保存在栈中，每个栈都是隔离的，不会有问题 修饰方法块：静态代码块，加载 .class 到内存中的时候，先初始化 static 的代码块，常常用于初始化一些值 父类和子类加载顺序： 父类静态变量初始化 父类静态代码块初始化 子类静态变量初始化 子类静态代码块初始化 父类构造方法 子类构造方法 规律： 父类的静态变量和静态代码块比子类优先初始化 静态变量和静态代码块比类构造器优先初始化 final定义：不变的，不可改变的 修饰： 类：表示该类是无法被继承的 方法：表示该方法是无法被重写（Override） 变量：内存地址不可改变，且在声明的时候初始化就必须要完成 被 final 的修饰的对象，对象的内存地址不可以更改，但是对象中的内容可以更改 try &amp; catch &amp; finally用于捕捉异常的一套流程 try：用来确定代码指定的范围 catch：捕捉可能有可能会发生的异常 finally：用来执行一定要执行的代码块，无论有没有异常发生，总要执行 finally 语句，为程序提供了一个统一的出口，使程序能正常退出 如果 catch 中发生了异常，finally 还会继续执行，finally 中的代码执行完成后，才会抛出 catch 中的异常 volatile用来修饰某个共享变量，意思是当前共享变量的值被修改后，会及时通知到其他线程上，其他线程就能知道当前共享的变量已经被修改了 transient用来修饰类变量，意思是当前变量是无需进行序列化的，在序列化时，就会忽略该变量 default一般用在接口的方法上，意思是对于该接口，实现类无需强制实现，但自己必须有默认实现]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java知识点day01(String & Long)]]></title>
    <url>%2F2019%2F09%2F18%2FJava%E7%9F%A5%E8%AF%86%E7%82%B9day01-String-Long%2F</url>
    <content type="text"><![CDATA[String不变性源码 12345![second_hello](D:\Blog\myblog\source\_posts\Java知识点day01-String-Long\second_hello.png)![second_hello](D:\Blog\myblog\source\_posts\Java知识点day01-String-Long\second_hello.png)public static void main(String[] args) &#123; String str = "hello"; str = "hello"; str = "world";&#125; 第一次 hello 第二次 hello 第三次 world 可以看出，str 对象并没有变化，但是指向的内存地址改变了 原因 1234public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[];&#125; String 类被 final 修饰，不可以被继承 value[] 也被 final 修饰，说明这个是一个常量数组，一旦被赋值，内存地址就不可以再修改 value[] 被声明为私有属性，外部无法访问到，也没有 set / get 方法 所以针对于当前 String 的对象锁做的操作都是无法影响到 value[]，也就是当前对象指向的那个值，比如 replace，split，substring 等等都无法影响到当前值，只有把生成的新值返回给对象才会有效（其实是在字符串常量池中重新生成了一个新的字符串而已，原来的字符串也还在） 乱码原因 当前所用的编码集不包含当前语言的编码 二进制转化操作时，并没有强制规定字符编码 相等判断源码 1234567891011121314151617181920212223242526public boolean equals(Object anObject) &#123; // 先判断两个对象的地址是否相同，相同直接返回 true，否则继续判断 if (this == anObject) &#123; return true; &#125; // 判断另一个对象到底是不是字符串 if (anObject instanceof String) &#123; // 转化为字符串类型 String anotherString = (String)anObject; int n = value.length; // 判断两个字符串的长度 if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; // 字符串长度相等就一个一个的判断字符串中每个字符是否相等 while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 字符串操作建议使用谷歌的第三方工具包 Guava，里面提供了一系列方法，操作类似于 Scala 语言，不过多说明 LongLong 类型有缓存，他实现了一种缓存机制，缓存了从 -128 到 127 内所有的 Lang 值，也就是说如果使用这个范围内的值，直接冲缓存中拿 123456789101112private static class LongCache &#123; private LongCache()&#123;&#125; // 缓存，范围从 -128 到 127，+1 是因为还有 0 static final Long cache[] = new Long[-(-128) + 127 + 1]; // 静态代码块，Jvm 加载类的时候优先初始化这部分代码 static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Long(i - 128); &#125;&#125; 使用 Long 时，推荐使用 ValueOf 方法，因为 ValueOf 会从缓存中去拿，如果命中缓存，会减小资源的开销]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper安装和Hadoop安装]]></title>
    <url>%2F2019%2F09%2F15%2FZookeeper%E5%AE%89%E8%A3%85%E5%92%8CHadoop%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Zookeeper 安装关闭防火墙！！！ 下载 JDK 1.8 版本下载 Zookeeper 安装包下载链接 解压到 Linux 的路径下（一般是 /usr/local ）配置 Linux 环境变量配置 JAVA_HOME 和 ZOOKEERER_HOME 配置 Zookeeper 单节点 在 zookeeper 文件夹下创建 data 文件夹和 logs 文件夹，用于存放数据和日志 进入 conf 中，将 zoo_sample.cfg 复制一份并重命名为 zoo.cfg 配置 zoo.fg 1234tickTime=2000dataLogDir=/usr/local/zookeeper*/logsdataDir=/usr/local/zookeeper*/dataclientPort=2181 配置完成后即可开启单节点模式 配置 Zookeeper 多节点模式（分布式） 先多搞几台虚拟机（具体多少台开心就好，最好 3 台起步，之后用 scp 复制文件到其他虚拟机） 配置 hosts 文件 配置 ssh 免密登录 给所有虚拟机搞上 JDK 和 Zookeeper 每台虚拟机的 Zookeeper 的目录下创建 data 和 logs 目录 配置 zoo.cfg（和单节点一样搞出来的） 123456789tickTime=2000dataDir=/var/lib/zookeeperclientPort=2181initLimit=5syncLimit=2# 主机名、心跳端口、数据端口server.1=zoo1:2888:3888server.2=zoo2:2888:3888server.3=zoo3:2888:3888 给每个节点加上 myid（myid 是放到 zookeeper 配置的 dataDir 的路径下的） 123iweb5 ： echo '1'&gt;/usr/local/zookeeper/data/myidiweb6 ： echo '2'&gt;/usr/local/zookeeper/data/myidiweb7 ： echo '3'&gt;/usr/local/zookeeper/data/myid 最后就可以启动集群了 Hadoop 安装关闭防火墙！！！ 这玩意儿环境配置老费劲了 直接跳过单节点模式，要是 hadoop 玩单节点就没有必要搞集群了 PS：Hadoop 是在 Zookeeper 环境配置好了的基础上安装的 JDK || 环境变量 || SSH 免密 || hosts 文件配置这里要把 HADOOP_HOME 配置进去，添加到 PATH 里面的时候要把 /bin 和 /sbin 都配置进去 架设虚拟机（实验用的两台，加上 Zookeeper 一共 5 台）开始配置 Hadoop 先配置 hadoop*/etc/hadoop/hadoop-env.sh，将里面的 ${JAVA_HOME} 改成当前 JAVA_HOME 的路径 配置 hadoop*/etc/hadoop/core-site.xml 12345678910111213141516171819&lt;configuration&gt; &lt;!-- 指定hdfs的ns为ns --&gt; &lt;property&gt; &lt;name&gt;fs.defaultF S&lt;/name&gt; &lt;value&gt;hdfs://ns&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop临时目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop-2.8.4/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zookeeper地址 --&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;bigdata1:2181,bigdata2:2181,bigdata3:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置 hadoop*/etc/hadoop/hdfs-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;configuration&gt; &lt;!-- 指定HDFS副本的数量默认3个 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;!--指定hdfs的nameservices为ns，需要和core-site.xml中的保持一致 --&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns&lt;/value&gt; &lt;/property&gt; &lt;!-- ns下面有两个NameNode，分别是nn1，nn2 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;!-- nn1的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn1&lt;/name&gt; &lt;value&gt;bigdata5:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode-1的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn1&lt;/name&gt; &lt;value&gt;bigdata5:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode-2的RPC通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn2&lt;/name&gt; &lt;value&gt;bigdata6:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- namenode-2的http通信地址 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn2&lt;/name&gt; &lt;value&gt;bigdata6:50070&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://bigdata1:8485;bigdata2:8485;bigdata3:8485/ns&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop-2.8.4/journaldata&lt;/value&gt; &lt;/property&gt; &lt;!-- 开启NameNode失败自动切换 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置失败自动切换实现方式 --&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt; sshfence shell(/bin/true) &lt;/value&gt; &lt;/property&gt; &lt;!-- 使用sshfence隔离机制时需要ssh免登陆 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置sshfence隔离机制超时时间 --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置 hadoop*/etc/hadoop/mapred-site.xml 1234567&lt;configuration&gt; &lt;!-- 指定mr框架为yarn方式 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置 hadoop*/etc/hadoop/yarn-site.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;configuration&gt; &lt;!-- 开启RM高可用 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的cluster id --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yrc&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定RM的名字 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;!-- 分别指定RM的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;bigdata5&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;bigdata6&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定zk集群地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;bigdata1:2181,bigdata2:2181,bigdata3:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;hadoopMaster:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;hadoopMaster:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;hadoopMaster:8031&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 同步配置通过 scp 命令将 hadoop*/ 发送给所有主机 集群启动准备工作（所有命令官方文档都有） 在 Zookeeper 的主机上启动 journalnode （这里我必须要说一句，一定要先启动 journalnode，我就是忘记要启动 journalnode，最后耗费了我一个多小时才启动成功） 格式化 namenode （在 active 主机上执行） hdfs namenode -format 格式化 zkfc（在 active 主机上执行） hdfs zkfc -formatZK 启动 active 上的 namenode hadoop-daemon.sh start namenode 在 standby 执行 hdfs namenode -bootstrapStandby 手动启动以下程序 [ hdfs ] namenode zkfc datanode [ yarn ] resourcemanager nodemanager 启动 Web 客户端查看信息]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper概念]]></title>
    <url>%2F2019%2F09%2F15%2FZookeeper%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[简介分布式协调服务，为其他的分布式程序提供协调服务 本身就是分布式程序 提供的服务包含： 主从协调 服务器节点动态上下线 统一配置管理 分布式共享锁 统一名称服务 底层其实只包含两层服务 管理（存储和读取）用户程序提交的数据 为用户程序提供数据节点监听服务 特性 一个 leader，多个 follower 组成的集群 全局数据一致：每个 ZK 服务器的数据都是一致的，无论哪个客户端连接到 ZK，获得的数据都是一样的 分布式读写：更新请求转发，由 leader 实施 顺序执行：来自同一个客户的更新请求按照发送顺序执行 数据更新原子性：要么成功，要么失败 实时性：在一定时间范围内，客户端能得到最新的数据 数据结构 层次化结构，和文件系统差不多 每个节点叫做 znode，并且有唯一路径标识 每个 znode 可以包含数据和子节点（EPHEMERAL 不能有子节点，因为是短暂节点，连接断开后悔自己删除） 客户端可以在节点上设置监视器 Znode 节点类型 有两种节点类型 短暂（EPHEMERAL）断开连接自己删除 持久（PERSISTENT）断开连接不删除 org.apache.zookeeper.CreateMode中定义了四种节点类型 PERSISTENT：永久节点 EPHEMERAL：临时节点 PERSISTENT_SEQUENTIAL：永久节点、序列化 EPHEMERAL_SEQUENTIAL：临时节点、序列化 创建 znode 是设置顺序表示，znode 名称后会附加一个值，顺序号是一个单调递增的计数器，由父节点维护，设置顺序是为了对所有事件进行全局排序，客户端就可以通过顺序推断事件的顺序 分布式共享锁作用：做到一次只有指定个数的客户端访问服务器的某些资源 实现步骤： 客户端上线就向 ZK 注册，创建一把锁 判断是否只有一个客户端在工作，是则该客户端处理业务 获取父节点下注册的所有锁，判断自己是否是注册号码最小的，是则处理业务 当业务处理完成后必须要释放锁 ZooKeeper 中的时间 Zxid 致使 ZooKeeper 节点状态改变的每一个操作都将使节点接收到一个 zxid 格式的时间戳，并且这个时间戳全局有序。 cZxid：是节点的创建时间所对应的 Zxid 格式时间戳。 mZxid：是节点的修改时间所对应的 Zxid 格式时间戳，与其子节点无关。 pZxid：该节点的子节点（或该节点）的最近一次 创建 / 删除 的修改时间所对应的 cZxid 格式时间戳（注：只与 本节点 / 该节点的子节点，有关；与孙子节点无关 版本号 对节点的每一个操作都将致使这个节点的版本号增加。每个节点维护着三个版本号，他们分别为： version 节点数据版本号 cversion 子节点版本号 aversion 节点所拥有的 ACL 版本号 Zookeeper 投票机制用例子比较直观（配置 3 台机器）： 每台机器的 “票” 结构：（myid，zxid） 情况一 T1（1，0） T2（2，0） T3（3，0） T1 启动给自己投一票 T2 启动给自己投一票，收到 T1 的票，并将自己的票发给 T1 —— 判断（如果 zxid 相同，则 myid 大的作为 leader）T2 作为 leader T3 启动已经有 leader 了，不再参与选举直接指定 T2 作为leader 情况二 T1 （1，3） T2（2，10） T3（3，5） T2 作为 leader 然后嗝屁了 T1 和 T3 选举 —— 判断（如果 zxid 不同，则直接判断 zxid，和 myid 无关）T3 作为 leader T2 重新上线后由于 T3 已经是 leader，直接指定 T3 为 leader]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis-Plus高级操作]]></title>
    <url>%2F2019%2F09%2F11%2FMyBatis-Plus%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[推荐视频MyBatis 入门教程 MyBatis 进阶教程 逻辑删除介绍：修改某一行的数据中的某一列的标志值，用值来表示是否已经 “逻辑删除” 并不是真的在表中真正的删除这条数据 先在 application.yml 中配置标志值 1234567mybatis-plus: global-config: db-config: # 未删除的值 logic-not-delete-value: 0 # 已删除的值 logic-delete-value: 1 创建配置类 MyBatisPlusConfiguration.class 123456789101112@Configurationpublic class MyBatisPlusConfiguration &#123; /** * 在 mybatis-plus 3.1.0 以上的版本中不再需要添加这一步 * @return */ @Bean public ISqlInjector sqlInjector() &#123; return new LogicSqlInjector(); &#125;&#125; 在实体类中添加注解 @TableLogic 1234567891011121314151617@Data@TableName("user_pro")public class User &#123; private Long id; private String name; private Integer age; private String email; private Long managerId; private LocalDateTime createTime; private LocalDateTime updateTime; private Integer version; @TableLogic @TableField(select = false, value = "deleted") private Integer deleted;&#125; 使用：这些方法在使用的时候都会自己在后面添加一个 and deleted = 0，表示只操作删除标志位为 0（未删除） 的数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package cn.chentyit.mp2;import cn.chentyit.mp2.dao.UserMapper;import cn.chentyit.mp2.entity.User;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import javax.annotation.Resource;import java.util.List;/** * @Author Chentyit * @Date 2019/9/11 09:22 * @Description: */@RunWith(SpringRunner.class)@SpringBootTestpublic class MyLogicDelete &#123; @Resource private UserMapper userMapper; /** * 会把删除标志位置 1 */ @Test public void deleteById() &#123; int rows = userMapper.deleteById(1094592041087729666L); System.out.println("影响行数：" + rows); &#125; /** * 只查询出删除标志位为 0 的数据 */ @Test public void select() &#123; List&lt;User&gt; users = userMapper.selectList(null); users.forEach(System.out::println); &#125; /** * 只更新标志位为 0 的数据 */ @Test public void updateById() &#123; User user = new User(); user.setAge(26); user.setId(1088248166370832385L); int rows = userMapper.updateById(user); System.out.println("影响行数：" + rows); &#125;&#125; 自动填充介绍：自动填充值以及一些额外的数据 实现： 先在实体类中添加注解 @TableField(fill = FieldFill.INSERT) 和 @TableField(fill = FieldFill.UPDATE) 1234567891011121314151617181920212223242526@Data@TableName("user_pro")public class User &#123; private Long id; private String name; private Integer age; private String email; private Long managerId; @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; @TableField(fill = FieldFill.UPDATE) private LocalDateTime updateTime; private Integer version; @TableLogic @TableField(select = false, value = "deleted") private Integer deleted;&#125; 实现 MetaObjectHandler 接口 12345678910111213141516171819202122232425262728293031323334353637/** * @Author Chentyit * @Date 2019/9/11 10:13 * @Description: */@Componentpublic class MyMetaObjectHandler implements MetaObjectHandler &#123; /** * 在插入的时候填充 * @param metaObject */ @Override public void insertFill(MetaObject metaObject) &#123; // 判断数据库中是否有这个列 boolean hasSetter = metaObject.hasSetter("createTime1"); // 如果有就向这个列插入数据 // 如果没有就不插 if (hasSetter) &#123; setInsertFieldValByName("createTime", LocalDateTime.now(), metaObject); &#125; &#125; /** * 在更新的时候填充 * @param metaObject */ @Override public void updateFill(MetaObject metaObject) &#123; // 判断是否已经设置了值 Object val = getFieldValByName("updateTime", metaObject); // 如果设置了就不进行自动填充 if (val == null) &#123; setUpdateFieldValByName("updateTime", LocalDateTime.now(), metaObject); &#125; &#125;&#125; 测试 1234567891011121314151617181920212223242526272829303132333435/** * @Author Chentyit * @Date 2019/9/11 10:39 * @Description: */@RunWith(SpringRunner.class)@SpringBootTestpublic class FillTest &#123; @Resource private UserMapper userMapper; @Test public void insert() &#123; User user = new User(); user.setName("陈天翼"); user.setAge(21); user.setEmail("chentyit@qq.com"); user.setManagerId(1088248166370832385L); int rows = userMapper.insert(user); System.out.println("影响行数：" + rows); &#125; @Test public void updateById() &#123; User user = new User(); user.setAge(27); user.setId(1171615225418350594L); int rows = userMapper.updateById(user); System.out.println("影响行数：" + rows); &#125;&#125; 乐观锁插件（注：多写的情况下使用悲观锁，多读的场景使用乐观锁） 介绍：取出记录时，获取当前 version 更新时，带上这个 version 版本正确更新成功，错误更新失败 使用： 添加插件 123456789101112@Configurationpublic class MyBatisPlusConfiguration &#123; /** * 添加乐观锁插件 * @return */ @Bean public OptimisticLockerInterceptor optimisticLockerInterceptor() &#123; return new OptimisticLockerInterceptor(); &#125;&#125; 在实体类中的版本属性上面添加 @Verison 12345678910@Data@TableName("user_pro")public class User &#123; // **** @Version private Integer version; // ****&#125; 测试 12345678910111213141516171819202122232425262728/** * @Author Chentyit * @Date 2019/9/11 11:16 * @Description: */@RunWith(SpringRunner.class)@SpringBootTestpublic class OptTest &#123; @Resource private UserMapper userMapper; /** * 如果使用条件构造器 则添加构造器不能复用 */ @Test public void updateById() &#123; int version = 1; User user = new User(); user.setEmail("chentyit2@qq.com"); user.setId(1171617683297271809L); user.setVersion(version); int rows = userMapper.updateById(user); System.out.println("影响行数：" + rows); &#125;&#125; 性能分析插件介绍：输出每条 SQL 语句的执行时间，只在测试和开发环境使用，因为开销很大 使用： 在配置类中添加性能分析插件 12345678910111213141516171819@Configurationpublic class MyBatisPlusConfiguration &#123; // ****** /** * 添加性能分析插件 * @return */ @Bean @Profile(&#123;"dev", "test"&#125;) public PerformanceInterceptor performanceInterceptor() &#123; PerformanceInterceptor performanceInterceptor = new PerformanceInterceptor(); // 格式化 SQL 语句 performanceInterceptor.setFormat(true); // 设置执行最大时间 performanceInterceptor.setMaxTime(5); return performanceInterceptor; &#125;&#125; 配置 JVM 参数 12// 表示使用开发环境-Dspring.profiles.active=dev 执行 SQL 分析打印 先添加依赖包 12345&lt;dependency&gt; &lt;groupId&gt;p6spy&lt;/groupId&gt; &lt;artifactId&gt;p6spy&lt;/artifactId&gt; &lt;version&gt;3.8.2&lt;/version&gt;&lt;/dependency&gt; 修改配置文件 12driver-class-name: com.p6spy.engine.spy.P6SpyDriverurl: jdbc:p6spy:mysql://127.0.0.1:3306/mp?characterEncoding=utf8&amp;useSSL=true&amp;serverTimezone=Asia/Shanghai 添加配置文件 spy.properties 123456789101112131415161718192021module.log=com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory# 自定义日志打印logMessageFormat=com.baomidou.mybatisplus.extension.p6spy.P6SpyLogger# 日志输出到控制台appender=com.baomidou.mybatisplus.extension.p6spy.StdoutLogger# 使用日志系统记录 sql#appender=com.p6spy.engine.spy.appender.Slf4JLogger# 设置 p6spy driver 代理deregisterdrivers=true# 取消JDBC URL前缀useprefix=true# 配置记录 Log 例外,可去掉的结果集有error,info,batch,debug,statement,commit,rollback,result,resultset.excludecategories=info,debug,result,batch,resultset# 日期格式dateformat=yyyy-MM-dd HH:mm:ss# 实际驱动可多个#driverlist=org.h2.Driver# 是否开启慢SQL记录outagedetection=true# 慢SQL记录标准 2 秒outagedetectioninterval=2 修改日志输出路径 先修改配置文件 spy.properties 12# 日志输出到控制台# appender=com.baomidou.mybatisplus.extension.p6spy.StdoutLogger 再添加参数 1logfile=log.log 日志就会打印到 log.log 文件里面了 多租户介绍：多个用户间使用同一套程序，但每个用户之间实现数据隔离 实现： 添加分页插件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * @Author Chentyit * @Date 2019/9/11 09:18 * @Description: */@Configurationpublic class MyBatisPlusConfiguration &#123; // ********** /** * 添加分页插件 * @return */ @Bean public PaginationInterceptor paginationInterceptor() &#123; PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); ArrayList&lt;ISqlParser&gt; sqlParserList = new ArrayList&lt;&gt;(); TenantSqlParser tenantSqlParser = new TenantSqlParser(); tenantSqlParser.setTenantHandler(new TenantHandler() &#123; /** * 添加租户信息的值 * @return */ @Override public Expression getTenantId() &#123; return new LongValue(1088248166370832385L); &#125; /** * 哪个字段添加信息 * @return */ @Override public String getTenantIdColumn() &#123; return "manager_id"; &#125; /** * 是否向某个表中添加租户信息 * @param tableName * @return true 表示过滤掉，不增加； false 表示不过滤，添加租户信息 */ @Override public boolean doTableFilter(String tableName) &#123; if ("user_pro".equals(tableName)) &#123; return true; &#125; return false; &#125; &#125;); sqlParserList.add(tenantSqlParser); paginationInterceptor.setSqlParserList(sqlParserList); return paginationInterceptor; &#125;&#125; 特定 SQL 过滤 方法一：在上面的代码中添加以下代码： 1234567891011121314151617paginationInterceptor.setSqlParserFilter(new ISqlParserFilter() &#123; /** * 是否执行过滤 * @param metaObject * @return false 代表不增加过滤信息；true 代表增加过滤信息 */ @Override public boolean doFilter(MetaObject metaObject) &#123; MappedStatement ms = SqlParserHelper.getMappedStatement(metaObject); if ("cn.chentyit.mp2.dao.UserMapper.selectById".equals(ms.getId())) &#123; return true; &#125; return false; &#125;&#125;); 方法二：在 Mapper 的自定义方法上添加注解 @SqlParser(filter = true)，在查询的时候不需要添加租户信息 1234567891011/** * @Author Chentyit * @Date 2019/9/11 09:09 * @Description: */public interface UserMapper extends BaseMapper&lt;User&gt; &#123; @SqlParser(filter = true) @Select("select * from user_pro $&#123;ew.customSqlSegment&#125;") List&lt;User&gt; mySelectList(@Param(Constants.WRAPPER)Wrapper&lt;User&gt; wrapper);&#125; 动态表名 SQL 解析器介绍：分表存储 使用： 添加动态表名插件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * @Author Chentyit * @Date 2019/9/11 09:18 * @Description: */@Configurationpublic class MyBatisPlusConfiguration &#123; public static ThreadLocal&lt;String&gt; myTableName = new ThreadLocal&lt;&gt;(); // ****************** /** * 添加分页插件 * @return */ @Bean public PaginationInterceptor paginationInterceptor() &#123; PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); ArrayList&lt;ISqlParser&gt; sqlParserList = new ArrayList&lt;&gt;(); // 设置动态表名 DynamicTableNameParser dynamicTableNameParser = new DynamicTableNameParser(); Map&lt;String, ITableNameHandler&gt; tableNameHandlerMap = new HashMap&lt;&gt;(16); // 返回值为 MyBatisPlusConfiguration.myTableName.set("user_2019"); 设置的表名 tableNameHandlerMap.put("user_pro", (metaObject, sql, tableName) -&gt; myTableName.get()); dynamicTableNameParser.setTableNameHandlerMap(tableNameHandlerMap); sqlParserList.add(dynamicTableNameParser); paginationInterceptor.setSqlParserList(sqlParserList); paginationInterceptor.setSqlParserFilter(new ISqlParserFilter() &#123; /** * 是否执行过滤 * @param metaObject * @return false 代表不增加过滤信息；true 代表增加过滤信息 */ @Override public boolean doFilter(MetaObject metaObject) &#123; MappedStatement ms = SqlParserHelper.getMappedStatement(metaObject); if ("cn.chentyit.mp2.dao.UserMapper.selectById".equals(ms.getId())) &#123; return true; &#125; return false; &#125; &#125;); return paginationInterceptor; &#125;&#125; 在代码中调用 1234567@Testpublic void select() &#123; // 设置表名 MyBatisPlusConfiguration.myTableName.set("user_2019"); List&lt;User&gt; users = userMapper.selectList(null); users.forEach(System.out::println);&#125; SQL 注入器介绍：自定义 SQL 使用 创建定义方法的类 123456789101112131415161718/** * @Author Chentyit * @Date 2019/9/11 14:55 * @Description: */public class DeleteAllMethod extends AbstractMethod &#123; @Override public MappedStatement injectMappedStatement(Class&lt;?&gt; mapperClass, Class&lt;?&gt; modelClass, TableInfo tableInfo) &#123; // 指定的 SQL String sql = "delete from " + tableInfo.getTableName(); // mapper 接口方法名 String method = "deleteAll"; SqlSource sqlSource = languageDriver.createSqlSource(configuration, sql, modelClass); return addDeleteMappedStatement(mapperClass, method, sqlSource); &#125;&#125; 创建注入器 123456789101112131415/** * @Author Chentyit * @Date 2019/9/11 14:58 * @Description: */@Componentpublic class MySqlInjector extends DefaultSqlInjector &#123; @Override public List&lt;AbstractMethod&gt; getMethodList(Class&lt;?&gt; mapperClass) &#123; List&lt;AbstractMethod&gt; methodList = super.getMethodList(mapperClass); methodList.add(new DeleteAllMethod()); return methodList; &#125;&#125; 在 Mapper 中加入自定义方法 12345678910111213141516171819202122/** * @Author Chentyit * @Date 2019/9/11 15:09 * @Description: */public interface MyMapper&lt;T&gt; extends BaseMapper&lt;T&gt; &#123; int deleteAll();&#125;/** * @Author Chentyit * @Date 2019/9/11 09:09 * @Description: */public interface UserMapper extends MyMapper&lt;User&gt; &#123; @SqlParser(filter = true) @Select("select * from user_pro $&#123;ew.customSqlSegment&#125;") List&lt;User&gt; mySelectList(@Param(Constants.WRAPPER)Wrapper&lt;User&gt; wrapper);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>MyBatis-Plus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala 操作外部数据]]></title>
    <url>%2F2019%2F09%2F10%2FScala-%E6%93%8D%E4%BD%9C%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[操作文件 &amp;&amp; 网络数据 操作XML 操作 MySQL 操作文件 &amp;&amp; 网络数据12345678910111213141516171819202122232425262728293031323334package cn.chentyit.chapter09import scala.io.Sourceobject FileApp &#123; def main(args: Array[String]): Unit = &#123; val file = Source.fromFile("E:\\test\\data.txt")(scala.io.Codec.UTF8) // 按行读 def readLine(): Unit = &#123; for (line &lt;- file.getLines()) &#123; println(line) &#125; &#125; // readLine() // 按照字符读 def readChar(): Unit = &#123; for (ele &lt;- file) &#123; println(ele) &#125; &#125; // readChar() // 读取网络文件 def readNet(): Unit = &#123; val file = Source.fromURL("http://www.chentyit.com") for (line &lt;- file.getLines()) &#123; println(line) &#125; &#125; readNet() &#125;&#125; 操作XML实例一test.xml 1234567891011&lt;symbols&gt; &lt;symbol ticker="AAPL"&gt; &lt;units&gt;200&lt;/units&gt; &lt;/symbol&gt; &lt;units&gt;200&lt;/units&gt; &lt;symbol ticker="IBM"&gt; &lt;units&gt;400&lt;/units&gt; &lt;/symbol&gt;&lt;/symbols&gt; XMLApp.scala 1234567891011121314151617181920212223package cn.chentyit.chapter09import java.io.&#123;FileInputStream, InputStreamReader&#125;import scala.xml.XMLobject XMLApp &#123; def loadXML(): Unit = &#123; // val xml = XML.load(this.getClass.getClassLoader.getResource("test.xml")) // println(xml) // val xml = XML.load(new FileInputStream("E:\\Program\\IDEA-workplace\\Scala\\scalatrain\\src\\main\\resources\\test.xml")) // print(xml) val xml = XML.load(new InputStreamReader(new FileInputStream("E:\\Program\\IDEA-workplace\\Scala\\scalatrain\\src\\main\\resources\\test.xml"))) print(xml) &#125; def main(args: Array[String]): Unit = &#123; loadXML() &#125;&#125; 实例二pk.xml 12345678910111213141516171819202122232425262728293031323334353637&lt;fix major="4" minor="2"&gt; &lt;header&gt; &lt;field name="BeginString" required="Y"&gt;FIX4.2&lt;/field&gt; &lt;field name="MsgType" required="Y"&gt;Test&lt;/field&gt; &lt;/header&gt; &lt;trailer&gt; &lt;field name="Signature" required="N"/&gt; &lt;field name="CheckSum" required="Y"/&gt; &lt;/trailer&gt; &lt;messages&gt; &lt;message name="Logon" msgtype="A" msgcat="admin"&gt; &lt;field name="ResetSeqNumFlag" required="N"/&gt; &lt;field name="MaxMessageSize" required="N"/&gt; &lt;group name="NoMsgTypes" required="N"&gt; &lt;field name="RefMsgType" required="N"/&gt; &lt;field name="MsgDirection" required="N"/&gt; &lt;/group&gt; &lt;/message&gt; &lt;message name="ResendRequest" msgtype="2" msgcat="admin"&gt; &lt;field name="BeginSeqNo" required="Y"/&gt; &lt;field name="EndSeqNo" required="Y"/&gt; &lt;/message&gt; &lt;/messages&gt; &lt;fields&gt; &lt;field number="1" name="TradingEntityId" type="STRING"/&gt; &lt;field number="4" name="AdvSide" type="STRING"&gt; &lt;value enum="X" description="CROSS"/&gt; &lt;value enum="T" description="TRADE"/&gt; &lt;/field&gt; &lt;field number="5" name="AdvTransType" type="STRING"&gt; &lt;value enum="N" description="NEW"/&gt; &lt;/field&gt; &lt;/fields&gt;&lt;/fix&gt; XMLApp.scala 1234567891011121314151617181920212223242526272829303132333435363738394041424344package cn.chentyit.chapter09import java.io.&#123;FileInputStream, InputStreamReader&#125;import scala.xml.XMLobject XMLApp &#123; def readXMLAttr(): Unit = &#123; val xml = XML.load(this.getClass.getClassLoader.getResource("pk.xml")) // println(xml) // 找到 &lt;header&gt; 下的 &lt;field&gt; // val headerField = xml \ "header" \ "field" // println(headerField) // 找到所有的 &lt;field&gt; // val fields = xml \\ "field" // for (field &lt;- fields) &#123; // println(field) // &#125; // 找到 /header/field/name // val fieldAttributes = (xml \ "header" \ "field").map(_ \ "@name") // val fieldAttributes = (xml \ "header" \ "field" \\ "@name") // for (filedAttribute &lt;- fieldAttributes) &#123; // println(filedAttribute) // &#125; // 找到 name="Logon" 的 message // val filters = (xml \\ "message").filter(_.attribute("name").exists(_.text.equals("Logon"))) // val filters = (xml \\ "message").filter(x =&gt; (x \ "@name").text.equals("Logon")) // for (filter &lt;- filters) &#123; // println(filter) // &#125; // 找到 header/field/name (xml \ "header" \ "field").map(x =&gt;(x \ "@name", x.text, x \ "@required")).foreach(println) &#125; def main(args: Array[String]): Unit = &#123; readXMLAttr() &#125;&#125; 操作 MySQL123456789101112131415161718192021222324252627282930313233343536package cn.chentyit.chapter09import java.sql.&#123;Connection, DriverManager&#125;object MySQLApp &#123; def main(args: Array[String]): Unit = &#123; val url = "jdbc:mysql://127.0.0.1:3306/mysql?characterEncoding=utf8&amp;useSSL=true&amp;serverTimezone=Asia/Shanghai" val userName = "root" val password = "Chentyit123456" var connection: Connection = null; try &#123; // 返回运行时的一个 class 类型 // 不写也可以，但是建议写上 classOf[com.mysql.cj.jdbc.Driver] connection = DriverManager.getConnection(url, userName, password) // 创建 Statement，执行查询语句 val statement = connection.createStatement() val resultSet = statement.executeQuery("select host, user from user") while (resultSet.next()) &#123; val host = resultSet.getString("host") val user = resultSet.getString("user") println(s"$host, $user") &#125; &#125; catch &#123; case e: Exception =&gt; e.printStackTrace() &#125; finally &#123; // 释放资源 if (connection != null) &#123; connection.close() &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala隐式转换]]></title>
    <url>%2F2019%2F09%2F10%2FScala%E9%9A%90%E5%BC%8F%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[概述为一个已存在的类添加一个新的方法 Java：动态代理 Scala：隐式转换 模板123456/** * 传一个简单的对象进来 (man) * 返回一个牛逼的对象回去 (SuperMan) * 然后简单对象就有了牛逼对象的方法了 */implicit def man2superman(man: Man): SuperMan = new SuperMan(man.name) 实例一12345678910111213141516171819202122232425262728293031323334353637383940package cn.chentyit.chapter08import java.io.Fileimport scala.io.Source/********************* 人变超人 *********************/class Man(val name: String) &#123; def eat() = &#123; println(s"man[ $name ] eat ......") &#125;&#125;class SuperMan(val name: String) &#123; def fly() = &#123; println(s"superman[ $name ] fly ......") &#125;&#125;/********************* 给 Scala 的文件对象添加 read 操作 *********************/class RichFile(file: File) &#123; def read() = &#123; Source.fromFile(file.getAbsoluteFile).mkString &#125;&#125;object ImplicitApp extends App &#123; // 定义隐式转换函数 // implicit def man2superman(man: Man): SuperMan = new SuperMan(man.name) // // val man = new Man("cty") // man.eat() // man.fly() implicit def file2RichFile(file: File): RichFile = new RichFile(file) val file = new File("E:\\test\\data.txt") println(file.read())&#125; 实例二（切面封装）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package cn.chentyit.scala06import java.io.Fileimport scala.io.Source/******************* 比较器的扩展 *******************/case class User(name: String, age: Int)trait UserOrdering extends Ordering[User] &#123; override def compare(x: User, y: User): Int = &#123; x.age - y.age &#125;&#125;/******************* 对文件的读写的扩展 *******************/class RichFile(file: String) &#123; def read: String = &#123; Source.fromFile(file).mkString &#125;&#125;object File &#123; def apply(file: String): File = new File(file)&#125;/******************* 隐式函数 切面封装 *******************/object ImplicitContext &#123; // 隐式对象 implicit object UserOrder extends UserOrdering // 隐式函数 implicit def double2Int(x: Double) = x.toInt; // 将 File 转成 RichFile implicit def file2RichFIle(file: File) = new RichFile(file.getAbsolutePath)&#125;// 导入切面封装的对象import cn.chentyit.scala06.ImplicitContext._object Test &#123; def main(args: Array[String]): Unit = &#123; println(List(23, 43, 5, 42).sorted) println(List(User("jack", 20), User("tom", 18)).sorted) val i: Int = 100.9 println(i) println(File("E:\\test\\data.txt").read) &#125;&#125; 隐式参数（不建议使用）介绍：指的是在函数或者方法中，定义一个用 implicit 修饰的参数，此时 Scala 会尝试找到一个指定类型的，用 implicit 修饰的对象，即隐式值，并注入参数 123456789101112131415161718192021222324package cn.chentyit.chapter08/** * 设置隐式参数的函数在没有传参的情况下会寻找作用域（方法，对象，伴生对象）中存在的一个隐式值并传入 * 如果传参就直接将参数传递过去 */object ImplicitArgsApp extends App &#123; implicit val test = "test" def testParam(implicit name: String): Unit = &#123; println(name + "~~~~~~~~~~~~~~~~~~~~") &#125; // implicit val name = "implicit_name" // 编译器会传一个已存在的隐式参数进入函数 // testParam // testParam("cty") // implicit val s1 = "s1" // implicit val s2 = "s2" // 编译器不知道应该传哪一个隐式参数进去 会报错 // testParam&#125; 隐式类介绍：对类增加 implicit 限定的类，其作用主要是对类的加强 123456789101112131415161718package cn.chentyit.chapter08object ImplicitClassApp extends App &#123; implicit class CalculatorInt(x: Int) &#123; def add(a: Int) = a + x &#125; implicit class CalculatorStr(str: String) &#123; def add(a: Int): Int = &#123; var i = str.toInt return i + a &#125; &#125; println(1.add(3)) println("12".add(1))&#125;]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scala函数高级操作]]></title>
    <url>%2F2019%2F09%2F10%2FScala%E5%87%BD%E6%95%B0%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[字符串高级操作 匿名函数 Curry 函数 高阶函数 综合例子 偏函数 字符串高级操作插入变量12345678910package cn.chentyit.chapter07object StringApp extends App &#123; val s = "Hello" val name = "PK" val team = "AC Milan" println(s"$s $name $team")&#125; 多行字符串1234567891011package cn.chentyit.chapter07object StringApp extends App &#123; val b = """ | 这是一个多行字符串 | Hello world | Chentyit |""".stripMargin println(b)&#125; 匿名函数1234567891011121314package cn.chentyit.chapter07/** * 匿名函数：函数可以匿名，也可以不匿名 * (参数名：参数类型) =&gt; 函数体 */object FunctoinApp extends App &#123; val m1 = (x: Int) =&gt; x + 1 println(m1(10)) def add = (x: Int, y: Int) =&gt; x + y println(add(10, 20))&#125; Curry 函数实例一12345678910package cn.chentyit.chapter07object CurryApp extends App &#123; def sum(x: Int, y: Int) = x + y println(sum(10, 20)) // 将原来接收两个参数的函数，转换成两个 def sum2(x: Int)(y: Int) = x + y println(sum2(10)(20))&#125; 实例二1234567891011121314151617181920212223242526272829303132333435package cn.chentyit.scala02object Test &#123; def fun1(x: Int): Int =&gt; Int = &#123; y: Int =&gt; &#123; println(s"$x, $y") x + y &#125; &#125; def fun2(x: Int, y: Int): Int = &#123; x + y &#125; /** * fn3 可以分步调用 * fn2 不可以分步调用 * fn1 可读性差 * @param x * @param y * @return */ def fun3(x: Int)(y: Int): Int = &#123; x + y &#125; def main(args: Array[String]): Unit = &#123; val re1 = fun1(2) val re2 = re1(3) println(re2) println(fun3(2)(3)) &#125;&#125; 高阶函数map &amp;&amp; filter123456789101112131415package cn.chentyit.chapter07object HighFuncApp extends App &#123; val l = List(1, 2, 3, 4, 5, 6, 7, 8) // map：逐个去操作集合中的每个元素 println(l.map((x: Int) =&gt; x * 2)) println(l.map(x =&gt; x * 2)) // 下划线代表当前的元素 println(l.map(_ * 2)) // 过滤出符合条件的元素 println(l.map(_ * 2).filter(_ &gt; 8))&#125; reduce &amp;&amp; fold1234567891011121314151617181920package cn.chentyit.chapter07object HighFuncApp extends App &#123; val l = List(1, 2, 3, 4, 5, 6, 7, 8) // 将两两相邻的元素相减 println(l.reduce(_ - _)) // 从左边开始 // 左边一个元素减右边一个 // 得到的新值再去和右边的值组合再相减 println(l.reduceLeft(_ - _)) // 和上面一样，只是组合方向不同 println(l.reduceRight(_ - _)) // 和 reduce 一样 // 但是在计算开始会给一个初值和第一个参与计算的元素组合 println(l.fold(0)(_ - _)) println(l.foldLeft(0)(_ - _)) println(l.foldRight(0)(_ - _))&#125; flatten &amp;&amp; flatMap12345678910111213package cn.chentyit.chapter07object HighFuncApp extends App &#123; val f = List(List(1, 2), List(3, 4), List(5, 6)) // 将集合 “拍扁” println(f.flatten) // 操作集合中的元素 println(f.map(_.map(_ * 2))) // 操作集合中的元素并 “拍扁” // 可以理解为 flat + map println(f.flatMap(_.map(_ * 2)))&#125; 输出结果 123List(1, 2, 3, 4, 5, 6)List(List(2, 4), List(6, 8), List(10, 12))List(2, 4, 6, 8, 10, 12) 综合例子1234567891011121314package cn.chentyit.chapter07import scala.io.Sourceobject HighFuncApp extends App &#123; val txt = Source.fromFile("E:\\test\\data.txt").mkString val l = List(txt) // mapValues 作用： // Key 保持不变，与新的 Value 一起组成新的元素 // 该函数只适用于 K-V 对的元素 l.flatMap(_.split(",")).map(x =&gt; (x, 1)).groupBy(_._1).mapValues(_.size).foreach(println) // 两种方法结果相同 l.flatMap(_.split(",")).map(x =&gt; (x, 1)).groupBy(_._1).map(x =&gt; (x._1, x._2.size)).foreach(println)&#125; 测试文件内容：（data.txt) 1hello,hello,world,hello 输出结果 12(world,1)(hello,3) 偏函数实例一1234567891011121314151617181920212223242526package cn.chentyit.chapter07import scala.util.Random/** * 偏函数： * 被包在花括号内没有 match 的一组 case 语句 */object PartitalFunctionApp extends App &#123; val names = Array("Akiho Yoshizawa", "YuiHatano", "Aoi Sola") val name = names(Random.nextInt(names.length)) /** * A 是输入参数类型 * B 是输出参数类型 * * @return */ def sayChinese: PartialFunction[String, String] = &#123; case "Akiho Yoshizawa" =&gt; "aaa" case "YuiHatano" =&gt; "bbb" case "Aoi Sola" =&gt; "ccc" &#125; println(sayChinese("Akiho Yoshizawa"))&#125; 实例二1234567891011121314151617181920package chentyit.scala2object Test2 &#123; def main(args: Array[String]): Unit = &#123; val l = List(1, 2, 3, 4, "one") // 将集合中的数据加 10 // l.map(&#123; case x: Int =&gt; x + 10 &#125;) println(l.collect(&#123; case x: Int =&gt; x + 10 &#125;)) val fn1 = new PartialFunction[Any, Int] &#123; // 判断数据是否合法 override def isDefinedAt(x: Any): Boolean = x.isInstanceOf[Int] // 处理数据的方式 override def apply(x: Any): Int = x.asInstanceOf[Int] + 10 &#125; println(l.collect(fn1)) &#125;&#125; 实例三123456789101112131415package chentyit.scala2object Test2 &#123; def main(args: Array[String]): Unit = &#123; val l = List(1, 2, 3, 4, "one") val fn2: PartialFunction[Any, Int] = &#123; case x: Int =&gt; x + 10 &#125; println(l.collect(fn2)) println(l.collect(&#123; case x: Int =&gt; x + 10 &#125;)) &#125;&#125; 实例四12345678910111213141516171819202122232425package chentyit.scala2object Test2 &#123; def main(args: Array[String]): Unit = &#123; val strNum = List("one", "two", "three") def fnx1: PartialFunction[String, Int] = &#123; case "one" =&gt; 1 &#125; def fnx2: PartialFunction[String, Int] = &#123; case "two" =&gt; 2 &#125; def fnx3: PartialFunction[String, Int] = &#123; case _ =&gt; 3 &#125; def fnxx = fnx1 orElse fnx2 orElse fnx3 println(strNum.collect(fnxx)) &#125;&#125;]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy(一)]]></title>
    <url>%2F2019%2F09%2F08%2FScrapy-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[介绍 使用 pipline logging 介绍Scrapy 是一个未来爬取网站数据，提取结构性数据而编写的应用框架 使用创建项目1scrapy startproject mySpider 创建爬取模块1scrapy genspider itcast "itcast.cn" 启动开始爬取1scrapy crawl itcast 代码块： 123456789101112131415161718192021222324# -*- coding: utf-8 -*-import scrapyclass ItcastSpider(scrapy.Spider): # 爬虫名 name = 'itcast' # 允许爬取的范围 allowed_domains = ['itcast.cn'] # 最开始请求的 url 地址 start_urls = ['http://www.itcast.cn/channel/teacher.shtml'] def parse(self, response): # 处理 start_urls 地址对应的响应 # ret1 = response.xpath("//div[@class='tea_con']//h3/text()").extract() # print(ret1) # 分组 li_list = response.xpath("//div[@class='tea_con']//li") for li in li_list: item = &#123;&#125; item["name"] = li.xpath(".//h3/text()").extract()[0] item["title"] = li.xpath(".//h4/text()").extract()[0] print(item) 保存数据pipeline 中保存数据 piplinepipline 可以有多个，原因： 可能会有多个 Spider，不同的 pipline 处理不同的 item 的内容 一个 spider 的内容可能要做不同的操作，比如存入不同的数据库中 注意： pipline 的权重越小，优先级越高 pipline 中 process_item 方法名不能修改为其他的名称 loggingScrapy 项目中使用在 setting.py 里面设置 12345# 设置日志级别LOG_LEVEL = &quot;WARNING&quot;# 设置日志保存路径LOG_FILE = &quot;./log.log&quot; 在代码中调用： 123456789101112131415161718192021# -*- coding: utf-8 -*-import scrapy# 先调用 logging 模块import logging# 将 python 文件名加载到 logging 中logger = logging.getLogger(__name__)class ItcastSpider(scrapy.Spider): name = 'itcast' allowed_domains = ['itcast.cn'] start_urls = ['http://www.itcast.cn/'] def parse(self, response): for i in range(10): item = &#123;&#125; item["come_from"] = "itcast" # 将信息按照等级打印出来 logger.warning(item) yield item 在一般项目用使用单独测试 logging 模块： log_a.py 1234567891011121314import logging# 设置日志的输出样式logging.basicConfig(level=logging.INFO, format='%(levelname)s [%(filename)s] ' '[%(lineno)d] : %(message)s' ' - %(asctime)s', datefmt='[%d/%b/%Y %H:%M:%S]')logger = logging.getLogger(__name__)if __name__ == '__main__': logger.info("this is a info log") logger.info("this is a info log 1") 在 log_b.py 中调用 log_a.py 中的 logging 12345from log_a import loggerif __name__ == '__main__': logger.warning("this is log_b 1") logger.warning("this is log_b 2")]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase 安装]]></title>
    <url>%2F2019%2F09%2F01%2FHBase-%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[下载 HBase 的安装包下载的是 2.0.6 版本 解压安装包1tar -xzvf hdfs-*** -C /usr/local 添加环境变量123456vim /etc/profileexport HBASE_HOME="/usr/local/hbase-2.0.6"export PATH=$&#123;PATH&#125;:$&#123;HBASE_HOME&#125;/binsource /etc/profile 修改配置文件修改 /conf 下的 hbase-env.sh123export JAVA_HOME=/usr/local/jdk8# 使用自己的 Zookeeper 不使用 HBase 自带的 ZKexport HBASE_MANAGES_ZK=false 修改 /conf 下的 hbase-site.xml123456789101112131415161718192021222324252627&lt;configuration&gt; &lt;property&gt; &lt;!-- 这里不设置这个也可以，但是要在下面写上端口号，设置了也不会发生冲突 --&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;bigdata1:2181,bigdata2:2181,bigdata3:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 可以不配置，如果要配置，需要和zookeeper配置文件zoo.cfg中的dataDir指定的路径相同 --&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/usr/local/zookeeper/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 设置 HDFS 的命名空间 --&gt; &lt;!-- 注意：这里要和 hadoop 里面的 core-site.xml 里面配置的 HDFS 命名空间名称相同 --&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://ns/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 设置为分布式 --&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 把 hadoop 的配置文件 core-site.xml 和 hdfs-site.xml 复制到 hbase 的配置文件目录下网上大多数教程都没有这一步，但是加上也没有报错 12cp hadoop-2.8.4/etc/hadoop/core-site.xml hbase-2.0.6/conf/cp hadoop-2.8.4/etc/hadoop/hdfs-site.xml hbase-2.0.6/conf/ 修改 regionservers 文件在 regionservers 文件中添加节点（先把里面的 localhost 删掉） 123456vim regionservers# 添加如下内容（按自己要求修改）bigdata1bigdata2bigdata3 添加并修改 backup-masters文件12345vim backup-masters# 添加如下内容（按自己要求修改）# 这个是备用的 master 节点（防止当前 master 嗝屁后 HBase 集群也跟着嗝屁）bigdata6 将 HBase 文件全部分发到集群的其他节点1scp -r /etc/local/hbase-*** hostname:/etc/local 同步时间（特别注意！！！）如果不同步时间，将无法启动 12# 没有的话就用 yum 安装后再同步ntpdate -u ntp.api.bz 启动 Zookeeper &amp; HDFS &amp; YARN启动后检查一下 123zkServer.sh startstart-dfs.shstart-yarn.sh 启动 HBase(在集群的哪台机器启动，哪台就是当前的 Master) 1start-hbase.sh 观察启动状态在浏览器输入 http://hostname:16010 可以按到 HBase 的节点状态（hostname 是启动 Hbase 的那台机器名） 在命令行输入 jps 查看进程（HRegionServer 和 HMaster 是否启动）]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flume 跨服务器拉取日志]]></title>
    <url>%2F2019%2F08%2F25%2FFlume-%E8%B7%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8B%89%E5%8F%96%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[Flume 跨服务器拉取日志思路介绍 在实际开发中，网站应该不会运行装有 Hadoop 以及相关服务的集群上，所以需要一台新的服务器来运行网站的环境以免发生环境冲突或者端口占用的错误 分服务器的 Nginx 生成日志文件 access.log（存放到任何目录） 分服务器的 Flume 监听 access.log 文件的变化，并将 access.log 文件里面的信息拉取下沉到汇总服务器 汇总服务器获取到分服务器下沉的日志信息，然后再一步下沉到 HDFS 中 如果以上思路成立就存在 Flume 汇总服务器以及 Flume 分服务器（我自己命名的），汇总服务器接收分服务器下沉过来的数据，然后再下沉到 HDFS 中，最后在用 MR + HIVE + Sqoop + MySQL 完成工作流 分服务器的 Flume 配置文件1234567891011121314151617181920212223242526a1.sources = r1a1.channels = c1a1.sinks = k1#define sourcesa1.sources.r1.type = TAILDIRa1.sources.r1.positionFile = /usr/local/flume-1.8.0/bigdata8/taildir_position.jsona1.sources.r1.command =tail -f /test/log.txta1.sources.r1.filegroups = f1a1.sources.r1.filegroups.f1 = /root/web/access.loga1.sources.r1.headers.f1.headerKey1 = value1a1.sources.r1.fileHeader = true#define channelsa1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100#define sinka1.sinks.k1.type = avroa1.sinks.k1.hostname = 192.168.11.37a1.sinks.k1.port =44444#bind sources and sink to channel a1.sources.r1.channels = c1a1.sinks.k1.channel = c1 汇总服务器的 Flume 配置文件1234567891011121314151617181920212223242526272829303132a2.sources = r2a2.channels = c2a2.sinks = k2#define sourcesa2.sources.r2.type = avroa2.sources.r2.bind = 0.0.0.0a2.sources.r2.port = 44444#define channelsa2.channels.c2.type = memorya2.channels.c2.capacity = 10000a2.channels.c2.transactionCapacity = 10000a2.channels.c2.byteCapacityBufferPercentage = 20a2.channels.c2.byteCapacity = 800000#define sinka2.sinks.k2.type = hdfsa2.sinks.k2.channel = c1a2.sinks.k2.hdfs.path = /weblog/flume/events/%y-%m-%d/%H%M%Sa2.sinks.k2.hdfs.filePrefix = events-#一定要加上a2.sinks.k2.hdfs.useLocalTimeStamp = truea2.sinks.k2.hdfs.round = truea2.sinks.k2.hdfs.roundValue = 10a2.sinks.k2.hdfs.roundUnit = minute#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本a2.sinks.k2.hdfs.fileType = DataStream#bind sources and sink to channel a2.sources.r2.channels = c2a2.sinks.k2.channel = c2 总结在分服务器中将下沉（sink）的 type 设置为 avro，并设置下沉的目标服务器的 IP 地址 在汇总服务器中将源（source）的 type 设置成为 arvo 启动的时候先启动汇总服务器再启动分服务器 这里注意：不要在 a2.sources.r2.bind 后面写 localhost 要直接写符合 IPv4 格式的 IP 地址，我试过很多次就是这里出了问题]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive(一)]]></title>
    <url>%2F2019%2F08%2F20%2FHive-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[HiveHive 数据仓库：用于存储数据，都是历史数据，不可变的数据，不能改，不能删，对于 hive 而言，增加的是文件 关系型数据库：用于存储数据，注重业务逻辑，可以进行增删改查 hive 保存了元数据信息，是一个元数据管理工具，是一个驱动，hive 解析 sql 语句，将其翻译成为 MR 的运算程序，同时保存了与元数据信息 安装教程1. JDK 安装2. Hadoop 安装3. MySQL 安装4. 开始安装 Hive 解压到 /usr/local 配置环境变量到 /etc/profile 1export HIVE_HOME="/usr/local/hive1.2.2" 配置元数据库信息 在 hive*/conf/ 中 1cp hive-default.xml.template hive-site.xml 在 hive-site.xml 中添加以下文件 1234567891011121314151617181920212223242526272829303132&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://bigdata7:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt; &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;description&gt;username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;Chentyit123456&lt;/value&gt; &lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;system:java.io.tmpdir&lt;/name&gt; &lt;value&gt;/usr/local/hive1.2.2/tmp&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;system:user.name&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt; 将 MySQL 的连接 jar 包拷贝到 $HIVE_HOME/lib 目录下 这里如果数据库是 5.5 以上版本的 MySQL，选择版本高一点的 5.1.*.jar 连接包，如果是 8.0.0 的就直接使用 8 的连接包 拷贝 hive 的 lib 目录中 jline.2.12.jar 的 jar 包替换掉 hadoop 中的包 1$&#123;HADOOP_HOME&#125;/share/hadoop/yarn/lib/jline-0.9.94.jar 启动 Hive 直接使用 hive 命令 先打开服务端，再打开客户端连接 12hive --service hiveserver2&gt;/dev/null 2&gt;&amp;1 &amp;beeline -u jdbc:hive2://主机名:10000 -n root Hive 命令创建数据库12create database chentyit;create database chentyit if not exists chentyit; 查看数据库12show databases;show databases like 'chenty.*'; 查看某一个数据库的详细信息1describe database chentyit; 删除非空数据库1drop database chentyit CASCADE; 创建数据库时，指定数据库位置（这个位置是在 hdfs 上的）1create database chentyit_p location '/home/database/'; 创建数据库的时候希望能够给数据库增加一些描述性东西1create database chentyit_c comment 'my database'; 创建数据库的时候，需要为数据库增加属性信息，可以使用 with dbproperties 信息1create database chentyit_d with dbproperties('createor'='chenty','date'='2019-08-19'); 修改数据库的属性信息1alter database chentyit_d set dbproperties('edited-by'='hello'); 如果要使用自己已经存在的数据库1use chentyit; 查看当前数据库下的所有表1show tables; 创建表（默认是内部表）1create table user_info(id int, name string) row format delimited fields terminated by '\t'; 创建一个表，该表和已有的某一个表的结构一样（复制表结构）1create table if not exists emp like emp1; 删除一个已经存在的表1drop table emp1; 修改一个表明，重命名1alter table user_info rename to emp_info; 将hdfs上面的文件信息导入到hive表中/home/bigdata 代表文件在在 HDFS 上位置 使用改命令时一定要注意数据与数据之间在 txt 文件编辑的时候一定要 Tab 间隔 导入后 HDFS 里面的数据没了 1load data inpath '/home/database' into table emp_info; 给某一个表增加某一列的信息1alter table emp_info add columns(job string); 修改某一个表的某一列的信息1alter table emp_info change column job cjob int comment 'job_id'; 替换表中的某一个列这里注意，这里的 replace 不是替换一列，而是把所有列重新改写成括号里面的新列 举个例子：原列是（a, b, c) 用下列命令后就变成了 （job, dept）而 a，b，c 三列不见了 1alter table emp_info replace columns(job int, dept int); 修改表中某一列的属性1alter table tab_name set tblproperties('value'='hello'); Hive 成批向某一表插入数据1insert overwrite table emp_info_b select * from emp_info; 将查询结果保留到一个新表中去1create table emp_info_c as select * from emp_info_b; 将查询结果保存到指定的文件目录（可以是本地，也可以 HDFS）12insert overwrite local directory '/home/hadoop/test' select * from emp_info;insert overwrite directory '/aaa/bbb/' select * from emp_info; 两表内连1select * from emp_info a join emp_info b on a.id = b.id; 创建分区表普通表和分区表区别：有大量数据增加的需要建分区表 123create table stu(id INT, age INT, name STRING)partitioned by(p_date STRING) row format delimited fields terminated by '\t'; 分区表加载数据 1load data local inpath '本地文件路径' overwrite into table stu partition (pubdate='2010-08-22'); 创建一个带桶的表1234create table bucket_stu (id int ,age int ,name string)partitioned by (p_date string)clustered by (id) sorted by(id) into 3 bucketsrow format delimited fields terminated by '\t'; 分桶前要设置 1set hive.enforce.bucketing = true; 向桶中添加数据 1insert overwrite table bucket_stu partition(p_date='0817') select id,age,name from stu where p_date='0817'; 数据块抽样（tablesample() 函数） tablesample(n percent) 1create table xxx_new as select * from xxx tablesample(10 percent); tablesample(n M) 指定抽样数据的大小，单位为M 1create table xxx_new as select * from xxx tablesample(n M); tablesample(n rows) —— 默认map的数量是2 1create table xxx_new as select * from xxx tablesample(n rows); 分桶抽样hive 中分桶其实就是根据某一个字段 Hash 取模，放入指定数据的桶中，比如将表 table_1 按照 ID 分成 100 个桶，其算法是 hash(id) % 100，这样，hash(id) % 100 = 0 的数据被放到第一个桶中，hash(id) % 100 = 1 的记录被放到第二个桶中。创建分桶表的关键语句为：CLUSTER BY 语句。 12TABLESAMPLE (BUCKET x OUT OF y [ON colname])select * from table_01 tablesample(bucket 1 out of 10 on rand()); 其中 x 是要抽样的桶编号，桶编号从 1 开始，colname 表示抽样的列，y 表示桶的数量。 随机抽样（rand() 函数） 使用 rand() 函数进行随机抽样，limit 关键字限制抽样返回的数据，其中 rand 函数前的 distribute 和 sort 关键字可以保证数据在 mapper 和 reducer 阶段是随机分布的（Map的个数由自己设置的个数决定） 1select * from table_name where col=xxx distribute by rand() sort by rand() limit num; 使用 order 关键词 (hive 会把 map 的个数设置回 1） 1select * from table_name where col=xxx order by rand() limit num;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx安装]]></title>
    <url>%2F2019%2F08%2F17%2FNginx%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装必要的 C++ 等插件1yum install -y gcc gcc-c++ automake autoconf libtool make 安装 PCRE1234tar -zxvf pcre2-10.33.tar.gz -C /usr/local/cd /usr/local/pcre2-10.33/./configuremake &amp;&amp; make install 安装 zlib12345wget http://zlib.net/zlib-1.2.11.tar.gztar -zxvf zlib-1.2.11.tar.gzcd zlib-1.2.11/./configuremake &amp;&amp; make install 安装 OpenSSL1yum -y install openssl openssl-devel 安装 Nginx12345678tar -zxvf nginx-1.8.1.tar.gz -C /usr/local/cd /usr/local/nginx-1.8.1/./configure --prefix=/usr/local/nginx/make &amp;&amp; make install# 启动需要到 Nginx 的目录下sbin/nginx -c conf/nginx.conf# 查看是否启动成功（80 端口启动)netstat -ntlp 更改配置文件12345location / &#123; root html; # index index.html index.htm; proxy_pass http://chentyit.com;&#125; 然后重新加载一下 1sbin/nginx -s reload 具体配置方式见官网]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop常见错误集]]></title>
    <url>%2F2019%2F08%2F13%2FHadoop%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E9%9B%86%2F</url>
    <content type="text"><![CDATA[摄影：Garrett Patz，来自Unsplash Hadoop集群从节点出现错误（Connection refused） 错误原因：Hadoop 集群 yarn-site.xml 配置错误： 默认情况下 yarn ResourceManager 相关服务IP地址指向的是0.0.0.0。 而在服务器中，0.0.0.0 指的是本机网络地址，那么 NodeManager 就会在本机找 ResourceManager 相关服务，而 slave 节点上并没有这些服务，这些服务在 ResourceManager Master 节点上。所以针对 Hadoop 集群配置 yare-site.xml 某些配置项不能使用默认配置。 注意：hadoop 伪分布式可以使用默认配置，因为所有服务都在本地运行 解决方法：修改所有节点上yare-site.xml配置文件，在该文件中配置ResourceManager Master节点所在地址即可解决问题。详细配置信息如下： 123456789101112&lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;hadoopMaster:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;hadoopMaster:8030&lt;/value&gt; &lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;hadoopMaster:8031&lt;/value&gt; &lt;/property&gt; MR本地提交集群运行 问题描述：无法加载 core-site.xml 配置文件，没法找到 hdfs://ns 的路径，直接指定默认本地路径 错误原因：Maven 打包时没有将 XML 文件打包，所以运行程序时无法加载到 core-site.xml 文件 解决办法：在 pom.xml 文件的 &lt;build&gt;&lt;/build&gt; 添加 12345678910&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 再重新打包运行即可 Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer 这个问题我花了很久时间，代码改了三次才运行成功 最后发现是因为 Mapper 和 Reducer 的传入值有问题，总结下来就是 Mapper 和 Reducer 的入参和出参的类型必须要使用 Hadoop 封装的类型，或者按照 Hadoop 要求封装的类型（自行封装的类，除了要实现 WritableComparable 接口，而且自定义类还必须要有无参构造方法），Hadoop 已封装类型如下：]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>开发问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题274（H指数）]]></title>
    <url>%2F2019%2F07%2F27%2FLeetCode%E5%88%B7%E9%A2%98274%EF%BC%88H%E6%8C%87%E6%95%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[123456789给定一位研究者论文被引用次数的数组（被引用次数是非负整数）。编写一个方法，计算出研究者的 h 指数。h 指数的定义: “h 代表“高引用次数”（high citations）一名科研人员的 h 指数是指他（她）的 （N 篇论文中）至多有 h 篇论文分别被引用了至少 h 次。（其余的 N - h 篇论文每篇被引用次数不多于 h 次。）”来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/h-index著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 示例： 输入: citations = [3,0,6,1,5]输出: 3解释: 给定数组表示研究者总共有 5 篇论文，每篇论文相应的被引用了 3, 0, 6, 1, 5 次。由于研究者有 3 篇论文每篇至少被引用了 3 次，其余两篇论文每篇被引用不多于 3 次，所以她的 h 指数是 3。 思路（借鉴官网的题解）： h 值意味着一个标准，将数组按照题目要求分成两个部分（我刚开始理解成这个标准是通过计算得到的，在阅读题解后发现，降序数组中，这种标准只是一个属性而已，也就是能通过数组规律直接找到） 将数组降序排列 找到 h 值，h 值就是 arr[i] == i 时的 值，将数值作图可以表示为（图片来源于LeetCode 274题解）： h 值是 arr[i] &gt; i 的临界值，只要记录索引 i，就可以求出 h 值 Java 语言实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123; /** * 快速排序 */ public static void qsort(int[] arr, int left, int right) &#123; if (left &gt;= right) &#123; return; &#125; int value = arr[left]; int index = left; // 排序标准为降序 for (int i = left; i &lt;= right; i++) &#123; if (value &lt; arr[i]) &#123; arr[index] = arr[i]; arr[i] = arr[++index]; &#125; &#125; arr[index] = value; qsort(arr, left, index - 1); qsort(arr, index + 1, right); &#125; /** * 解题主体 */ public int hIndex(int[] citations) &#123; // 对数组进行降序排序 qsort(citations, 0, citations.length - 1); // 记录 h 值 int h = 0; for (int i = 0; i &lt; citations.length; i++) &#123; // 只要满足引用值 arr[i] 大于 i值 // 即可求出 h 值 if (citations[i] &gt; i) &#123; h++; &#125; &#125; return h; &#125;&#125; Golang 语言实现123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 快速排序 */func qsort(arr []int, left, right int) &#123; if left &gt;= right &#123; return &#125; value := arr[left] index := left // 排序标准为降序 for i := left; i &lt;= right; i++ &#123; if value &lt; arr[i] &#123; arr[index] = arr[i] arr[i] = arr[index + 1] index++ &#125; &#125; arr[index] = value qsort(arr, left, index - 1) qsort(arr, index + 1, right)&#125;/** * 解题主体 */func hIndex(citations []int) int &#123; // 对数组进行降序排序 qsort(citations, 0, len(citations) - 1) // 记录 h 值 num := 0 for index, value := range citations &#123; // 只要满足引用值 arr[i] 大于 i值 // 即可求出 h 值 if index &lt; value &#123; num += 1 &#125; &#125; return num&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题1122（数组的相对排序）]]></title>
    <url>%2F2019%2F07%2F25%2FLeetCode%E5%88%B7%E9%A2%981122%EF%BC%88%E6%95%B0%E7%BB%84%E7%9A%84%E7%9B%B8%E5%AF%B9%E6%8E%92%E5%BA%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[12345678910给你两个数组，arr1 和 arr2，arr2 中的元素各不相同arr2 中的每个元素都出现在 arr1 中对 arr1 中的元素进行排序，使 arr1 中项的相对顺序和 arr2 中的相对顺序相同未在 arr2 中出现过的元素需要按照升序放在 arr1 的末尾来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/relative-sort-array著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 示例： 输入：arr1 = [2, 3, 1, 3, 2, 4, 6, 7, 9, 2, 19], arr2 = [2, 1, 4, 3, 9, 6]输出：[2, 2, 2, 1, 4, 3, 3, 9, 6, 7, 19] 思路： 先将 arr2 中的元素存入到一个 Map 中，值为 key，下标索引为 index，作为排序的标准 将 arr1 分为两个部分，第一个部分包含 arr2 的元素，第二个部分不包含 arr2 的元素 将第一个部分按照 Map 中的规则进行排序，第二个部分按照升序排序 将两个部分的数组拼接起来 Java 语言实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182class Solution &#123; /** * 这里使用快速排序（我对快速排序情有独钟，但是之后会尝试一下归并排序） * @map 这个是思路1中制定好的排序规则，用作排序条件 */ private static void qsort(Integer[] arr, int left, int right, Map&lt;Integer, Integer&gt; map) &#123; if (left &gt;= right) &#123; return; &#125; int value = arr[left]; int index = left; for (int i = left; i &lt;= right; i++) &#123; // 从 map 中取出对应 key 的 value // 获得该数值对应的序号 if (map.get(value) &gt; map.get(arr[i])) &#123; arr[index] = arr[i]; arr[i] = arr[index + 1]; index++; &#125; &#125; arr[index] = value; qsort(arr, left, index - 1, map); qsort(arr, index + 1, right, map); &#125; /** * 解题主体 */ public int[] relativeSortArray(int[] arr1, int[] arr2) &#123; // 构建一个 Map 存放排序规则 Map&lt;Integer, Integer&gt; numMap = new HashMap&lt;&gt;(16); for (int i = 0; i &lt; arr2.length; i++) &#123; numMap.put(arr2[i], i); &#125; // 两个 list 存放 arr1 分割的两段数据 List&lt;Integer&gt; l1 = new ArrayList&lt;&gt;(); List&lt;Integer&gt; l2 = new ArrayList&lt;&gt;(); for (int i : arr1) &#123; if (numMap.containsKey(i)) &#123; l1.add(i); &#125; else &#123; l2.add(i); &#125; &#125; // 对第一段数据进行快速排序 Integer[] arrbefore = l1.toArray(new Integer[l1.size()]); qsort(arrbefore, 0, arrbefore.length - 1, numMap); // 将第二段数据放入数组中，进行简单选择排序 Integer[] arrafter = l2.toArray(new Integer[l2.size()]); for (int i = 0; i &lt; arrafter.length - 1; i++) &#123; for (int j = i + 1; j &lt; arrafter.length; j++) &#123; if (arrafter[i] &gt; arrafter[j]) &#123; int buf = arrafter[i]; arrafter[i] = arrafter[j]; arrafter[j] = buf; &#125; &#125; &#125; // 创建一个新数组存放结果 int[] arrResult = new int[arrbefore.length + arrafter.length]; // 存放第一部分的数值 for (int i = 0; i &lt; arrbefore.length; i++) &#123; arrResult[i] = arrbefore[i]; &#125; // 存放第二部分的数值 for (int i = 0; i &lt; arrafter.length; i++) &#123; arrResult[i + arrbefore.length] = arrafter[i]; &#125; return arrResult; &#125;&#125; Golang 语言实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * 这里使用快速排序（我对快速排序情有独钟，但是之后会尝试一下归并排序） * @numMap 这个是思路1中制定好的排序规则，用作排序条件 */func qsort(arr []int, left, right int, numMap map[int]int) &#123; if left &gt;= right &#123; return &#125; value := arr[left] index := left for i := left; i &lt;= right; i++ &#123; // 从 map 中取出对应 key 的 value // 获得该数值对应的序号 if numMap[value] &gt; numMap[arr[i]] &#123; arr[index] = arr[i] arr[i] = arr[index + 1] index++ &#125; &#125; arr[index] = value qsort(arr, left, index - 1, numMap) qsort(arr, index + 1, right, numMap)&#125;/** * 解题主体 */func relativeSortArray(arr1 []int, arr2 []int) []int &#123; // 构建一个 Map 存放排序规则 numMap := make(map[int]int) for i := 0; i &lt; len(arr2); i++ &#123; numMap[arr2[i]] = i &#125; // 两个数组存放 arr1 分割的两段数据 var l1 []int var l2 []int // 设置标志位 flag := false for i := 0; i &lt; len(arr1); i++ &#123; // 从 map 中找到对应的 key // 如果找到就存到 l1 中 // 没找到就存到 l2 中 for key, _ := range numMap&#123; if arr1[i] == key &#123; l1 = append(l1, arr1[i]) flag = true break &#125; &#125; if !flag &#123; l2 = append(l2, arr1[i]) &#125; flag = false &#125; // 对 l1 进行快速排序 qsort(l1, 0, len(l1) - 1, numMap) // 对 l2 进行选择排序 for i := 0; i &lt; len(l2) - 1; i++ &#123; for j := i + 1; j &lt; len(l2); j++ &#123; if l2[i] &gt; l2[j] &#123; l2[i], l2[j] = l2[j], l2[i] &#125; &#125; &#125; // 合并两个部分的数组（不得不说 golang 操作数组真的方便） l1 = append(l1, l2...) return l1&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题1030（距离顺序排列矩阵单元格）]]></title>
    <url>%2F2019%2F07%2F24%2FLeetCode%E5%88%B7%E9%A2%981030%EF%BC%88%E8%B7%9D%E7%A6%BB%E9%A1%BA%E5%BA%8F%E6%8E%92%E5%88%97%E7%9F%A9%E9%98%B5%E5%8D%95%E5%85%83%E6%A0%BC%EF%BC%89%2F</url>
    <content type="text"><![CDATA[12345678910给出 R 行 C 列的矩阵，其中的单元格的整数坐标为 (r, c)，满足 0 &lt;= r &lt; R 且 0 &lt;= c &lt; C。另外，我们在该矩阵中给出了一个坐标为 (r0, c0) 的单元格。返回矩阵中的所有单元格的坐标，并按到 (r0, c0) 的距离从最小到最大的顺序排，其中两单元格(r1, c1) 和 (r2, c2) 之间的距离是曼哈顿距离，|r1 - r2| + |c1 - c2|。来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/matrix-cells-in-distance-order著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 示例1： 输入：R = 1, C = 2, r0 = 0, c0 = 0输出：[[0,0],[0,1]]解释：从 (r0, c0) 到其他单元格的距离为：[0,1] 示例2： 输入：R = 2, C = 2, r0 = 0, c0 = 1输出：[[0,1],[0,0],[1,1],[1,0]]解释：从 (r0, c0) 到其他单元格的距离为：[0,1,1,2][[0,1],[1,1],[0,0],[1,0]] 也会被视作正确答案 示例3： 输入：R = 2, C = 3, r0 = 1, c0 = 2输出：[[1,2],[0,2],[1,1],[0,1],[1,0],[0,0]]解释：从 (r0, c0) 到其他单元格的距离为：[0,1,1,2,2,3]其他满足题目要求的答案也会被视为正确，例如 [[1,2],[1,1],[0,2],[1,0],[0,1],[0,0]] 思路： 用一个一位数组存下所有点 利用快速排序按照曼哈顿距离对所有的点进行排序 Java 语言实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Solution &#123; /** * 快速排序 * 排序条件是各个点到目标点的距离 */ private static void qsort(int[][] arr, int left, int right, int r0, int c0) &#123; if (left &gt;= right) &#123; return; &#125; int[] value = arr[left]; int index = left; for (int i = left; i &lt;= right; i++) &#123; // 按照各个点到目标点的距离进行排序 if (Math.abs(value[0] - r0) + Math.abs(value[1] - c0) &gt; Math.abs(arr[i][0] - r0) + Math.abs(arr[i][1] - c0)) &#123; arr[index] = arr[i]; arr[i] = arr[index + 1]; index++; &#125; &#125; arr[index] = value; qsort(arr, left, index - 1, r0, c0); qsort(arr, index + 1, right, r0, c0); &#125; /** * 解题主要方法 */ public int[][] allCellsDistOrder(int R, int C, int r0, int c0) &#123; // 判断所传参数是否满足题目要求 if ((R &gt; 100) || (R &lt; 1) || (C &gt; 100) || (C &lt; 1)) &#123; return null; &#125; // 利用一个一位数组存放二维坐标 // 实质上也是一个二维数组 int[][] arr = new int[R * C][]; for (int i = 0; i &lt; R; i++) &#123; for (int j = 0; j &lt; C; j++) &#123; // 创建一个空间存放每个点的坐标 arr[i * C + j] = new int[2]; arr[i * C + j][0] = i; arr[i * C + j][1] = j; &#125; &#125; // 进行快速排序 qsort(arr, 0, arr.length - 1, r0, c0); return arr; &#125;&#125; Golang 语言实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 快速排序 * 排序条件是各个点到目标点的距离 */func qsort(arr [][]int, left, right, r0, c0 int) &#123; if left &gt;= right &#123; return &#125; value := arr[left] index := left for i := left; i &lt;= right; i++ &#123; // 按照各个点到目标点的距离进行排序 if math.Abs(float64(value[0] - r0)) + math.Abs(float64(value[1] - c0)) &gt; math.Abs(float64(arr[i][0] - r0)) + math.Abs(float64(arr[i][1] - c0)) &#123; arr[index] = arr[i] arr[i] = arr[index + 1] index++ &#125; &#125; arr[index] = value qsort(arr, left, index - 1, r0, c0) qsort(arr, index + 1, right, r0, c0)&#125;/** * 解题主要方法 */func allCellsDistOrder(R int, C int, r0 int, c0 int) [][]int &#123; // 判断所传参数是否满足题目要求 if R &gt; 100 || R &lt; 1 || C &gt; 100 || C &lt; 1 &#123; return nil &#125; // 利用一个一位数组存放二维坐标 // 实质上也是一个二维数组 result := make([][]int, R * C) for i := 0; i &lt; R; i++ &#123; for j := 0; j &lt; C; j++ &#123; // 创建一个空间存放每个点的坐标 result[i * C + j] = make([]int, 2) result[i * C + j][0] = i result[i * C + j][1] = j &#125; &#125; // 进行快速排序 qsort(result, 0, len(result) - 1, r0, c0) return result&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题976（三角形的最大周长）]]></title>
    <url>%2F2019%2F07%2F23%2FLeetCode%E5%88%B7%E9%A2%98976%EF%BC%88%E4%B8%89%E8%A7%92%E5%BD%A2%E7%9A%84%E6%9C%80%E5%A4%A7%E5%91%A8%E9%95%BF%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1234567给定由一些正数（代表长度）组成的数组 A，返回由其中三个长度组成的、面积不为零的三角形的最大周长。如果不能形成任何面积不为零的三角形，返回 0。来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/largest-perimeter-triangle/著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 示例1： 输入：[2,1,2]输出：5 示例2： 输入：[1,2,1]输出：0 示例3： 输入：[3,2,3,4]输出：10 示例4： 输入：[3,6,2,3]输出：8 思路： 理清楚三角形特点，两边之和大于第三边 A1 + A2 &gt; A3，两边之差小于第三边 |A1 - A2| &lt; A3 根据思路1可以得到在有序数组中，某一元素大于前两项之和即可 排序得到有序数组（升序降序随意） 根据思路 1 和 2 得到最大周长 Java 语言实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution &#123; /** * 这里使用的是快速排序 * 具体说明就不详细写了，单独起新博客写 */ public static void qsort(int[] arr, int left, int right) &#123; if (left &gt;= right) &#123; return; &#125; int value = arr[left]; int index = left; for (int i = left; i &lt;= right; i++) &#123; if (value &gt; arr[i]) &#123; arr[index] = arr[i]; arr[i] = arr[index + 1]; index++; &#125; &#125; arr[index] = value; qsort(arr, left, index - 1); qsort(arr, index + 1, right); &#125; /** * 求出满足三角形条件的最大周长 */ public int largestPerimeter(int[] A) &#123; // 判断所给的数组长度是否满足 3 条边 if (A.length &lt; 3) &#123; return 0; &#125; // 快速排序获得一个升序数组 qsort(A, 0, A.length - 1); // 设定一个最大值 int max = 0; // 开始计算最大值 for (int i = 2; i &lt; A.length; i++) &#123; // 计算出满足两边之和大于第三边的最大周长 if ((A[i] &lt; (A[i - 1] + A[i - 2])) &amp;&amp; (max &lt; A[i] + A[i - 1] + A[i - 2])) &#123; max = A[i] + A[i - 1] + A[i - 2]; &#125; &#125; // 返回最大周长 return max; &#125;&#125; Golang 语言实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 这里使用的是快速排序 * 具体说明就不详细写了，单独起新博客写 */func qsort(arr []int, left, right int) &#123; if left &gt;= right &#123; return &#125; value := arr[left] index := left for i := left; i &lt;= right; i++ &#123; if value &gt; arr[i] &#123; arr[index] = arr[i] arr[i] = arr[index + 1] index++ &#125; &#125; arr[index] = value qsort(arr, left, index - 1) qsort(arr, index + 1, right)&#125;/** * 求出满足三角形条件的最大周长 */func largestPerimeter(A []int) int &#123; // 判断所给的数组长度是否满足 3 条边 if len(A) &lt; 3 &#123; return 0 &#125; // 快速排序获得一个升序数组 qsort(A, 0, len(A) - 1) // 设定一个最大值 max := 0 // 开始计算最大值 for i := 2; i &lt; len(A); i++ &#123; // 计算出满足两边之和大于第三边的最大周长 if (A[i] &lt; (A[i-1] + A[i-2])) &amp;&amp; (A[i] + A[i - 1] + A[i - 2] &gt; max) &#123; max = A[i] + A[i - 1] + A[i - 2] &#125; &#125; // 返回最大周长 return max&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LeetCode刷题922（按奇偶排序数组 II）]]></title>
    <url>%2F2019%2F07%2F23%2FLeetCode%E5%88%B7%E9%A2%98922%EF%BC%88%E6%8C%89%E5%A5%87%E5%81%B6%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%20II%EF%BC%89%2F</url>
    <content type="text"><![CDATA[123456789给定一个非负整数数组 A， A 中一半整数是奇数，一半整数是偶数。对数组进行排序，以便当 A[i] 为奇数时，i 也是奇数；当 A[i] 为偶数时， i 也是偶数。你可以返回任何满足上述条件的数组作为答案。来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/sort-array-by-parity-ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 示例： 输入：[4, 2, 5, 7]输出：[4, 5, 2, 7]解释：[4, 7, 2, 5]，[2, 5, 4, 7]，[2, 7, 4, 5] 也会被接受。 思路： 设置奇偶指针指向奇偶位 如果满足奇偶数条件，指针加 2，不满足，两个指针位互换 Java 语言实现1234567891011121314151617181920212223242526class Solution &#123; public static int[] sortArrayByParityII(int[] A) &#123; // 设置奇数指针 int even = 0; // 设置偶数指针 int odd = 1; // 开始循环判断 while (even &lt; A.length &amp;&amp; odd &lt; A.length) &#123; // 判断是否满足偶数条件 if (A[even] % 2 == 0) &#123; even += 2; continue; &#125; // 判断是否满足奇数条件 if (A[odd] % 2 != 0) &#123; odd += 2; continue; &#125; // 不满足以上条件就交换两个指针的值 int buf = A[even]; A[even] = A[odd]; A[odd] = buf; &#125; return A; &#125;&#125; Golang 语言实现12345678910111213141516171819202122func sortArrayByParityII(A []int) []int &#123; // 设置奇数指针 even := 0 // 设置偶数指针 odd := 1 // 开始循环判断 for even &lt; len(A) &amp;&amp; odd &lt; len(A) &#123; // 判断是否满足偶数条件 if A[even]%2 == 0 &#123; even += 2 continue &#125; // 判断是否满足奇数条件 if A[odd]%2 != 0 &#123; odd += 2 continue &#125; // 不满足以上条件就交换两个指针的值 A[even], A[odd] = A[odd], A[even] &#125; return A&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++复制构造函数]]></title>
    <url>%2F2019%2F07%2F19%2FC-%E5%A4%8D%E5%88%B6%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728#include&lt;iostream&gt;using namespace std;class A &#123;private: int value;public: A(int n) &#123; value = n; &#125; A(A other) &#123; value = other.value; &#125; void Print() &#123; cout &lt;&lt; value &lt;&lt; endl; &#125;&#125;;int main() &#123; A a = 10; A b = a; b.Print(); return 0;&#125; 上述代码中，复制构造函数 A(A other) 传入的是 A 的一个实例，由于是传值参数，把形参复制到实参会调用复制构造函数，如果允许复制构造函数传值，就会在复制构造函数内调用复制构造函数，就会形成永久递归，导致栈溢出 修改方案：将 A(A other) 修改为 A(const A&amp; other)]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++的sizeof函数]]></title>
    <url>%2F2019%2F07%2F19%2FC-%E7%9A%84sizeoff%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[1234567891011#include&lt;iostream&gt;using namespace std;class Chen &#123;&#125;;int main() &#123; Chen a; cout &lt;&lt; sizeof(a) &lt;&lt; endl; return 0;&#125; 定义一个空类型，里面没有任何成员变量和成员函数，对该类型求 sizeof，得到的结果是多少？ 正确答案：1 空类型的实例中不包含任何信息，sizeof 的结果本应该是 0，但声明类型的时候应该在内存中占有一定的空间，否则无法使用，占用大小由编译器决定，在 Visual Studio 中占 1 字节空间 如果在该类型中添加构造函数和析构函数，sizeof 的值是多少 正确答案：1 调用构造函数和析构函数只需要找到函数在内存中的地址就可以了，函数地址只与类型有关，与类型的实例无关，编译器不会为这两个函数添加信息，所以 sizeof 的值不会改变 如果把析构函数改成虚函数，sizeof 的值是多少 正确答案：根据计算机来说（32 位机是 4，64 位机是 8） C++ 编译器中，类型中一旦有虚函数，就会为类型生成虚函数表，并且为每一个实例添加一个指向虚函数表的指针，在 32 位机中，一个指针占 4 字节空间，64 位机中，一个指针占 8 字节空间]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言的Goroutine]]></title>
    <url>%2F2019%2F07%2F06%2FGo%E8%AF%AD%E8%A8%80%E7%9A%84Goroutine%2F</url>
    <content type="text"><![CDATA[并发和并行 并发：多线程程序在一个核的 CPU 上运行 并行：多线程程序在多个核的 CPU 上运行 协程和线程 协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的 线程：一个线程上可以跑多个协程，协程是轻量级的线程 goroutine 调度模型 M：线程，OS线程抽象，代表着真正执行计算的资源，在绑定有效的P后，进入schedule循环；而schedule循环的机制大致是从Global队列、P的Local队列以及wait队列中获取G，切换到G的执行栈上并执行G的函数，调用goexit做清理工作并回到M，如此反复。M并不保留G状态，这是G可以跨M调度的基础，M的数量是不定的 P：上下文，表示逻辑处理器， 对G来说，P相当于CPU核，G只有绑定到P(在P的local runq中)才能被调度。对M来说，P提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等，P的数量决定了系统内最大可并行的G的数量（前提：物理CPU核数 &gt;= P的数量），P的数量由用户设置的GOMAXPROCS决定，但是不论GOMAXPROCS设置为多大，P的数量最大为256 G：Goroutine，每个Goroutine对应一个G结构体，G存储Goroutine的运行堆栈、状态以及任务函数，可重用。G并非执行体，每个G需要绑定到P才能被调度执行]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言的Struct]]></title>
    <url>%2F2019%2F07%2F02%2FGo%E8%AF%AD%E8%A8%80%E7%9A%84Struct%2F</url>
    <content type="text"><![CDATA[12345type Student struct &#123; Name string Age int score float32&#125; Struct 的定义struct 定义的三种方式： var stu Student var stu *Student = new (Student) var stu *Student = &amp;Student{} 其中 2 和 3 返回的都是指向结构体的指针，访问形式如下： stu.Name 或者 (*stu).Name Struct 的初始化struct 的内存布局：struct 中的所有字段在内存是连续的 12345678910111213141516171819202122232425262728func main() &#123; var stu Student stu.Age = 18 stu.Name = "hua" stu.score = 80 var stu1 *Student = &amp;Student&#123; Name:"cty", Age:21, score:100, &#125; var stu2 = Student&#123; Name:"cty", Age:21, score:100, &#125; var stu3 = new (Student) stu3.Age = 18 stu3.Name = "hua" stu3.score = 80 fmt.Println(stu) fmt.Println(*stu1) fmt.Println(stu2) fmt.Println(*stu3)&#125; 输出结果 1234&#123;hua 18 80&#125;&#123;cty 21 100&#125;&#123;cty 21 100&#125;&#123;hua 18 80&#125; 工厂模式golang 中的 struct 没有构造函数，一般可以使用工厂模式解决 1234567891011type Student struct &#123; Name string Age int&#125;func NewStudent(name string, age int) *Student &#123; return &amp;Student&#123; Name: name, Age: age, &#125;&#125; Tag可以为 struct 中的每个字段写上一个 tag，这个tag 可以通过反射机制获取，最常用的就是 json 序列化和反序列化 12345678910111213141516171819202122232425import ( "encoding/json" "fmt")type Student struct &#123; Name string `json:"student_name"` Age int `json:"student_age"` Score int `json:"student_score"`&#125;func main() &#123; var stu = Student&#123; Name: "sss", Age: 18, Score: 80, &#125; data, err := json.Marshal(stu) if err != nil &#123; fmt.Println("json encode stu failed, err: ", err) return &#125; fmt.Println(string(data))&#125; 输出结果 1&#123;&quot;student_name&quot;:&quot;sss&quot;,&quot;student_age&quot;:18,&quot;student_score&quot;:80&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言切片]]></title>
    <url>%2F2019%2F07%2F01%2FGo%E8%AF%AD%E8%A8%80%E5%88%87%E7%89%87%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425func testSlice() &#123; var slice []int var arr = [...]int&#123;1, 2, 3, 4, 5&#125; fmt.Println() fmt.Println(arr) slice = arr[1:] fmt.Println(slice) fmt.Println(len(slice)) fmt.Println(cap(slice)) fmt.Println() fmt.Println(arr) slice1 := slice[0:1] fmt.Println(slice1) fmt.Println(len(slice1)) fmt.Println(cap(slice1)) fmt.Println() fmt.Println(arr) slice2 := slice1[0:3] fmt.Println(slice2) fmt.Println(len(slice2)) fmt.Println(cap(slice2))&#125; 初学 Go 语言，疯狂踩坑，很多语法与 Java 不同，这是第一篇关于 Go 语言的学习笔记，开始记录一些学习中遇到的坑 关于切片，在 Java，Python，JS 等语言中都有过类似的语法，但是人家那个叫做截取，就是截取一段新的数组出来，但是 GO 语言就是那个不一样的烟火，刚开始看的时候，就有点懵，今天终于搞懂了，就特地来记录一下，就拿上面这段代码举例，咱们先把运行结果贴出来，方便解释： 1234567891011121314[1 2 3 4 5][2 3 4 5]44[1 2 3 4 5][2]14[1 2 3 4 5][2 3 4]34 我每次都打印一下 arr 就是为了看看切片的时候有没有影响到原数组（很明显没有） 现在来看源代码中的 slice = arr[1:] 这里就生成了第一块切片，也就是 [2, 3, 4, 5]，长度为 4，容量为 4，这个就是初始的切片 然后用 slice1 := slice[0:1] 得到 slice1，仍然没有影响到原数组，得到的切片就是 [2]，长度为 1，容量为 4，因为这个切片是从一个容量为 4 的切片中切出来的，容量不变，只是截取需要的值就行 最后用 slice2 := slice1[0:3] 得到 slice2，这里就和上面的解释一样的了，我就不赘述了 原本我以为从数组里面切出来后的切片再切，容量也会跟着变，但看样子，只要最初的的那个切片容量定了，那再由这个切面切出来的其他切面的容量也是一样，虽然目前看起来没什么用，但以后肯定会有机会用到的 关于自学笔记的博客我不太喜欢用太过专业的词汇来描述，简单能理解就好了，Go 语言不得不说在我放弃 C++ 学习 Java 后，唯一一个能让我觉得优雅的语言（仅个人主观喜好） 补充： 切片创建的方式： 1234var slice []type = make([]type, len)slice := make([]type, len)slice := make([]type, len, cap)// 或者使用数组创建]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS查缺补漏01（面向对象）]]></title>
    <url>%2F2019%2F05%2F31%2FJS%E6%9F%A5%E7%BC%BA%E8%A1%A5%E6%BC%8F01%EF%BC%88%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%EF%BC%89%2F</url>
    <content type="text"><![CDATA[面向对象对象的分类内建对象： 由 ES 标准中定义的对象，在任何的 ES 的实现中都可以使用 宿主对象： 由 JS 的运行环境提供的对象，目前来讲主要指由浏览器提供的对象 自建对象： 由开发人员自己创建的对象 删除对象属性： delete 对象.属性名]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day14）]]></title>
    <url>%2F2019%2F05%2F22%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day14%EF%BC%89%2F</url>
    <content type="text"><![CDATA[异步线程池定义线程池和开启异步可用AsyncConfigurer 接口源码 1234567891011public interface AsyncConfigurer &#123; @Nullable default Executor getAsyncExecutor() &#123; return null; &#125; @Nullable default AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return null; &#125;&#125; getAsyncExecutor 方法返回的是一个自定义的线程池，提供空闲线程来执行异步任务 AsyncUncaughtExceptionHandler 处理异常处理器方法，自定义处理异常 @EnableAsync 如果 Java 配置文件标注它，Spring 就会开启异步可用 @Async 驱动 Spring 使用异步调用 使用 Java 配置定义线程池和启用异步 1234567891011121314151617181920212223@Configuration@EnableAsyncpublic class AsyncConfig implements AsyncConfigurer &#123; /** * 自定义线程池 * @return */ @Override public Executor getAsyncExecutor() &#123; // 定义线程池 ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor(); // 核心线程数 taskExecutor.setCorePoolSize(10); // 线程池最大线程数 taskExecutor.setMaxPoolSize(30); // 线程队列最大线程数 taskExecutor.setQueueCapacity(2000); // 初始化 taskExecutor.initialize(); return taskExecutor; &#125;&#125; 使用 @EnableAsync 代表开启 Spring 异步，就可以使用 @Async 驱动 Spring 使用异步 异步服务接口 1234567public interface AsyncService &#123; /** * 模拟报表生成的异步方法 */ public void generateReport();&#125; 异步方法实现 12345678910@Servicepublic class AsyncServiceImpl implements AsyncService &#123; @Override @Async // 声明使用异步调用 public void generateReport() &#123; // 打印异步线程名称 System.out.println("报表线程名称：【" + Thread.currentThread().getName() + "】"); &#125;&#125; 异步方法控制器 123456789101112131415@Controller@RequestMapping("/async")public class AsyncController &#123; @Autowired private AsyncService asyncService = null; @GetMapping("/page") public String asyncPage() &#123; System.out.println("请求线程名称：【" + Thread.currentThread() + "】"); // 调用异步服务 asyncService.generateReport(); return "async"; &#125;&#125; 控制台打印 12请求线程名称：【Thread[http-nio-8080-exec-1,5,main]】报表线程名称：【ThreadPoolTaskExecutor-1】 异步消息JMS 实例 —— ActiveMQ配置 ActiveMQ 和 JMS 信息 12345678910111213# ActiveMQ 地址spring.activemq.broker-url=tcp://localhost:61616# 配置用户名和密码spring.activemq.user=adminspring.activemq.password=admin# 是否使用发布订阅模式，默认为false，即用的是点对点的模式spring.jms.pub-sub-domain=true# 默认目的地址spring.jms.template.default-destination=activemq.default.destination# 是否启用连接池spring.activemq.pool.enabled=true# 连接池最大连接数spring.activemq.pool.max-connections=50 定义 ActiveMQ 接口 1234567891011121314151617/** * ActiveMQ 服务接口 */public interface ActiveMqService &#123; /** * 发送消息 * @param message */ public void sendMsg(String message); /** * 接收消息 * @param message */ public void receiveMsg(String message);&#125; ActiveMQ 服务实现类 1234567891011121314151617181920212223@Servicepublic class ActiveMqServiceImpl implements ActiveMqService &#123; /** * 注入由 Spring Boot 自动生产的 jmsTemplate */ @Autowired private JmsTemplate jmsTemplate = null; @Override public void sendMsg(String message) &#123; System.out.println("发送消息【" + message + "】"); jmsTemplate.convertAndSend(message); // 自定义发送地址 // jmsTemplate.convertAndSend("your-destination", message); &#125; @Override @JmsListener(destination = "$&#123;spring.jms.template.default-destination&#125;") public void receiveMsg(String message) &#123; System.out.println("接收到消息：【" + message + "】"); &#125;&#125; convertAndSend 是一个发送消息的方法 首先 convert 转换，默认情况下 JmsTemplate 会提供一个 SimpleMessageConverter 去提供转换规则 发送信息（已经在配置文件下设置好了就不用写了） 如果要发送一个对象，就要让对象实现 Serializable 接口以便序列化 ActiveMQ 发送 POJO 对象 1234567891011121314151617181920212223242526272829303132@Servicepublic class ActiveMqUserServiceImpl implements ActiveMqUserService &#123; /** * 注入由 Spring Boot 自动生产的 jmsTemplate */ @Autowired private JmsTemplate jmsTemplate = null; /** * 自定义地址 */ private static final String myDestination = "my-destination"; @Override public void sendUser(User user) &#123; System.out.println("发送消息【" + user + "】"); // 使用自定义地址发送对象 jmsTemplate.convertAndSend(myDestination, user); &#125; /** * 监控自定义地址 * @param user */ @Override @JmsListener(destination = myDestination) public void receiveUser(User user) &#123; System.out.println("接收到消息：【" + user + "】"); &#125;&#125; 但是 ActiveMQ 不信任 POJO 对象，所以要在配置文件中添加以下代码 12spring.activemq.packages.trusted=cn.chentyit.chapter13.pojo,java.langspring.activemq.packages.trust-all=true spring.activemq.packages.trusted 表示信任某个确定的包 spring.activemq.packages.trust-all 表示信任所有的包]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day13）]]></title>
    <url>%2F2019%2F05%2F21%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day13%EF%BC%89%2F</url>
    <content type="text"><![CDATA[限制请求抽象类 WebSecurityConfigurerAdapter 提供了一个方法 configure(HttpSecurity)，通过它能够实现对于不同角色（用户）赋予不同权限的功能 configure(HttpSecurity) 源码 123456789101112131415protected void configure(HttpSecurity http) throws Exception &#123; this.logger.debug("Using default configure(HttpSecurity). If subclassed this will potentially override subclass configure(HttpSecurity)."); /** * 只要通过验证就可以访问所有的请求 * authorizeRequests 方法限定只对签名成功的用户请求 * anyRequest 方法限定所有请求 * authenticated 方法对所有签名成功的用户允许方法 */ ((HttpSecurity)((HttpSecurity)((AuthorizedUrl)http.authorizeRequests().anyRequest()) .authenticated() // and 方法是连接词，formLogin 代表使用 Spring Security 默认的登录界面 .and()).formLogin() // httpBasic 方法说明启用 HTTP 认证 .and()).httpBasic();&#125; formLogin 方法配置了使用 Spring Security 的默认登录页面和 httpBasic 方法启用浏览器的 HTTP 基础认证方式 配置请求路径访问权限使用 Ant 风格配置限定 1234567891011121314151617181920212223242526272829/** * WebSecurityConfigurerAdapter 默认设定访问权限和登录方式 * @param http * @throws Exception */@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; // 限定签名后的权限 http. /* ============== 第一段 ============== */ authorizeRequests() // 限定 "/user/welcome" 请求赋予角色 ROLE_USER 或者 ROLE_ADMIN .antMatchers("/user/welcome", "/user/details").hasAnyRole("USER", "ADMIN") // 限定 "/admin/" 先所有请求权限赋予角色 ROLE_ADMIN .antMatchers("/admin/**").hasAnyAuthority("ROLE_ADMIN") // 其他路径允许签名后访问 .anyRequest().permitAll() /* ============== 第二段 ============== */ // and 代表连接词 // 对于没有配置权限的其他请求允许匿名访问 .and().anonymous() /* ============== 第三段 ============== */ // 使用 Spring Security 默认的登录页面 .and().formLogin() // 启动 HTTP 基础验证 .and().httpBasic();&#125; 权限方法说明 方法 含义 access(String) 参数为SpEL，如果返回为 true 则允许访问 anonymous() 允许匿名访问 authorizeRequests() 限定通过签名的请求 anyRequest() 限定任意的请求 hasAnyRole(String…) 将访问权限赋予多个角色（角色会自动加入前缀 “ROLE_” hasRole(String) 将访问权限赋予一个角色（角色会自动加入前缀 “ROLE_” permitAll() 无条件允许访问 and() 连接词，并取消之前限定前提规则 httpBasic() 启用浏览器的 HTTP 基础验证 formLogin() 启用 Spring Security 默认的登录页面 not() 对其他方法的访问采取求反 fullyAuthenticated() 如果是完整验证（并非 Remember-me），则允许访问 denyAll() 无条件不允许任何访问 hasIpAddress(String) 如果是给定的 IP 地址则允许访问 rememberme() 用户通过 Remember-me 功能验证就允许访问 hasAuthority(String) 如果是给定的角色就允许访问（不加入前缀 “ROLE_”） hasAnyAuthority(String…) 如果是给定的角色中的任意一个就允许访问（不加入前缀 “ROLE_” ） Spring 表达式设置权限 12345678910111213141516@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http.authorizeRequests() // 使用 Spring 表达式限定只有角色 ROLE_USER 或者 ROLE_ADMIN .antMatchers("/user/**").access("hasRole('USER') or hasRole('ADMIN')") // 设置访问权限给角色 ROLE_ADMIN，要求是完整登录（非记住登录） .antMatchers("/admin/welcome").access("hasAnyAuthority('ROLE_ADMIN') &amp;&amp; isFullyAuthenticated()") // 限定 "/admin/welcome2" 访问权限给角色 ROLE_ADMIN，允许不完整登录 .antMatchers("/admin/welcome2").access("hasAnyAuthority('ROLE_ADMIN')") // 使用记住功能 .and().rememberMe() // 使用 Spring Security 默认的登录页面 .and().formLogin() // 启用 HTTP 基础验证 .and().httpBasic();&#125; 方法 含义 authentication() 用户认证对象 denyAll() 拒绝任何访问 hasAnyRole(String…) 当前用户是否存在参数中列明的对象属性 hasRole(String) 当前用户是否存在角色 hasIpAddress(String) 是否请求来自指定的 IP isAnonymous() 是否匿名访问 isAuthenticated() 是否用户通过认证签名 isFullAuthenticated() 是否用户是完整验证，即非“记住我”功能通过的认证 isRememberMe() 是否是通过 “记住我” 功能通过的验证 permitAll() 无条件允许任何访问 principal() 用户的 principal 对象 用户认证功能自定义登录页面Spring Boot 配置登录请求连接和 “记住我” 12345678910111213141516@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http. // 访问 /admin 下的请求需要管理员权限 authorizeRequests().antMatchers("/admin/**").access("hasRole('ADMIN')") // 启用 remember me 功能 .and().rememberMe().tokenValiditySeconds(86400).key("remember-me-key") // 启用 HTTP Basic 功能 .and().httpBasic() // 通过签名后可以访问任何请求 .and().authorizeRequests().antMatchers("/**").permitAll() // 设置登录页和默认的跳转路径 .and().formLogin().loginPage("/login/page").defaultSuccessUrl("/admin/welcome1") // 登出页面和默认跳转路径 .and().logout().logoutUrl("/logout/page").logoutSuccessUrl("/welcome");&#125; remember 启用了 “记住我” 功能，有效期为 1 天 浏览器中将使用 Cookie 以键 “remember-mu-key” 进行保存，并且以 MD5 加密 loginPage 是指定登录路径为 “/login/page” defaultSuccessUrl 方法是指定默认的跳转路径为 “/admin/welcome1” 新增映射关系 1234567891011121314151617@Configurationpublic class WebConfig implements WebMvcConfigurer &#123; /** * 增加映射关系 * @param registry */ @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // 是的 /login/page 映射为 login.jsp registry.addViewController("/login/page").setViewName("login"); // 使得 /login/page 映射为 logout_welcome.jsp registry.addViewController("/login/page").setViewName("logout_welcome"); // 使得 /logout 映射为 logout.jsp registry.addViewController("/logout").setViewName("logout"); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day12）]]></title>
    <url>%2F2019%2F05%2F20%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day12%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Spring Security 安全 Spring Boot 对 Spring Security 支持的配置项 1234567891011121314151617# SECURITY (SecurityProperties)# Spring Security 过滤器排序spring.security.filter.order=-100# 安全过滤器责任链拦截的分支类型spring.security.filter.dispatcher-types=async,error,request# 用户名spring.security.user.name=myuser# 用户密码spring.security.user.password=123456# 用户角色spring.security.user.roles=# SECURITY OATH2 CLIENT（OAuth2ClientProperties）# OAuth 提供者详情配置信息spring.security.oauth2.client.provider.*= ## OAuth 客户端登记信息spring.security.oauth2.client.registration.*= 使用 WebSecurityConfigurerAdapter 自定义WebSecurityConfigurerAdapter 中默认存在的三个方法： 1234567891011121314151617/** * 用来配置用户签名服务，主要是 user-details 机制，还可以给予用户赋予角色 * @param auth 签名管理器构造器，用于构建用户具体权限控制 */protected void configure(AuthenticationManagerBuilder auth);/** * 用来配置 Filter 链 * @param web Spring Web Security 对象 */public void configure(WebSecurity web);/** * 用来配置拦截保护的请求，比如请求放行，请求验证 * @param http http 安全请求对象 */protected void configure(HttpSecurity http) throws Exception; 对于使用 WebSecurity 参数的方法主要是配置 Filter 链的内容，可以配置 Filter 链忽略那些内容。 自定义用户服务信息使用内存签名服务使用内存用户（取消连接方法 and() ） 123456789101112131415161718192021@SpringBootApplicationpublic class Chapter12Application extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; // 密码编码器 PasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); // 使用内存存储 InMemoryUserDetailsManagerConfigurer&lt;AuthenticationManagerBuilder&gt; userConfig = auth.inMemoryAuthentication().passwordEncoder(passwordEncoder); // 注册用户 admin，密码为 abc，并赋予 USER 和 ADMIN 的角色权限 userConfig.withUser("admin") .password(passwordEncoder.encode("abc")) .authorities("ROLE_USER", "ROLE_ADMIN"); userConfig.withUser("myuser") .password(passwordEncoder.encode("123456")) .authorities("ROLE_USER"); &#125; ......&#125; 使用内存缓存用户信息方式不是主要方式，因为内存空间优先，而且会占用 JVM 内存空间 UserDetailsBuilder 方法简介 项目类型 描 述 accountExpired(boolean) 设置账号是否过期 accountLocked(boolean) 是否锁定账号 credentialsExpired(boolean) 定义凭证是否过期 disabled(boolean) 是否禁用用户 username(String) 定义用户名 authorities(GrantedAuthority…) 赋予一个或者多个权限 authorities(List&lt;? extends GrantedAuthority) 使用列表（List）赋予权限 password(String) 定义密码 roles(String…) 赋予角色，会自动加入前缀 “ROLE_” 使用数据库定义用户认证服务12345678910111213141516171819202122232425262728293031323334353637/** * 注入数据源 */@Resourceprivate DataSource dataSource = null;/** * 使用和用户名称查询密码 */String pwdQuery = " select user_name, pwd, available from t_user3 where user_name = ?";/** * 使用用户名称查询角色信息 */String roleQuery = "select u.user_name, r.role_name " + "from t_user3 as u, t_user_role as ur, t_role as r " + "where u.id = ur.user_id, and r.id = ur.role_id " + "and u.user_name = ?";/** * 覆盖 WebSecurityConfigurerAdapter 用户详情方法 * @param auth 用户签名管理器构造器 * @throws Exception */@Overrideprotected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; PasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); auth.jdbcAuthentication() // 密码编码器 .passwordEncoder(passwordEncoder) // 数据源 .dataSource(dataSource) // 查询用户，自动判断密码是否一致 .usersByUsernameQuery(pwdQuery) // 赋予权限 .authoritiesByUsernameQuery(roleQuery);&#125; 设置密码管理器 12345678910111213141516171819202122232425262728293031323334/** * 注入数据源 */@Resourceprivate DataSource dataSource = null;/** * 使用和用户名称查询密码 */String pwdQuery = " select user_name, pwd, available from t_user3 where user_name = ?";/** * 使用用户名称查询角色信息 */String roleQuery = "select u.user_name, r.role_name " + "from t_user3 as u, t_user_role as ur, t_role as r " + "where u.id = ur.user_id, and r.id = ur.role_id " + "and u.user_name = ?";/** * 注入配置的钥匙 */@Value("$&#123;system.user.password.secret&#125;")private String secret = null;@Overrideprotected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; PasswordEncoder passwordEncoder = new Pbkdf2PasswordEncoder(this.secret); auth.jdbcAuthentication() .passwordEncoder(passwordEncoder) .dataSource(dataSource) .usersByUsernameQuery(pwdQuery) .authoritiesByUsernameQuery(roleQuery);&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle学习笔记01]]></title>
    <url>%2F2019%2F05%2F18%2FOracle%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B001%2F</url>
    <content type="text"><![CDATA[count() 如果字段为空，则不统计，* 全部统计 排序 asc 升序，desc 降序 通过其他表创建一个新表 1234CREATE TABLE EMP3 ASSELECT EMP_NO, EMP_NAMEFROM EMPWHERE EMP_NO &lt;= 10 左连接和右连接的主表信息全部显示：左连接的左表示主表，右连接的右表是主表 full join 全连接，有无关联都显示 左连接简写 1234SELECT e.EMP_NO, e.EMP_NAME, d.DEPT_NAMEFROM EMP e, DEPT dWHERE e.DEPTNO = d.DEPT_NO(+)ORDER BY e.EMP_NO 右连接简写 1234SELECT e.EMP_NO, e.EMP_NAME, d.DEPT_NAMEFROM EMP e, DEPT dWHERE e.DEPTNO(+) = d.DEPT_NOORDER BY e.EMP_NO all 表示必须满足所有及结果集，any 表示满足其中一个结果集就可以 ROWID 获取物理地址 ROWNUM 在查询的列前面，添加序号 intersect 放在两个查询之间，表示取交集 union 表示取并集 minus 表示取差集 单行函数 / 聚合函数 单行函数：对每一个函数应用在表的记录中时，只能输入一行结果，返回一个结果. 聚合函数：聚合函数同时可以对多行数据进行操作，并返回一个结果. decode函数 decode(条件,值1,返回值1,值2,返回值2,…值n,返回值n,缺省值) case 12345678910SELECT e.EMP_NO, e.EMP_NAME, ( CASE WHEN e.SALARY &gt;= 900 THEN 'A' WHEN e.SALARY &gt;= 700 AND e.SALARY &lt; 900 THEN 'B' WHEN e.SALARY &gt;= 300 AND e.SALARY &lt; 700 THEN 'C' ELSE 'D' END) lvlFROM EMP eORDER BY lvl 恢复数据库 12345678910111213-- 获取当前时间select * from NTUCTY.EMPas of scn 12156162;deleteFROM EMP eWHERE e.EMP_NO = 15-- 先运行这一条命令 启用行移动功能alter table NTUCTY.EMP enable row movement;-- 在运行这一条 恢复数据flashback table NTUCTY.EMP to scn 12156162;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Oracle - 自学笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day11）]]></title>
    <url>%2F2019%2F05%2F16%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day11%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Erik Kaha on Unsplash REST 风格网站HTTP 动作 GET（VISIT）：访问服务器资源（一个或多个资源） POST（CREATE）：提交服务器资源信息，用来创建新的资源 PUT（UPDATE）：修改服务器已经存在的资源，使用 PUT 时需要把资源的所有属性一并提交 PATCH（UPDATE）：修改服务器已经存在的资源，使用 PATCH 时只需要将部分资源属性提交 DELETE（DELETE）：从服务器将资源删除 Spring MVC 整合 REST如果是简单参数，往往直接通过 URL 直接传递，在 Spring MVC 中可以使用注解 @PathVariable 进行获取。（动点脑子，复杂的你确定你会用 URL 传吗，肯定 JSON 啊） @RequestBody 可以将请求体为 JSON 的数据转化为复杂的 Java 对象。 处理 HTTP 状态码、异常和响应头Spring 提供了实体封装类 ResponseEntity 和注解 @ResponseStatus ResponseEntity 封装错误消息和状态码 @ResponseStatus 配置指定的响应码给客户端]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day10）]]></title>
    <url>%2F2019%2F05%2F15%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day10%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Max Ducourneau on Unsplash Spring MVC 补充知识@ResponseBody 转换为 JSON 的原理@ResponseBody 注解转换为 JSON 流程图 重定向废话不多说，直接上代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 显示用户 * @param id * @param model * @return */@GetMapping("/show")public String showUser(Long id, Model model) &#123; User user = userService.getUser(id); model.addAttribute("user", user); return "data/user";&#125;/** * 使用字符串指定跳转 * @param userName * @param note * @return */@GetMapping("/redirect1")public String redirect1(String userName, String note) &#123; User user = new User(); user.setNote(note); user.setUserName(userName); // 插入数据库后，回填 user 的 id userService.insertUser(user); return "redirect:/user/show?id=" + user.getId();&#125;/** * 使用模型和视图指定跳转 * @param userName * @param note * @return */@GetMapping("/redirect2")public ModelAndView redirect2(String userName, String note) &#123; User user = new User(); user.setNote(note); user.setUserName(userName); // 插入数据库后，回填 user 的 id userService.insertUser(user); ModelAndView mv = new ModelAndView(); mv.setViewName("redirect:/user/show?id=" + user.getId()); return mv;&#125; 改进版本 重定向传递 Java 对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 显示用户 * @param user 直接从数据模型 RedirectAttributes 对象中取出 * @param model * @return */@GetMapping("/showUser")public String showUser(User user, Model model) &#123; System.out.println(user.getId()); return "data/user";&#125;/** * 使用字符串指定跳转 * @param userName * @param note * @param ra * @return */@GetMapping("/redirect1")public String redirect1(String userName, String note, RedirectAttributes ra) &#123; User user = new User(); user.setNote(note); user.setUserName(userName); // 插入数据库后，回填 user 的 id userService.insertUser(user); // 保存需要传递给重定向的对象 ra.addFlashAttribute("user", user); return "redirect:/user/showUser";&#125;/** * 使用模型和视图指定跳转 * @param userName * @param note * @param ra * @return */@GetMapping("/redirect2")public ModelAndView redirect2(String userName, String note, RedirectAttributes ra) &#123; User user = new User(); user.setNote(note); user.setUserName(userName); // 插入数据库后，回填 user 的 id userService.insertUser(user); // 保存需要传递给重定向的对象 ra.addFlashAttribute("user", user); ModelAndView mv = new ModelAndView(); mv.setViewName("redirect:/user/showUser"); return mv;&#125; 上面的代码中给方法中加入了 RedirectAttributes 对象参数，然后将 redirect1 和 redirect2 方法的用户信息通过 addFlashAttribute 保存起来，在执行重定向的时候，再将 user 对象传递 被 addFlashAttribute 保存的参数，在控制器执行完之后，会被保存到 Session 对象中； 执行重定向的时候，进入重定向前首先把 Session 中的参数取出，用以填充重定向方法的参数和数据模型，之后删除 Session 中的数据，执行重定向方法，并传递对象 重定向传递对象的流程图 操作会话对象 @SessionAttribute 应用于参数，将 HTTPSession 中的属性读出 @SessionAttributes 只能用于类的注解，将相关数据模型的属性保存到 Session 中 1234567891011121314151617181920212223@SessionAttributes(names = &#123;"user"&#125;, types = Long.class)@Controller@RequestMapping("/session")public class SessionController &#123; @Autowired private UserService userService = null; /** * @param id @SessionAttribute 从 HttpSession 中取出数据，填充控制器方法参数 * @param model * @return */ @GetMapping("/test") public String test(@SessionAttribute("id") Long id, Model model) &#123; // 根据类型保存到 Session 中 model.addAttribute("id_new", id); User user = userService.getUser(id); // 根据名称保存到 Session 中 model.addAttribute("user", user); return "session/test"; &#125;&#125; 给控制器增加通知 @ControllerAdvice：定义一个控制器的通知类，允许定义一些关于增强控制器的各类通知和限定增强哪些控制器功能等； @InitBinder：定义控制器参数绑定规则，如转换规则，格式化等，他会在参数转换之前执行； @ExceptionHandler：定义控制器发生异常后的操作。发生异常后转跳到指定的友好页面； @ModelAttribute：可以在控制器方法前执行，对数据模型进行操作； （这里有点复杂，笔记没法描述清楚，请看《SpringBoot 深入浅出》第 245 页） 获取请求头参数带请求头的 HTTP 请求 123456789101112131415$.post(&#123; url : "$&#123;pageContext.request.contextPath&#125;/user/header/user", // 设置请求头参数 headers : &#123;id : '1'&#125;, // 成功后的方法 success : function(user) &#123; if (user == null || user.id == null) &#123; alert("获取失败"); return; &#125; // 弹出请求返回的用户信息 alert("id=" + user.id +", user_name=" +user.userName+", note="+ user.note); &#125;&#125;); 代码中的 “headers : {id : ‘1’}” 设置了一个请求头，是一个键为 id 而值为 1 的请求头 使用 @RequestHeader 接收请求头参数 1234567891011/** * 通过 @RequestHeader 接收请求头参数 * @param id * @return */ @PostMapping("/header/user") @ResponseBody public User headerUser(@RequestHeader("id") Long id) &#123; User user = userService.getUser(id); return user; &#125; 通过注解 @RequestHeader(“id”) 获取请求请求头中的的 id 键值]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day09）]]></title>
    <url>%2F2019%2F05%2F14%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day09%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Sid Verma on Unsplash 文件上传Spring MVC 对文件上传的支持文件请求转换类之间的关系 Spring MVC 会将 HttpServletRequest 对象转化为 MultipartHttpServletRequest 对象； 上传文件时，还需要配置 MultipartHttpServletRequest，是通过 MultipartResolver 接口实现的； MultipartResolver 有两个实现类：StandardServletMultipartResolver 和 CommonsMultipartResolver，推荐使用前者进行文件上传（如果没有自定义 MultipartResolver，Spring Boot 自定创建 StandardServletMultipartResolver 对象）； 文件上传配置 12345678910111213# MULTIPART (MultipartProperties)# 是否启用 Spring MVC 多分部上传功能spring.servlet.multipart.enabled=true# 将文件写入磁盘的阈值。值可以使用后缀&quot;MB&quot;或&quot;KB&quot;来表示兆字节或字节大小spring.servlet.multipart.file-size-threshold=0# 指定默认上传的文件夹spring.servlet.multipart.location=# 限制单个文件最大大小spring.servlet.multipart.max-file-size=1MB# 限制所有文件最大大小spring.servlet.multipart.max-request-size=10MB# 是否延迟多部文件请求的参数和文件的解析spring.servlet.multipart.resolve-lazily=false 上传文件 Controller 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091@Controller@RequestMapping("/file")public class FileController &#123; /** * 打开文件上传请求页面 * @return 指向 JSP 的字符串 */ @GetMapping("/upload/page") public String uploadPage() &#123; return "/file/upload"; &#125; /** * 使用HTTPServletRequest 作为参数 * @param request * @return */ @PostMapping("/upload/request") @ResponseBody public Map&lt;String, Object&gt; uploadRequest(HttpServletRequest request) &#123; boolean flag = false; MultipartHttpServletRequest mreq = null; // 强制转换为 MultipartHttpServletRequest 接口对象 if (request instanceof MultipartHttpServletRequest) &#123; mreq = (MultipartHttpServletRequest) request; &#125; else &#123; return dealRequestMap(false, "上传失败"); &#125; // 获取 MultipartFile 文件信息 MultipartFile mf = mreq.getFile("file"); // 获取源文件名称 String fileName = mf != null ? mf.getOriginalFilename() : null; File file = new File(fileName); try &#123; // 保存文件 mf.transferTo(file); &#125; catch (Exception e) &#123; e.printStackTrace(); return dealRequestMap(false, "上传失败"); &#125; return dealRequestMap(true, "上传成功"); &#125; /** * 使用 Spring MVC 的 MultipartFile 类作为参数 * @param file * @return */ @PostMapping("/upload/multipart") @ResponseBody public Map&lt;String, Object&gt; uploadMultipartFile(MultipartFile file) &#123; String fileName = file.getOriginalFilename(); File dest = new File(fileName); try &#123; file.transferTo(dest); &#125; catch (Exception e) &#123; e.printStackTrace(); return dealRequestMap(false, "上传失败"); &#125; return dealRequestMap(true, "上传成功"); &#125; @PostMapping("/upload/part") @ResponseBody public Map&lt;String, Object&gt; uploadPart(Part file) &#123; // 获取提交文件名称 String fileName = file.getSubmittedFileName(); try &#123; // 写入文件 file.write(fileName); &#125; catch (Exception e) &#123; e.printStackTrace(); return dealRequestMap(false, "上传失败"); &#125; return dealRequestMap(true, "上传成功"); &#125; /** * 处理上传文件结果 * @param success * @param msg * @return */ private Map&lt;String, Object&gt; dealRequestMap(boolean success, String msg) &#123; Map&lt;String, Object&gt; result = new HashMap&lt;&gt;(); result.put("success", success); result.put("msg", msg); return result; &#125;&#125; 拦截器当请求来到 DispatcherServlet 时，会根据 HandlerMapping 的机制找到处理器，这样就会返回一个 HandlerExecution 对象，这个对象包含处理器和拦截器，拦截器会对处理器进行拦截。 拦截器的设计HandlerInterceptor 源码 123456789101112131415161718192021public interface HandlerInterceptor &#123; /** * 处理器执行前方法 */ default boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return true; &#125; /** * 处理器处理后方法 */ default void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception &#123; &#125; /** * 处理器完成后方法 */ default void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception &#123; &#125;&#125; 拦截器执行过程 执行 preHandle 方法，返回一个布尔值，如果为 false，则结束所有流程；如果为 true，则执行下一步 执行处理器逻辑，它包含控制器的功能 执行 postHandle 方法 执行视图解析和视图渲染 执行 afterCompletion 方法 自定义简单拦截器 123456789101112131415161718192021222324252627282930public class Interceptor1 implements HandlerInterceptor &#123; @Override public boolean preHandle( HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("处理器前方法"); // 返回 true，不会拦截后续的处理 return true; &#125; @Override public void postHandle( HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("处理器后方法"); &#125; @Override public void afterCompletion( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("处理器完成方法"); &#125;&#125; 注册拦截器 123456789101112131415@SpringBootApplicationpublic class Chapter10Application implements WebMvcConfigurer &#123; public static void main(String[] args) &#123; SpringApplication.run(Chapter10Application.class, args); &#125; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 注册拦截器到 Spring MVC 机制，然后会返回一个拦截器注册 InterceptorRegistration ir = registry.addInterceptor(new Interceptor1()); // 指定拦截匹配模式，限制拦截器拦截请求 ir.addPathPatterns("/interceptor/*"); &#125;&#125; 如果注册多个，和上面一样配置 国际化国际化消息源大部分情况下，是使用 JDK 的 ResourceBundle 处理国际化信息的，为此这里主要使用 ResourceBundleMessageSource 这个国际化消息源 123456789101112# 设置国际化消息是否总是采用格式化，默认 falsespring.messages.always-use-message-format=false# 设置国际化属性名称，如果可以使用逗号分隔，默认为 messagespring.messages.basename=messages# 设置国际化消息缓存超时秒数，默认为永远不过期，如果为 0 表示每次都重新加载spring.messages.cache-duration=# 国际化消息编码spring.messages.encoding=utf-8# 如果没有找到特定区域设置的文件，则设置是否返回到系统区域设置spring.messages.fallback-to-system-locale=true# 是否使用消息编码作为默认的响应消息，而非抛出 NoSuchMessageException 异常，建议只在开发时使用spring.messages.use-code-as-default-message=false 国际化解析器 AcceptHeaderLocaleResolver：使用浏览器头请求去实现国际化区域 FixedLocaleResolve：固定国际化区域。 CookieLocaleResolve：将国际化区域信息设置在浏览器 Cookie 中，使得系统可以从 Cookie 中读取国际化信息来确定用户的国际化区域 SessionLocaleResolve：类似于 CookieLocaleResolve，只是将国际化信息设置在 Session 中，这样就能读取 Session 中的信息去确定用户的国际化区域 国际化解析器设计 Spring MVC 国际化流程图 LocaleChangeInterceptor 拦截器可以通过请求参数来确定国际化，同时吧请求参数保存到 Session 中。 在 Spring Boot 启动 java 文件中添加国家化解析器和拦截器 1234567891011121314151617181920212223242526272829303132333435/** * 国际化解析器 * Bean Name 要为 localeResolve * @return */ @Bean(name = "localeResolver") public LocaleResolver initLocaleResolver() &#123; SessionLocaleResolver slr = new SessionLocaleResolver(); // 默认国际化区域 slr.setDefaultLocale(Locale.SIMPLIFIED_CHINESE); return slr; &#125; /** * 创建国际化拦截器 * @return */ @Bean public LocaleChangeInterceptor localeChangeInterceptor() &#123; if (lci != null) &#123; return lci; &#125; lci.setParamName("language"); return lci; &#125; /** * 给处理器增加国际化拦截器 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 这里将通过国际化拦截器的 preHandle 方法对请求的国际化区域参数进行修改 registry.addInterceptor(localeChangeInterceptor()); &#125; initLocaleResolver 方法创建了一个国际化拦截器，有两点需要注意，第一，保证 BeanName 为 “localeResolver”；第二，设置了默认语言为简体中文； localeChangeInterceptor 方法创建国际化拦截器，这里设置拦截参数为 “language”； addInterceptors 方法将拦截器添加到 Spring MVC 中；]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day08）]]></title>
    <url>%2F2019%2F05%2F11%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day08%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by asoggetti on Unsplash 处理器映射12345678910111213141516171819202122232425262728293031@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Mappingpublic @interface RequestMapping &#123; // 配置请求映射名称 String name() default ""; // 通过路径映射 @AliasFor("path") String[] value() default &#123;&#125;; // 通过路径映射回 path 配置项 @AliasFor("value") String[] path() default &#123;&#125;; // 限定只响应 HTTP 请求类型，如 GET，POST，HEAD，OPTIONS，PUT，TRACE 等 RequestMethod[] method() default &#123;&#125;; // 当存在对应的 HTTP 参数时才响应请求 String[] params() default &#123;&#125;; // 限定请求头存在对应的参数时才响应 String[] headers() default &#123;&#125;; // 限定 HTTP 请求体提交类型，如 "application/json"、"text/html" String[] consumes() default &#123;&#125;; // 限定返回的内容类型，仅当 HTTP 请求头中的（Accept）类型中包含该指定类型时才返回 String[] produces() default &#123;&#125;;&#125; 获取控制器参数处理器是对控制器的包装，处理器运行过程中会调度控制器的方法，只是它在进入控制器方法之前会对 HTTP 的参数和上下文进行解析 无注解下获取参数12345678910111213141516/** * 在无注解下获取参数，要求参数名称和 HTTP 参数名称一致 * @param intVal —— 整数 * @param longVal —— 长整型 * @param string —— 字符串 * @return 响应 JSON 参数 */@GetMapping("/no/annotation")@ResponseBodypublic Map&lt;String, Object&gt; noAnnotation(Integer intVal, Long longVal, String string) &#123; Map&lt;String, Object&gt; paramsMap = new HashMap&lt;&gt;(); paramsMap.put("intVal", intVal); paramsMap.put("longVal", longVal); paramsMap.put("str", string); return paramsMap;&#125; 使用 @RequestParam 获取参数12345678910111213141516171819/** * 通过注解 @RequestParam 获取参数 * @param intVal —— 整数 * @param longVal —— 长整型 * @param strVal —— 字符串，在默认情况下，标注的参数是不能为空的，为了能让它为空，可以配置其属性 required 为 false * @return 响应 JSON 数据集 */@GetMapping("/annotation")@ResponseBodypublic Map&lt;String, Object&gt; requestParam( @RequestParam("int_val") Integer intVal, @RequestParam("long_val") Long longVal, @RequestParam(value = "str_val", required = false) String strVal) &#123; Map&lt;String, Object&gt; paramsMap = new HashMap&lt;&gt;(); paramsMap.put("intVal", intVal); paramsMap.put("longVal", longVal); paramsMap.put("strVal", strVal); return paramsMap;&#125; 传递数组12345678910@GetMapping("/requestArray")@ResponseBodypublic Map&lt;String, Object&gt; requestArray( int[] intArr, Long[] longArr, String[] strArr) &#123; Map&lt;String, Object&gt; paramsMap = new HashMap&lt;&gt;(); paramsMap.put("intArr", intArr); paramsMap.put("longArr", longArr); paramsMap.put("strArr", strArr); return paramsMap;&#125; 传递 JSON方法的参数标注为 @RequestBody，意味着它将接受前端提交的 JSON 请求体，在 JSON 请求体与 User 类之间的属性名称保持一致的 1234567891011/** * 新增用户 * @param user 通过 @RequestBody 注解得到 JSON 参数 * @return 回填 id 后的用户信息 */@PostMapping("/insert")@ResponseBodypublic User insert(@RequestBody User user) &#123; userService.insertUser(user); return user;&#125; 通过 URL 传递参数12345@GetMapping("/&#123;id&#125;")@ResponseBodypublic User get(@PathVariable("id") Long id) &#123; return userService.getUser(id);&#125; 首先通过 @GetMapping 指定一个 URL，然后用 {…} 来标明参数的位置和名称，这里指定名称为 id，Spring MVC 就会根据请求去匹配这个方法；@PathVariable 配置的字符串为 id，它对应 URL 的参数声明，这样 Spring 就知道如何从 URL 中获取参数。 获取格式化参数12345678910@PostMapping("/format/commit")@ResponseBodypublic Map&lt;String, Object&gt; format( @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) Date date, @NumberFormat(pattern = "#,###,##") Double number) &#123; Map&lt;String, Object&gt; dataMap = new HashMap&lt;&gt;(); dataMap.put("date", date); dataMap.put("number", number); return dataMap;&#125; @DateTimeFormat 和 @NumberFormat 配置了格式话所约定的格式 在 Spring Boot 中，日期参数的格式化也可以不使用 @DateTimeFormat，而只在配置文件 application.properties 中加入如下配置： spring.mvc.date-format=yyyy-MM-dd 自定义参数转换规则处理器获取参数逻辑HttpMessageConverter 接口 1234567891011121314151617public interface HttpMessageConverter&lt;T&gt; &#123; // 是否可读，其中 clazz 为 Java 类型，mediaType 为 HTTP 请求类型 boolean canRead(Class&lt;?&gt; var1, @Nullable MediaType var2); // 判断 clazz 类型是否能够转换为 mediaType 媒体类型 // 其中 clazz 为 java 类型，mediaType 为 HTTP 响应类型 boolean canWrite(Class&lt;?&gt; var1, @Nullable MediaType var2); // 可支持的媒体类型列表 List&lt;MediaType&gt; getSupportedMediaTypes(); // 当 canRead 验证通过后，读入 HTTP 请求信息 T read(Class&lt;? extends T&gt; var1, HttpInputMessage var2) throws IOException, HttpMessageNotReadableException; // 当 canWrite 方法验证通过后，写入响应 void write(T var1, @Nullable MediaType var2, HttpOutputMessage var3) throws IOException, HttpMessageNotWritableException;&#125; 在 Spring MVC 中，是通过 WebDataBinder 机制来获取参数的，作用是解析 HTTP 请求上下文，在控制器的调用之前，转换参数并且提供验证的功能，为调用控制器方法做准备； 处理器会从 HTTP 请求中读取数据，然后通过三类接口进行各类参数转换，分别是 Converter，Formatter 和 GenericConverter Spring MVC 处理器 HTTP 请求体转换流程图 Convert：是一个普通的转换器 Formatter：是一个格式转换器 GenericConverter：将 HTTP 参数转换为数组 ConversionService 转化机制设计 Spring Boot 的自动注册机制 1234567891011121314151617@Overridepublic void addFormatters(FormatterRegistry registry) &#123; // 遍历 IoC 容器，找到 Converter 类型的 Bean 注册到服务类中 for (Converter&lt;?, ?&gt; converter : getBeansOfType(Converter.class)) &#123; registry.addConverter(converter); &#125; // 遍历 IoC 容器，找到 GenericConverter 类型的 Bean 注册到服务类中 for (GenericConverter converter : getBeansOfType(GenericConverter.class)) &#123; registry.addConverter(converter); &#125; // 遍历 IoC 容器，找到 Formatter 类型的 Bean 注册到服务类中 for (Formatter&lt;?&gt; formatter : getBeansOfType(Formatter.class)) &#123; registry.addFormatter(formatter); &#125;&#125; Spring Boot 初始化时，会将对应用户自定义的 Converter，Formatter 和 GenericConverter 的实现类所创建的 Spring Bean 自动的注册到 DefaultFormattingConversionService 对象中。 数据验证JSR-303 验证1234567891011121314151617181920212223242526272829303132333435public class ValidatorPojo &#123; /** * 非空判断 */ @NotNull(message = "id不能为空") private Long id; @Future(message = "需要一个将来日期") // 只能是将来的日期 @DateTimeFormat(pattern = "yyyy-MM-dd") // 日期格式化 @NotNull // 不能为空 private Date date; @NotNull @DecimalMin(value = "0.1") // 最小值 0.1 元 @DecimalMax(value = "10000.00") // 最大值为 10000 元 private Double doubleValue = null; @Min(value = 1, message = "最小值为1") // 最小值为 1 @Max(value = 38, message = "最大值为88") // 最大值为 88 @NotNull private Integer integer; @Range(min = 1, max = 888, message = "范围为1至888") // 限定范围 private Long range; /** * 邮箱验证 */ @Email(message = "邮箱格式错误") private String email; @Size(min = 20, max = 30, message = "字符串长度还要求20到30之间") private String size;&#125; 后台验证方法 12345678910111213141516171819202122232425262728293031/** * 解析验证参数错误 * @param vp —— 需要验证的 POJO，使用注解 @Valid 表示验证 * @param errors —— 错误信息，它由 Spring MVC 通过验证 POJO 后自动填充 * @return 错误信息 */@ResponseBody@RequestMapping("/valid/validate")public Map&lt;String, Object&gt; validate( @Valid @RequestBody ValidatorPojo vp, Errors errors) &#123; Map&lt;String, Object&gt; errMap = new HashMap&lt;&gt;(); // 获取错误列表 List&lt;ObjectError&gt; oes = errors.getAllErrors(); for (ObjectError oe : oes) &#123; String key = null; String msg = null; // 字段错误 if (oe instanceof FieldError) &#123; FieldError fe = (FieldError) oe; key = fe.getField(); // 获取错误验证字段名 &#125; else &#123; // 非字段错误 key = oe.getObjectName(); // 获取验证对象名称 &#125; // 错误信息 msg = oe.getDefaultMessage(); errMap.put(key, msg); &#125; return errMap;&#125; @ResponseBody 代表接收一个 JSON 参数，然后 @Valid 注解则表示启动验证机制，Spring 就会启用 JSR-303 验证机制进行验证，自动地将最后的验证结果放入 Errors 对象中； 参数验证机制验证接口定义 12345678910111213141516public interface Validator &#123; /** * 判定当前验证器是否支持该 Class 类型的验证 * @param clazz —— POJO 类型 * @return 当前验证器是否支持该 POJO 验证 */ boolean supports(Class&lt;?&gt; clazz); /** * 如果 supports 返回 true，则这个方法执行验证逻辑 * @param target 被验证 POJO 对象 * @param errors 错误对象 */ void validate(Object target, Errors errors);&#125; supports 方法参数为需要验证的 POJO 类型，如果该方法返回 true，则 Spring 会使用当前验证器的 validate 方法验证 POJO； validate 方法包含需要的 target 对象和错误对象 errors，其中 target 是参数绑定后的 POJO，可以通过这个参数对象进行业务逻辑的自定义验证，如果发现错误，则保存到 errors 对象中，返回给控制器； 自定义用户验证器 1234567891011121314151617181920212223242526public class UserValidator implements Validator &#123; // 验证只支持 User 类验证 @Override public boolean supports(Class&lt;?&gt; clazz) &#123; return clazz.equals(User.class); &#125; // 验证逻辑 @Override public void validate(Object target, Errors errors) &#123; // 对象为空 if (target == null) &#123; // 直接在参数出报错，这样就不能进入控制器的方法 errors.rejectValue("", null, "用户不能为空"); return; &#125; // 强制转换 User user = (User) target; // 用户名非空串 if (StringUtils.isEmpty(user.getUserName())) &#123; // 增加错误，可以进入控制器方法 errors.rejectValue("userName", null, "用户名不能为空"); &#125; &#125;&#125; Spring MVC 中提供了一个注解 @InitBinder，他的作用是在执行控制器方法前，处理器会限制性被 @InitBinder 标注的方法。这是可以将 WebDataBinder 对象最为参数传递到方法中，得到 WebDataBinder 对象，该对象有 setValidator方法，可以绑定自定义的验证器，在获取参数后，通过自定义的验证器去验证参数。 视图和视图解析器视图设计123456789101112131415161718192021public interface View &#123; // 响应状态属性 String RESPONSE_STATUS_ATTRIBUTE = View.class.getName() + ".responseStatus"; // 路径变量 String PATH_VARIABLES = View.class.getName() + ".pathVariables"; // 选择内容类型 String SELECTED_CONTENT_TYPE = View.class.getName() + ".selectedContentType"; // 响应类型 @Nullable default String getContentType() &#123; return null; &#125; // 渲染方法 void render(@Nullable Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception;&#125; getContentType 方法是获取 HTTP 响应类型，它可以返回的类型是文本，JSON 数据集或者文件等 render 方法则是将数据模型渲染到视图的，model 参数是数据类型， Spring MVC 常用视图关系模型]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day07）]]></title>
    <url>%2F2019%2F05%2F09%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day07%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Pat Kay on Unsplash Spring MVC 流程流程和组件是 Spring MVC 的核心，Spring MVC的流程是围绕 DispatcherServlet 而工作的，所以在 Spring MVC 中DispatcherServlet 就是其中最重要的内容； Spring MVC 全流程 1234567891011121314151617181920212223242526272829@Controller@RequestMapping("/user")public class UserController &#123; /** * 注入用户服务类型 */ @Autowired private UserService userService; /** * 展示用户详情 * @param id * @return */ @RequestMapping("/details") public ModelAndView details(Long id) &#123; // 访问模型层得到数据 User user = userService.getUser(id); // 模型和视图 ModelAndView mv = new ModelAndView(); // 定义模型视图 mv.setViewName("user/details"); // 加入数据模型 mv.addObject("user", user); // 返回模型和视图 return mv; &#125;&#125; @Controller 表示这是一个控制器，@RequestMapping 代表请求路径和控制器的映射关系，会在 Web 服务器启动 Spring MVC 时，就被扫描到 HandlerMapping 的机制中存储，之后在用户发起请求被 DispatcherServlet 拦截后，通过 URI 和其他条件，通过 HandlerMapping 机制就能找到对应的控制器进行响应。只是通过 HandlerMapping 返回的是一个 HandlerExecutionChain 对象； HandlerExecutionChain 源码 123456789101112131415161718192021public class HandlerExecutionChain &#123; // 日志 private static final Log logger = LogFactory.getLog(HandlerExecutionChain.class); // 处理器 private final Object handler; // 拦截器数组 @Nullable private HandlerInterceptor[] interceptors; // 拦截器列表 @Nullable private List&lt;HandlerInterceptor&gt; interceptorList; // 拦截器当前下标 private int interceptorIndex = -1; ......&#125; HandlerExecutionChain 对象包含一个处理器，这里处理器是对控制器的包装。处理器包含了控制器方法的逻辑，此外还有处理器的拦截器，这样就能够通过拦截器进一步地增强处理器的功能； 还需要一个适配器去运行 HandlerExecutionChain 对象包含的处理器，就是 HandlerAdapter 的实现类 HttpRequesHandlerAdapter，通过请求类型，DispatcherServlet 就会找到它来执行 Web 请求的 HandlerExecutionChain 对象包含的内容 通过 application.properties 定制 InternalResourceViewResolver 初始化 12spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jsp 通过修改配置文件，就能在 Spring Boot 的机制下定制 InternalResourceViewResolver 这个视图解析器的初始化 （注：踩坑 —— 在项目编译的时候，springboot 好像没有支持 jsp，要手动在 pom.xml 里面添加以下内容） 12345![实例在SpringMVC下的流程图](D:\Blog\myblog\source\_posts\SpringBoot学习笔记（Day07）\实例在SpringMVC下的流程图.jpg)&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 实例在 Spring MVC 下的流程图 使用 JSON 视图 12345678910111213@RequestMapping("/detailsForJson")public ModelAndView detailsForJson(Long id) &#123; // 访问模型层得到数据 User user = userService.getUser(id); // 模型和视图 ModelAndView mv = new ModelAndView(); // 生成 JSON 视图 MappingJackson2JsonView jsonView = new MappingJackson2JsonView(); mv.setView(jsonView); // 加入模型 mv.addObject("user", user); return mv;&#125; 在 Spring MVC 流程中使用 JSON 视图 定制 Spring MVC 初始化12345678910111213141516171819202122232425262728293031323334353637383940414243# 异步请求超时时间spring.mvc.async.request-timeout=# 是否使用请求参数（默认参数为 &quot;format&quot;）来确定请求的媒体类型spring.mvc.contentnegotiation.favor-parameter=false# 是否使用 URL 中的路径扩展来确定请求的媒体类型spring.mvc.contentnegotiation.favor-path-extension=false# 设置内容协商向媒体类型映射文件扩展名，例如，YML文本 / YAMLspring.mvc.contentnegotiation.media-types.*=# 当启用 favor-parameter 参数时，自定义参数名spring.mvc.contentnegotiation.parameter-name=# 日期格式配置，入 yyyy-MM-ddspring.mvc.date-format=# 是否让 FrameworkServlet doService 方法支持 TRACE 请求spring.mvc.dispatch-trace-request=false# 是否启用 FrameworkServlet doService 方法支持 OPTIONS 请求spring.mvc.dispatch-options-request=true# spring MVC 的图标是否启用spring.mvc.favicon.enabled=true# Servlet 规范要求表格数据可用于 HTTP POST 而不是 HTTP PUT 或 PATCH 请求，这个选项将使得过滤器拦截 HTTP PUT 和 PATCH，且内容类型是 application/x-www-form-urlencoded 的请求，并且将其转换为 POST 请求spring.mvc.formcontent.filter.enabled=true# 如果配置为 default，那么他将忽略模型重定向的场景spring.mvc.ignore-default-model-on-redirect=true# 默认国际化选项，默认取 Accept-Languagespring.mvc.locale=# 国际化解析器，如果需要固定可以使用 fixedspring.mvc.locale-resolver=accept_header# 是否启用警告日志异常解决spring.mvc.log-resolved-exception=false# 消息代码的格式化策略。例如 &apos; prefix_error_code &apos;spring.mvc.message-codes-resolver-format=# 是否对 spring.mvc.contentnegotiation.media-types.* 注册的扩展采用后缀模式匹配spring.mvc.pathmatch.use-registered-suffix-pattern=false# 当匹配模式到请求时，是否使用后缀模式匹配（.*）spring.mvc.pathmatch.use-suffix-pattern=false# 启用 Spring Web 服务 Servlet 的优先顺序配置spring.mvc.servlet.load-on-startup=-1# 指定静态资源路径spring.mvc.static-path-pattern=/**# 如果请求找不到处理器，是否抛出 NoHandlerFoundException 异常spring.mvc.throw-exception-if-no-handler-found=falsespring.mvc.view.prefix=spring.mvc.view.suffix= 这些配置项将会被 Spring Boot 的机制读入，然后使用 WebMVCAutoConfigurationAdapter 去定制初始化]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day06）]]></title>
    <url>%2F2019%2F05%2F08%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day06%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Marion Michele on Unsplash Redis 的一些特殊用法使用 Redis 事务watch 命令：监控 Redis 的一些键； multi 命令：是开始事务，开始事务后，该客户端的命令不会马上执行，而是存放在一个队列里面； exec 命令：执行事务，在队列命令执行前会判断被 watch 监控的 Redis 键的数据是否发生过变化，如果发生变化，Redis 就会取消事务； Redis 事务执行过程 通过 Spring 使用 Redis 事务机制 12345678910111213141516171819202122232425262728@RequestMapping("/multi")@ResponseBodypublic Map&lt;String, Object&gt; testMulti() &#123; redisTemplate.opsForValue().set("key1", "value1"); List list = (List) redisTemplate.execute(new SessionCallback() &#123; @Override public Object execute(RedisOperations operations) throws DataAccessException &#123; // 设置要监控key1 operations.watch("key1"); // 开启事务，在exec命令执行前，全部都只是进入队列 operations.multi(); operations.opsForValue().set("key2", "value2"); // operations.opsForValue().increment("key1", 1);// ① // 获取值将为null，因为redis只是把命令放入队列， Object value2 = operations.opsForValue().get("key2"); System.out.println("命令在队列，所以value为null【" + value2 + "】"); operations.opsForValue().set("key3", "value3"); Object value3 = operations.opsForValue().get("key3"); System.out.println("命令在队列，所以value为null【" + value3 + "】"); // 执行exec命令，将先判别key1是否在监控后被修改过，如果是不执行事务，否则执行事务 return operations.exec();// ② &#125; &#125;); System.out.println(list); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("success", true); return map;&#125; Redis 处理事务和数据库事务不同，Redis 事务先让命令进入已有队列，所以一开始并没有检测错误命令是否能执行成功，只有在 exec 命令执行的时候，才能发现错误，对于出错的命令 Redis 只是报出错误，而错误后面的命令依旧被执行，这就是 Redis 事务的特点，也是使用 Redis 事务需要特别注意的地方； 使用 Redis 流水线一次性发送多条执行命令 使用 Redis 流水线测试性能 1234567891011121314151617181920212223@RequestMapping("/multi")@ResponseBodypublic Map&lt;String, Object&gt; testMulti() &#123; Long start = System.currentTimeMillis(); List list = (List) redisTemplate.execute(new SessionCallback() &#123; @Override public Object execute(RedisOperations operations) throws DataAccessException &#123; for (int i = 1; i &lt;= 100000; i++) &#123; operations.opsForValue().set("pipeline_" + i, "value_" + i); String value = (String) operations.opsForValue().get("pipeline_" + i); if (i == 100000) &#123; System.out.println("命令只是进入队列，所以值为空【" + value + "】"); &#125; &#125; return null; &#125; &#125;); Long end = System.currentTimeMillis(); System.out.println("耗时：" + (end - start) + "毫秒。"); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("success", true); return map;&#125; 使用 Redis 发布订阅发布订阅是消息的一种常用模式，Redis 先提供一个渠道，让消息能够发送到这个渠道上，多个系统可以监听这个渠道，当一条消息发送到渠道，渠道就会通知它的监听者，这些监听者就会根据自己的需要去处理这个消息 发布订阅模式 Redis 消息监听器 123456789101112131415161718@Componentpublic class RedisMessageListener implements MessageListener &#123; /** * onMessage 方法是得到消息后的处理方法 * @param message 代表 Redis 发送过来的消息 * @param pattern 渠道名称 */ @Override public void onMessage(Message message, byte[] pattern) &#123; // 消息体 String body = new String(message.getBody()); // 渠道名称 String topic = new String(pattern); System.out.println(body); System.out.println(topic); &#125;&#125; 使用 Spring 缓存注解操作 Redis缓存管理器和缓存的启用缓存管理器配置 1234567891011121314151617181920212223# SPRING CACHE (CacheProperties)# 如果由底层的缓存管理器支持创建，以逗号分隔的列表来缓存名称spring.cache.cache-names=# caffeine 缓存配置细节spring.cache.caffeine.spec=# couchbase 缓存超时时间，默认是永不超时spring.cache.couchbase.expiration=0ms# 配置 ehcache 缓存初始化文件路径spring.cache.infinispan.config=# jcache 缓存配置文件spring.cache.jcache.config=# jcache 缓存提供者配置spring.cache.jcache.provider=# 是否允许 Redis 缓存空值spring.cache.redis.cache-null-values=true# Redis 的键前缀spring.cache.redis.key-prefix=# 缓存超时时间戳，配置为0则不设置超时时间spring.cache.redis.time-to-live=0ms# 是否启用 Redis 的键前缀spring.cache.redis.use-key-prefix=true# 缓存类型，在默认的情况下，Spring 会自动根据上下文探测spring.cache.type= 用户实现类使用 Spring 缓存注解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserDao userDao = null; @Override @Transactional @Cacheable(value = "redisCache", key = "'redis_user_' + #id") public User getUser(Long id) &#123; return userDao.getUser(id); &#125; @Override @Transactional @CachePut(value = "redisCache", key = "'redis_user_' + #result.id") public User insertUser(User user) &#123; userDao.insertUser(user); return user; &#125; @Override @Transactional @CachePut(value = "redisCache", condition = "#result != 'null'", key = "'redis_user_' + #id") public User updateUserName(Long id, String userName) &#123; // 此处调用 getUser 方法，该方法缓存注解失效 // 所以这里还会执行 SQL，将查询到数据库最近数据 User user = this.getUser(id); if (user == null) &#123; return null; &#125; user.setUserName(userName); userDao.updateUser(user); return user; &#125; @Override @Transactional public List&lt;User&gt; findUsers(String userName, String note) &#123; return userDao.findUsers(userName, note); &#125; @Override @Transactional @CacheEvict(value = "redisCache", key = "'redis_user_' + #id", beforeInvocation = false) public int deleteUser(Long id) &#123; return userDao.deleteUser(id); &#125;&#125; @CachePut 表示将方法结果返回存放到缓存中 @Cacheable 表示先从缓存中通过定义的键查询，如果可以查询到数据，则返回，否则执行方法，返回数据，并且将返回结果保存到缓存中 @CacheEvict 通过定义的键移除缓存，它有一个 Boolean 类型的配置项 beforeInvocation，表示在方法之前或者之后移除缓存，false代表方法之后将缓存移除 自定义缓存管理器12345678# 禁用前缀spring.cache.redis.use-key-prefix=false# 允许保存空值# spring.cache.redis.cache-null-values=true# 自定义前缀# spring.cache.redis.key-prefix=# 定义超时时间，单位毫秒spring.cache.redis.time-to-live=600000 自定义缓存管理器 12345678910111213141516171819@Autowiredprivate RedisConnectionFactory connectionFactory = null;@Bean(name = "redisCacheManager")public RedisCacheManager initRedisCacheManager() &#123; // Redis 加锁的写入器 RedisCacheWriter writer = RedisCacheWriter.lockingRedisCacheWriter(connectionFactory); // 启动 Redis 序列化器 RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig(); // 设置 JDK 序列化器 config = config.serializerValuesWith(SerializationPair.fromSerializer(new JdkSerializationRedisSerializer())); // 禁用前缀 config = config.disableKeyProfix(); // 设置 10min 超时 config = config.entryTtl(Duration.ofMinutes(10)); // 创建缓存 Redis 管理器 RedisCacheManager redisCacheManager = new RedisCacheManager(writer, config); return redisCacheManager;&#125; 首先注入 RedisConnectionFactory 对象； 创建带锁的 RedisCacheWriter； 使用 RedisCacheConfiguration 对 RedisCacheWriter 属性进行配置（禁用前缀，设置超时时间为 10min）； 用 RedisCacheWriter 对象和 RedisCacheConfiguration 对象构建 RedisCacheManager 对象；]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day05）]]></title>
    <url>%2F2019%2F05%2F07%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day05%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Ruud Luijten on Unsplash spring-data-redis 项目介绍spring-data-redis 项目设计Spring 提供了一个 RedisConnectionFactory 接口，通过它可以生成一个 RedisConnection 接口对象，而 RedisConnection 是 Redis 底层接口的封装，如使用 Jedis，Spring 就会提供 RedisConnection 接口的实现类 JedisConnection 去封装原有的 Jedis； RedisTemplateRedisTemplate 是一个强大的类，首先他会自动从 RedisConnectionFactory 工厂中获取连接，执行对应的 Redis 命令，在最后还会关闭 Redis 的连接； Spring 序列化器Spring 序列化器用于转储 Java 对象到 Redis 中，因为 Redis 是一种基于字符串存储的 NoSQL，对象无法存储到 Redis 中，只有通过序列化器转换为二进制字符串才能存储 属性 描述 备注 defaultSerializer 默认序列化器 如果没有配置，则使用 JdkSerializationRedisSerializer keySerializer Redis 键序列化器 如果没有配置，则使用默认序列化器 valueSerializer Redis 值序列化器 如果没有配置，则使用默认序列化器 hashKeySerializer Redis 散列结构 field 序列化器 如果没有配置，则使用默认序列化器 hashValueSerializer Redis 散列结构 value 序列化器 如果没有配置，则使用默认序列化器 stringSerializer 字符串序列化器 RedisTemplate 自动赋值为 StringRedisSerializer 对象 Spring 对 Redis 数据类型操作的封装spring-data-redis 数据类型封装操作接口 操作接口 功能 备注 GeoOperations 地理位置操作接口 使用不多 HashOperations 散列操作接口 HyperLogLogOperations 基数操作接口 使用不多 ListOperations 列表（链表）操作接口 SetOperations 集合操作接口 ValueOperations 字符串操作接口 ZSetOperations 有序集合操作接口 都可以通过 RedisTemplate 得到，代码如下： 1234567891011121314// 获取地理位置操作接口redisTemplate.opsForGeo();// 获取散列操作接口redisTemplate.opsForHash();// 获取基数操作接口redisTemplate.opsForHyperLogLog();// 获取列表操作接口redisTemplate.opsForList();// 获取集合操作接口redisTemplate.opsForSet();// 获取字符串操作接口redisTemplate.opsForValue();// 获取有序集合操作接口redisTemplate.opsForZSet(); 有事需要连续操作一个散列数据类型或者列表多次，这时 Spring 也提供支持，它提供了对应的 BoundXXXOperation 绑定接口： 接 口 说 明 BoundGeoOperations 绑定一个地理位置数据类型的键操作，不常用 BoundHashOperations 绑定一个散列数据类型的键操作 BoundListOperations 绑定一个列表（链表）数据类型的键操作 BoundSetOperations 绑定一个集合数据类型的键操作 BoundValueOperations 绑定一个字符串集合数据类型的键操作 BoundZSetOperations 绑定一个有序集合数据类型的键操作 RedisTemplate 对获取它们提供了对应的方法： 123456789101112// 获取地理位置绑定键操作接口redisTemplate.boundGeoOps();// 获取散列绑定键操作接口redisTemplate.boundHashOps();// 获取列表（链表）绑定键操作接口redisTemplate.boundListOps();// 获取集合绑定键操作接口redisTemplate.boundSetOps();// 获取字符串绑定键操作接口redisTemplate.boundValueOps();// 获取有序集合绑定键操作接口redisTemplate.boundZSetOps(); SessionCallback 和 RedisCallback 接口作用是让 RedisTemplate 进行回调，通过它们可以在同一条连接下执行多个 Redis 命令； 在 Spring Boot 中配置和使用 Redis在 Spring Boot 中配置 Redis123456789101112# 配置连接池属性spring.redis.jedis.pool.min-idle=5spring.redis.jedis.pool.max-active=10spring.redis.jedis.pool.max-idle=10spring.redis.jedis.pool.max-wait=2000# 配置 Redis 服务器属性spring.redis.port=6379spring.redis.host=192.168.11.154# 由于我的 Redis 服务器没有设置密码就没下下面的配置了# spring.redis.password# Redis 连接超时时间，单位毫秒spring.redis.timeout=1000 操作 Redis 字符串和散列数据类型 12345678910111213141516171819202122232425262728293031323334353637383940@Controller@RequestMapping("/redis")public class RedisController &#123; @Autowired private RedisTemplate redisTemplate = null; @Autowired private StringRedisTemplate stringRedisTemplate = null; @RequestMapping("/stringAndHash") @ResponseBody public Map&lt;String, Object&gt; testStringAndHash() &#123; redisTemplate.opsForValue().set("key1", "value1"); redisTemplate.opsForValue().set("int_key", "1"); stringRedisTemplate.opsForValue().set("int", "1"); // 使用运算 stringRedisTemplate.opsForValue().increment("int", 1); // 获取底层 Jedis 连接 Jedis jedis = (Jedis) stringRedisTemplate.getConnectionFactory().getConnection().getNativeConnection(); // 减1操作，这个命令 RedisTemplate 不支持，所以先获取底层连接再操作 jedis.decr("int"); Map&lt;String, String&gt; hash = new HashMap&lt;&gt;(); hash.put("field1", "value1"); hash.put("field2", "value2"); // 存入一个散列数据类型 stringRedisTemplate.opsForHash().putAll("hash", hash); // 新增一个字段 stringRedisTemplate.opsForHash().put("hash", "field3", "value3"); // 绑定散列操作的key，这样可以连续对同一个散列数据类型进行操作 BoundHashOperations hashOps = stringRedisTemplate.boundHashOps("hash"); // 删除两个字段 hashOps.delete("field1", "field2"); // 新增一个字段 hashOps.put("field5", "value5"); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("success", true); return map; &#125;&#125; 使用 Spring 操作列表（链表） 123456789101112131415161718192021222324252627282930313233343536373839@Controller@RequestMapping("/redis")public class RedisController &#123; @Autowired private RedisTemplate redisTemplate = null; @Autowired private StringRedisTemplate stringRedisTemplate = null; @RequestMapping("/list") @ResponseBody public Map&lt;String, Object&gt; testList() &#123; // 插入两个列表，注意它们在链表的顺序 // 链表从左到右顺序为v10，v8，v6，v4，v2 stringRedisTemplate.opsForList().leftPushAll( "list1", "v2", "v4", "v6", "v8", "v10" ); // 链表从左到右顺序为v1, v2, v3, v4, v5, v6 stringRedisTemplate.opsForList().rightPushAll( "list2", "v1", "v2", "v3", "v4", "v5", "v6" ); // 绑定 list2 链表操作 BoundListOperations listOps = stringRedisTemplate.boundListOps("list2"); // 从右边弹出一个成员 Object result1 = listOps.rightPop(); // 获取定位元素，Redis 从 0 开始计算，这里值为 v2 Object result2 = listOps.index(1); // 从左边插入链表 listOps.leftPush("v0"); // 求链表长度 Long size = listOps.size(); // 求链表下标区间成员，整个链表下标范围为 0 到 size-1，这里不取最后一个元素 List elements = listOps.range(0, size - 2); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("success", true); return map; &#125;&#125; 使用 Spring 集合 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Controller@RequestMapping("/redis")public class RedisController &#123; @Autowired private RedisTemplate redisTemplate = null; @Autowired private StringRedisTemplate stringRedisTemplate = null; @RequestMapping("/set") @ResponseBody public Map&lt;String, Object&gt; testSet() &#123; // 请注意：这里 v1 重复两次，因为集合不允许重复，所以只是插入 5 个成员到集合中 stringRedisTemplate.opsForSet().add( "set1", "v1", "v1", "v2", "v3", "v4", "v5" ); stringRedisTemplate.opsForSet().add( "set2", "v2", "v4", "v6", "v8" ); // 绑定 set1 集合操作 BoundSetOperations setOps = stringRedisTemplate.boundSetOps("set1"); // 增加两个元素 setOps.add("v6", "v7"); // 删除两个元素 setOps.remove("v1", "v7"); // 返回所有元素 Set set1 = setOps.members(); // 求成员数 Long size = setOps.size(); // 求交集 Set inter = setOps.intersect("set2"); // 求交集，并且用新集合 inter 保存 setOps.intersectAndStore("set2", "inter"); // 求差集 Set diff = setOps.diff("set2"); // 求差集，并且用新集合 diff 保存 setOps.diffAndStore("set2", "diff"); // 求并集 Set union = setOps.union("set2"); // 求并集，并且用新集合 union 保存 setOps.unionAndStore("set2", "union"); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("success", true); return map; &#125;&#125; 操作 Redis 有序集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Controller@RequestMapping("/redis")public class RedisController &#123; @Autowired private RedisTemplate redisTemplate = null; @Autowired private StringRedisTemplate stringRedisTemplate = null; @RequestMapping("/zset") @ResponseBody public Map&lt;String, Object&gt; testZSet() &#123; Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; typedTupleSet = new HashSet&lt;&gt;(); for (int i = 1; i &lt;= 9; i++) &#123; // 分数 double score = i * 0.1; // 创建一个 TypeTuple 对象，存入值和分数 ZSetOperations.TypedTuple&lt;String&gt; typedTuple = new DefaultTypedTuple&lt;&gt;("value" + i, score); typedTupleSet.add(typedTuple); &#125; // 往有序集合插入元素 stringRedisTemplate.opsForZSet().add("zset1", typedTupleSet); // 绑定 zset1 有序集合操作 BoundZSetOperations&lt;String, String&gt; zsetOps = stringRedisTemplate.boundZSetOps("zset1"); // 增加一个元素 zsetOps.add("value10", 0.26); Set&lt;String&gt; setRange = zsetOps.range(1, 6); // 按分数排序获取有序集合 Set&lt;String&gt; setScore = zsetOps.rangeByScore(0.2, 0.6); // 定义值范围 Range range = new Range(); range.gt("value3"); range.lte("value8"); // 按值排序，请注意这个排序是按字符串排序 Set&lt;String&gt; setLex = zsetOps.rangeByLex(range); // 删除元素 zsetOps.remove("value9", "value2"); // 求分数 Double score = zsetOps.score("value8"); // 在下标区间下，按分数排序，同时返回 value 和 score Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; rangeSet = zsetOps.rangeWithScores(1, 6); // 在分数区间下，按分数排序，同时返回 value 和 score Set&lt;ZSetOperations.TypedTuple&lt;String&gt;&gt; scoreSet = zsetOps.rangeByScoreWithScores(1, 6); // 按从大到小排序 Set&lt;String&gt; reverseSet = zsetOps.reverseRange(2, 8); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("success", true); return map; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记（Day06）]]></title>
    <url>%2F2019%2F05%2F06%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day06%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Sid Verma on Unsplash Jedis所需 jar 包： commons-pool jedis 测试连接测试代码： 1234567public class TestPing &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis("192.168.11.154", 6379); System.out.println(jedis.ping()); &#125;&#125; 如果不是在 Linux 上直接运行代码，而是在 Windows 上远程连接，就会报错，解决方案： 注释配置文件的 bind 127.0.0.1 将保护模式后面的 yea 改为 no 如下： 123456789101112131415161718192021222324# JUST COMMENT THE FOLLOWING LINE.# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# 把这里的 bind 注释掉# bind 127.0.0.1# Protected mode is a layer of security protection, in order to avoid that# Redis instances left open on the internet are accessed and exploited.## When protected mode is on and if:## 1) The server is not binding explicitly to a set of addresses using the# &quot;bind&quot; directive.# 2) No password is configured.## The server only accepts connections from clients connecting from the# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain# sockets.## By default protected mode is enabled. You should disable it only if# you are sure you want clients from other hosts to connect to Redis# even if no authentication is configured, nor a specific set of interfaces# are explicitly listed using the &quot;bind&quot; directive.# 把保护模式关掉或者添加密码 测试的话直接关掉 省得麻烦protected-mode no Jedis 操作数据1234567891011121314public class TestAPI &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis("192.168.11.154", 6379); jedis.set("k1", "v1"); jedis.set("k2", "v2"); jedis.set("k3", "v3"); System.out.println(jedis.get("k1")); Set&lt;String&gt; sets = jedis.keys("*"); System.out.println(sets.size()); &#125;&#125; Jedis 事务测试代码： 12345678910111213public class TestTX &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis("192.168.11.154", 6379); Transaction transaction = jedis.multi(); transaction.set("k44", "v44"); transaction.set("k55", "v55"); // transaction.exec(); transaction.discard(); &#125;&#125; 事务案例代码： 12345678910111213141516171819202122232425262728293031323334353637383940public class TestTX &#123; public boolean transMethod() &#123; Jedis jedis = new Jedis("192.168.11.154", 6379); int balance; // 可用余额 int debt; // 欠额 int amtToSubtract = 10; // 实刷额度 jedis.watch("balance"); balance = Integer.parseInt(jedis.get("balance")); if (balance &lt; amtToSubtract) &#123; jedis.unwatch(); System.out.println("modify"); return false; &#125; else &#123; System.out.println("*******************transaction"); Transaction transaction = jedis.multi(); transaction.decrBy("balance", amtToSubtract); transaction.incrBy("debt", amtToSubtract); transaction.exec(); balance = Integer.parseInt(jedis.get("balance")); debt = Integer.parseInt(jedis.get("debt")); System.out.println("*************" + balance); System.out.println("*************" + debt); return true; &#125; &#125; /** * watch 命令就是标记一个键，如果标记了一个键 * 在提交事务前，如果别比人修改过，那事务就会失败 * @param args */ public static void main(String[] args) &#123; TestTX testTX = new TestTX(); boolean retValue = testTX.transMethod(); System.out.println("main retValue ----------- : " + retValue); &#125;&#125; JedisPool 获取 Jedis 实例需要从 JedisPool 中获取 用完 Jedis 实例需要返还给 JedisPool 如果 Jedis 在使用过程中出错，则也需要还给 JedisPool 演示代码： JedisPoolUtil.java 123456789101112131415161718192021222324252627282930public class JedisPoolUtil &#123; private static volatile JedisPool jedisPool = null; private JedisPoolUtil() &#123; &#125; public static JedisPool getJedisPoolInstance() &#123; if (jedisPool == null) &#123; synchronized (JedisPoolUtil.class) &#123; if (null == jedisPool) &#123; JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxActive(1000); poolConfig.setMaxIdle(32); poolConfig.setMaxWait(100 * 1000); poolConfig.setTestOnBorrow(true); jedisPool = new JedisPool(poolConfig, "192.168.11.154", 6379); &#125; &#125; &#125; return jedisPool; &#125; public static void release(JedisPool jedisPool, Jedis jedis) &#123; if (jedis != null) &#123; jedisPool.returnResourceObject(jedis); &#125; &#125;&#125; TestPool.java 12345678910111213141516public class TestPool &#123; public static void main(String[] args) &#123; JedisPool jedisPool = JedisPoolUtil.getJedisPoolInstance(); Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); jedis.set("aa", "bb"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; JedisPoolUtil.release(jedisPool, jedis); &#125; &#125;&#125; 总结： JedisPool 的配置参数大部分是由 JedisPoolConfig 的对应项来赋值的。 maxActive：控制一个pool可分配多少个jedis实例，通过 pool.getResource() 来获取；如果赋值为 -1，则表示不限制；如果 pool 已经分配了 maxActive 个 jedis 实例，则此时 pool 的状态为 exhausted； maxIdle：控制一个 pool 最多有多少个状态为 idle（空闲）的 jedis 实例； whenExhaustedAction：表示当 pool 中的 jedis 实例都被 allocated 完时，pool 要采取的操作；默认有三种： WHEN_EXHAUSTED_FAIL –&gt; 表示无 jedis 实例时，直接抛出 NoSuchElementException； WHEN_EXHAUSTED_BLOCK –&gt; 则表示阻塞住，或者达到 maxWait 时抛出 JedisConnectionException； WHEN_EXHAUSTED_GROW –&gt; 则表示新建一个 jedis 实例，也就说设置的 maxActive 无用； maxWait：表示当borrow一个 jedis 实例时，最大的等待时间，如果超过等待时间，则直接抛 JedisConnectionException； testOnBorrow：获得一个 jedis 实例的时候是否检查连接可用性（ ping() ）；如果为true，则得到的 jedis 实例均是可用的； testOnReturn：return 一个 jedis 实例给pool时，是否检查连接可用性（ping() ）； testWhileIdle：如果为 true，表示有一个 idle object evitor 线程对 idle object 进行扫描，如果 validate 失败，此 object 会被从 pool 中 drop 掉；这一项只有在 timeBetweenEvictionRunsMillis 大于 0 时才有意义； timeBetweenEvictionRunsMillis：表示 idle object evitor 两次扫描之间要 sleep 的毫秒数； numTestsPerEvictionRun：表示 idle object evitor 每次扫描的最多的对象数； minEvictableIdleTimeMillis：表示一个对象至少停留在 idle 状态的最短时间，然后才能被 idle object evitor 扫描并驱逐；这一项只有在 timeBetweenEvictionRunsMillis 大于0时才有意义； softMinEvictableIdleTimeMillis：在 minEvictableIdleTimeMillis 基础上，加入了至少 minIdle 个对象已经在pool里面了。如果为 -1，evicted 不会根据 idle time 驱逐任何对象。如果 minEvictableIdleTimeMillis&gt;0，则此项设置无意义，且只有在 timeBetweenEvictionRunsMillis 大于 0 时才有意义； lifo：borrowObject返回对象时，是采用 DEFAULT_LIFO（last in first out，即类似cache的最频繁使用队列），如果为 False，则表示 FIFO 队列； ==================================================================================================================其中 JedisPoolConfig 对一些参数的默认设置如下：testWhileIdle=trueminEvictableIdleTimeMills=60000timeBetweenEvictionRunsMillis=30000numTestsPerEvictionRun=-1]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记（Day05）]]></title>
    <url>%2F2019%2F05%2F05%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day05%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Martin Adams on Unsplash Redis 事务是什么可以一次执行多个命令，本质是一组命令的集合。一个事务中的，所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞 能干嘛一个队列中，一次性，顺序性，排他性的执行一系列命令 怎么玩常用命令Case1：DISCARD —— 取消事务，放弃事务块内的所有命令 Case2：EXEC —— 执行所有事务块内的命令 Case3：MULTI —— 标记一个事务块的开始 Case4：UNWATCH —— 取消 WATCH 命令对所有 key 的监视 Case5：WATCH —— 监视一个（或多个）key，如果在事务执行之前，这个（或这些）key 被其他命令所改动，那么事务将被打断 悲观锁 悲观锁（Pessimistic Lock）， 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁 乐观锁 乐观锁（Optimistic Lock）， 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量， 乐观锁策略：提交版本必须大于记录当前版本才能执行更新 CAS（Check And Set） 有加塞篡改 监控了key，如果key被修改了，后面一个事务的执行失效 一旦执行了 EXEC 之前加的监控锁都会被取消掉了 Watch 指令，类似乐观锁，事务提交时，如果 Key 的值已被别的客户端改变，比如某个 list 已被别的客户端 push / pop 过了，整个事务队列都不会被执行 通过 WATCH 命令在事务执行之前监控了多个 Keys，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 Nullmulti-bulk 应答以通知调用者事务执行失败 阶段 开启：以MULTI开始一个事务 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面 执行：由EXEC命令触发事务 特性 单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题 不保证原子性：redis 同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 Redis 的发布订阅是什么进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 命令 PSUBSCRIBE pattern [pattern …] 订阅一个或多个符合给定模式的频道 PUBSUB subcommand [argument [argument …]] 查看订阅与发布信息 PUBLISH channel message 将信息发送到指定的频道 PUNSUBSCRIBE [pattern [pattern …]] 退订所有给定模式的频道 SUBSCRIBE channel [channel …] 订阅给定的一个或多个频道信息 UNSUBSCRIBE [channel [channel …]] 指退订给定的频道 案列先订阅后发布后才能收到消息 可以一次性订阅多个，SUBSCRIBE c1 c2 c3 消息发布，PUBLISH c2 hello-redis 订阅多个，通配符，PSUBSCRIBE new 收取消息，PUBLISH new1 redis2015]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记（Day04）]]></title>
    <url>%2F2019%2F05%2F04%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day04%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Berti Benbanaste on Unsplash Redis 持久化RDB（Redis DataBase）是什么在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的 Snapshot 快照，它恢复时是将快照文件直接读到内存里 Redis 会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。 RDB 的缺点是最后一次持久化后的数据可能丢失。 Forkfork 的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 rdb 保存的是dump.rdb文件如何触发RDB快照 配置文件中默认的快照配置 冷拷贝后重新使用（可以cp dump.rdb dump_new.rdb） 命令 save 或者是 bgsave save：save时只管保存，其它不管，全部阻塞 bgsave：Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过 lastsave 命令获取最后一次成功执行快照的时间 执行flushall命令，也会产生dump.rdb文件，但里面是空的，无意义 如何恢复将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可 CONFIG GET dir获取目录 优势 适合大规模的数据恢复 对数据完整性和一致性要求不高 劣势 在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改 fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑 如何停止动态所有停止RDB保存规则的方法：redis-cli config set save “” AOF（Append Only File）是什么以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis 启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作 AOF 保存的是 appendonly.aof 文件AOF启动/修复/恢复正常恢复 修改默认的appendonly no，改为yes 将有数据的aof文件复制一份保存到对应目录(config get dir) 恢复：重启redis然后重新加载 异常恢复 修改默认的appendonly no，改为yes 备份被写坏的AOF文件 redis-check-aof –fix进行修复 恢复：重启redis然后重新加载 rewrite 是什么：AOF 采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制,当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集.可以使用命令 bgrewriteaof 重写原理：AOF 文件持续增长而过大时，会 fork 出一条新进程来将文件重写(也是先写临时文件最后再 rename)，遍历新进程的内存中数据，每条记录有一条的 Set 语句。重写 aof 文件的操作，并没有读取旧的 aof 文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的 aof 文件，这点和快照有点类似 触发机制： Redis 会记录上次重写时的 AOF 大小，默认配置是当AOF文件大小是上次 rewrite 后大小的一倍且文件大于 64M 时触发 优势 每修改同步：appendfsync always——同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好 每秒同步：appendfsync everysec——异步操作，每秒记录 如果一秒内宕机，有数据丢失 不同步：appendfsync no——从不同步 劣势 相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb aof运行效率要慢于rdb,每秒同步策略效率较好，不同步效率和rdb相同]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记（Day03）]]></title>
    <url>%2F2019%2F05%2F03%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day03%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by Chi Liu on Unsplash Redis 配置文件在哪拷贝出来单独执行，原文件在 redis 解压文件目录下 Units 单位 配置大小单位，开头定义了一些基本的度量单位，只支持 bytes，不支持 bit 对大小写不敏感 INCLUDES 包含和 Strust2 配置文件类似，可以通过 includes 包含，redis.conf 可以作为总闸，包含其他 GENERAL 通用 Daemonlize 默认为 no，需要改成 yes Pidfile 进程管道 ID 文件，运行起来如果没指定路径，就使用默认的路径 Port 配置的端口号 Tcp-backlog 设置 tcp 的 backlog，backlog其实是一个连接队列，backlog队列总和 = 未完成三次握手 + 已经完成三次握手队列 在高并发环境下，需要一个高 backlog 值来避免慢客户端连接问题，Linux 内核会将这个值减小到 /proc/sys/net/core/somaxconn 的值，所以需要确认增大 somaxconn 和 tcp_max_syn_backlog 两个值来达到想要的效果 Timeout Bind Tcp-keepalive 单位为秒，如果设置为 0，则不会进行 Keepalive 检测，建议设置成 60 Loglevel 日志级别： debug verbose notice warning Logfile 日志名字 Syslog-enabled 是否把日志输出到 Syslog（默认关） Syslog-ident 指定 Syslog 里的日志标志 Syslog-facility 指定 syslog 设备，只可以是 USER 或 LOCAL0 - LOCAL7（默认LOCAL0） Databases 默认数据库的数量 SNAPSHOTTING 快照 Save（save 秒钟 写操作次数） stop-writes-on-bgsave-error（如果配置成no，表示你不在乎数据不一致或者有其他的手段发现和控制） rdbcompression（rdbcompression：对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis 会采用 LZF 算法进行压缩。如果你不想消耗 CPU 来进行压缩的话，可以设置为关闭此功能） rdbchecksum（rdbchecksum：在存储快照后，还可以让 redis 使用 CRC64 算法来进行数据校验，但是这样做会增加大约 10% 的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能） dbfilename（备份文件名称） dir REPLICATION 复制SECURITY 安全LIMITS 限制 Maxclients Maxmemory Maxmemory-policy Volatile-lru -&gt; remove the key with an expire set using an LRU algorithm（使用 LRU 算法移除 key， 只对设置了过期时间的键） Allkeys-lru -&gt; remove any key according to the LRU algorithm（使用 LRU 算法移除 key） Volatile-random -&gt; remove a random key with an expire set（在过期集合中移除随机的 key，只对设置了过期时间的键） Allkeys-random -&gt; remoce a random key, any key（移除随机的 key） Volatile-ttl -&gt; remove the key with the nearest expire time(minor TTL)（移除那些 TTL 值最小的 key，即那些最近要过期的 key） Noeviction -&gt; don’t expire at all, just return an error on write operations（不进行移除，针对写操作，只是返回错误信息） Maxmemory-samples 设置样本数量，LRU 算法和最小 TTL 算法都并非是精确的算法，而是估算值，所以你可以设置样本的大小，redis 默认会检查这么多个 key 并选择其中 LRU 的那个 APPEND ONLY MODE 追加 appendonly appendfilename appendfsync always：同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好 everysec：出厂默认推荐，异步操作，每秒记录，如果一秒内宕机，有数据丢失 no no-appendfsync-on-rewrite：重写时是否可以运用 Appendfsync，用默认 no 即可，保证数据安全性。 auto-aof-rewrite-min-size：设置重写的基准值 auto-aof-rewrite-percentage：设置重写的基准值 常见配置 redis.conf 介绍参数说明redis.conf 配置项说明如下： Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字 port 6379 绑定的主机地址 bind 127.0.0.15.当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null logfile stdout 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb 指定本地数据库存放目录dir ./ 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof 当master服务设置了密码保护时，slav服务连接master的密码masterauth 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 128 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof 指定更新日志条件，共有3个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）everysec：表示每秒同步一次（折衷，默认值）appendfsync everysec 指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制） vm-enabled no 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap 将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 0 Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值 vm-page-size 32 设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。 vm-pages 134217728 设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 vm-max-threads 4 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启glueoutputbuf yes 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 64hash-max-zipmap-value 512 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）activerehashing yes 指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件include /path/to/local.conf]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记（Day02）]]></title>
    <url>%2F2019%2F05%2F02%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day02%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Photo by John Hoang on Unsplash 入门概述是什么Redis：Remote Dictionary Server（远程字典服务器） 是完全开源免费的，用 C 语言编写，遵循 BSD 协议，是一个高性能的（key / value）分布式内存数据库，基于内存运行并支持持久化的 NoSQL 数据库，是当前最热门的 NoSQL 数据库之一，也被称为数据结构服务器 特点： Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用 Redis 不仅仅支持简单的 key - value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储 Redis 支持数据的备份，即 master - slave 模式的数据备份 能干嘛内存存储和持久化：redis 支持异步将内存中的数据写到硬盘上，同时不影响继续服务 取最新 N 个数据的操作，如：可以将最新的10条评论的 ID 放在 Redis 的 List 集合里面 模拟类似于 HttpSession 这种需要设定过期时间的功能 发布、订阅消息系统 定时器、计数器 Redis安装及启动将 tar.gz 包发送到 Linux 下，解压，进入目录，make &amp;&amp; make install，如果报没有 gcc 错误，就执行 yum install -y gcc 安装完成之后可以在 /usr/local/bin 下面发现有以下命令 将 redis 解压目录下的 redis.conf 复制到自定义目录中（我的是/myredis/） 启动 redis 服务器：redis-server /myredis/redis.conf 查看 redis 服务是否启动：ps -ef | grep redis 启动 redis-cli：redis-cli -p 6379（6379 为默认端口） 基础知识 单进程 单进程模型来处理客户端请求，对读写等事件的响应，是通过对 epoll 函数的包装来做到的，Redis 的实际处理速度完全依靠主进程的执行效率 Epoll 是 Linux 内核为处理大批量文件描述符二做了改进的 epoll，是 Linux 下多路复用 IO 接口 select / poll 的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统 CPU 利用率 默认 16 个数据库，类似数组下标从 0 开始，初始默认使用零号数据库 Select 命令切换数据库 Dbsize 查看当前数据库的 key 的数量 FLUSHDB：清空当前库 FLUSHALL：通杀全部库 统一密码管理，16 个库都是同样的密码，要么都连接，要么都连不上 Redis 索引都是从零开始 默认端口 6379 Redis 数据类型Redis 五大数据类型 String（字符串，最多可以是 512M） Hash（哈希，类似于 Java 里的 Map） List（列表） Set（集合） Zset（sorted set：有序集合 每个元素都会关联一个double类型的分数，分数可重复） Redis 常见数据类型操作命令https://redis.io/commands Redis 键（key） keys * –&gt; 查看当前数据库所有的 key exists key的名字 –&gt; 判断某个 key 是否存在 move key名 db序号 –&gt; 将一个 key 值移动到指定的数据库中，当前数据库就没有了 expire key名 –&gt; 为给定的 key 设置过期时间 ttl key –&gt; 查看还有多少秒过期，-1 表示永不过期，-2 表示已过期 type key –&gt; 查看 key 是什么类型 Redis 字符串（String） set / get / del / append / strlen incr / decr / incrby / decrby，一定一要是数字才能进行加减（前面两个是递增或者递减，后面两个带值加减） getrange / setrange getrange：获取指定区间内的值，类似于 between …… and 的关系 setrange：设置指定区间内的值，格式是：setrange key值 具体值 setex（set with expire）键 秒 值 / setnx（set if not exist） mset / mget / msetnx 批量设置 key-value getset（先 get 再 set） Redis 列表（List） lpush / rpush / lrange lpop / rpop lindex，按照索引下标获得元素（从上到下） lrem list名 N value（从 list 中删除 N 个值为 value 的元素） ltrim list名 index index（截取指定范围的值后再赋给 key） rpoplpush 源列表 目的列表 linsert list名 before / after 值1 值2（在 list 中的值1前/后插入值2） Redis 集合（Set） sadd / smembers / sismember scard（获取集合里面的元素个数） srem key value （删除集合中元素） srandmember key 某个整数（随机出几个数） spop key （随机出栈） smove key1 key2 在 key1 里的某个值（作用是将 key1 里的某个值赋给 key2） 数学集合类 差集：sdiff 交集：sinter 并集：sunion Redis 哈希（Hash）KV 模式不变，但是 V 是一个键值对 hset / hget / hmset / hmget / hgetall / hdel hlen hexist key（在 key 里面的某个值的 key） hkeys / hvals hincrby / hincrbyfloat hsetnx Redis 有序集合（Zset —— sorted set） zadd / zrange（zrange 最后可以带一个 withscores 顺便输出 key 值） zrangebyscore key 开始score 结束score withscores ( 不包含 Limit i num 作用是返回限制（从 i 开始截取 num 个） zrem key 某个 score 下对应的 value 值（作用是删除元素） zcard / zcount / key score区间 / zrank key values值（作用是获得下标值 / zscore key 对应值，获得分数） zrevrank key values值（作用是逆序获得下标值） zrevrange zrevrangebyscore key 结束score 开始score]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记（Day01）]]></title>
    <url>%2F2019%2F05%2F01%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day01%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摄影：Kellen Riggin，来自Unsplash NoSQLNoSQL（NoSQL = Not Only SQL）泛指非关系型的数据库，这些类型的数据存储不需要固定的模式，无需多余操作就可以横向扩展 易扩展NoSQL 数据库种类繁多，共同德天是去掉关系数据库的关系型特性 数据之间无关系，非常容易扩展，在架构的层面带来了可扩展的能力 大数据量高性能具有非常高的读写性能，尤其是在大数据量下，同样表现优秀 3V + 3高3V： 海量 Volume 多样 Variety 实时 Velocity 3高： 高并发 高可扩 高性能 NoSQL 数据模型聚合模型 KV 键值对 BSON 列族 图形 NoSQL 数据库的四大分类KV 键值： 新浪 美团 阿里 百度 文档型数据库（BSON格式较多）： CouchDB MongoDB：是一个基于分布式存储的数据库，由 C++ 语言编写，结余关系数据库和非关系数据库之间的产品 列存储数据库： Cassandra HBase 分布式文件系统 图关系数据库 不是放图形的，放的是关系，比如：朋友圈社交网络、广告推荐系统，社交网络、推荐系统等，专注于构建关系图谱 Neo4j InfoGrid 四者对比 分类 Example 举例 典型应用场景 数据模型 优点 缺点 键值（key - value） Tokyo，Cabinet/Tyrant，Redis，Voldemort，Oracle BDB 内容缓存，主要用于处理大量数据的高访问负载，也用于一些日志系统等等 Key 指向 Value的键值对，通常用 hash table 来实现 查找熟读快 数据无机构化，通常只被当做字符串或者二进制数据 列存储数据库 Cassandra，HBase，Riak 分布式的文件系统 以列簇式存储，将同一列数据存在一起 查找速度快，可扩展性强，更容易进行分布式扩展 功能相对有限 文档型数据库 CouchDB，MongoDB Web 应用（与 key - value 类似，value 是结构化的，不同的是数据库能够了解 value 的内容 key - value对应的键值对，value 为结构化数据 数据结构要求不严格，表结构可变，不需要像关系型数据库一样需要预先定义表结构 查询性能不高，而且缺乏统一的查询语法 图形（Graph）数据库 Noe4J，InfoGrid，Infinite Graph 社交网络，推荐系统，专注于构建关系图谱 图结构 利用图结构相关算法，比如最短路径寻址，N 度关系查找等 很多时候需要对整个图做计算才能得出需要的信息，而且这种结构不太好做分布式的集群方案 分布式数据库中 CAP 原理 CAP + BASE传统的ACID A（Atomicity）原子性 C（Consistency）一致性 I（Isolation）独立性 D（Durability）持久性 CAP C（Consistency）强一致性 A（Availability）可用性 P（Partition tolerance）分区容错性 CAP 理论的核心：一个分布式系统不可能同时很好满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个 根据 CAP 原理将 NoSQL 数据库分成了 满足 CA 原则，满足 CP 原则和满足 AP 原则三大类： CA – 单点集群：满足一致性，可用性的系统，通常在可扩展性上不太强大；（Oracle） CP – 满足一致性，分区容错性的系统，通常性能不是特别高；（Redis，MongoDB） AP – 满足可用性，分区容错性的系统，通常可能对一致性要求低一些（大多数网站架构选择） BASE是为了结局关系数据库强一致性引起的问题而引起的可用性降低突出的解决方案 BA（Basically Available）基本可用 S（Soft state）软状态 E（Eventually consistent）最终一致 它的思想是通过让系统放松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day04）]]></title>
    <url>%2F2019%2F04%2F28%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day04%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摄影：asoggetti，来自Unsplash Spring 声明式事务的使用@Transactional 配置项@Transactional 源码1234567891011121314151617181920212223242526272829303132333435363738@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Transactional &#123; // 通过 bean name 指定事务管理器 @AliasFor(&quot;transactionManager&quot;) String value() default &quot;&quot;; // 同 value 属性 @AliasFor(&quot;value&quot;) String transactionManager() default &quot;&quot;; // 指定传播行为 Propagation propagation() default Propagation.REQUIRED; // 指定隔离级别 Isolation isolation() default Isolation.DEFAULT; // 指定超时时间 int timeout() default -1; // 是否只读事务 boolean readOnly() default false; // 方法在发生指定异常时回滚，默认是所有异常都回滚 Class&lt;? extends Throwable&gt;[] rollbackFor() default &#123;&#125;; // 方法在发生指定异常名称时回滚，默认是所有异常都回滚 String[] rollbackForClassName() default &#123;&#125;; // 方法在发生指定异常时不回滚，默认是所有异常都回滚 Class&lt;? extends Throwable&gt;[] noRollbackFor() default &#123;&#125;; // 方法在发生指定异常名称时不回滚，默认是所有异常都回滚 String[] noRollbackForClassName() default &#123;&#125;;&#125; value，transactionManager 属性是配置一个 Spring 的事务管理器；timeout 是事务可以允许存在的时间戳，单位为秒；readOnly 属性定义的是事务是否是只读事务；propagation 指的是传播行为；isolation 是隔离级别； 关于 @Transactional：它可以放在接口上，也可以放在实现类上，推荐放在实现类上 Spring 事务管理器PlatformTransactionManager 源码 1234567891011public interface PlatformTransactionManager &#123; // 获取事务，他还会设置数据属性 TransactionStatus getTransaction(@Nullable TransactionDefinition var1) throws TransactionException; // 提交事务 void commit(TransactionStatus var1) throws TransactionException; // 回滚事务 void rollback(TransactionStatus var1) throws TransactionException;&#125; getTransaction 方法的参数是一个事务定义器，依赖于配置的 @Transactional 的配置项生成的，提交和回滚事务也就可以通过 commit 和 rollback 方法执行 隔离级别数据库事务的知识数据库事务具有以下4个基本特征（ACID）： Atomoc（原子性）：事务中包含的操作被看作一个整体单元，这个业务单元中的操作要么全部成功，要么全部失败； Consistency（一致性）：事务在完成时，必须使所有的数据都保持一直状态，在数据库中所有的修改都基于事务，保证了数据的完整性； Isolation（隔离性）：为了压制丢失更新的产生，数据库定义了隔离级别的概念，可以在不同上程度压制丢失更新的发生； Durability（持久性）：事务结束后，所有的数据会固化到一个地方，入保存到磁盘中，即使断电重启后也可以提供应用程序访问； 详解隔离级别 未提交读（run uncommitted）：是最低的隔离级别，允许一个事务读取另一个事务没有提交的数据（比较危险，会出现脏读） 读写提交（read committed）：指一个事务只能读取另外一个事务已经提交的数据，不能读取未提交的数据 可重复读：克服读写提交中出现的不可重读的现象 串行化（Serializable）：是数据库最高的隔离级别，他会要求所有的 SQL，都会按照顺序执行，可以克服上述隔离级别出现的各种问题，能够保证数据的一致性 在 Spring Boot 配置文件 application.properties 中配置隔离级别：12345678910# 隔离级别数字配置的含义# -1 数据库默认隔离级别# 1 未提交读# 2 读写提交# 4 可重复读# 8 串行化# tomcat 数据源默认隔离级别spring.datasource.tomcat.default-transaction-isolation=2# dbcp2 数据库连接池默认隔离级别# spring.datasource.dbcp2.default-transaction-isolation=2 传播行为传播行为的定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public enum Propagation &#123; /** * 需要事务，它是默认传播行为，如果当前存在事务，就沿用当前事务 * 否则新建一个事务运行子方法 */ REQUIRED(TransactionDefinition.PROPAGATION_REQUIRED), /** * 支持事务，如果当前存在事务，就沿用当前事务 * 如果不存在，则继续采用无事务的方式运行子方法 */ SUPPORTS(TransactionDefinition.PROPAGATION_SUPPORTS), /** * 必须使用事务，如果当前没有事务，则会抛出异常 * 如果存在当前事务，就沿用当前事务 */ MANDATORY(TransactionDefinition.PROPAGATION_MANDATORY), /** * 无论当前事务是否存在，都会创建新事务运行方法 * 这样新事物就可以拥有新的锁和隔离级别等特性，与当前事务相互独立 */ REQUIRES_NEW(TransactionDefinition.PROPAGATION_REQUIRES_NEW), /** * 不支持事务，当前存在事务时，将挂起事务，运行方法 */ NOT_SUPPORTED(TransactionDefinition.PROPAGATION_NOT_SUPPORTED), /** * 不支持事务，当前存在事务时，将挂起事务，运行方法 */ NEVER(TransactionDefinition.PROPAGATION_NEVER), /** * 在当前方法调用子方法时，如果子方法发生异常 * 只回滚子方法执行过的 SQL，而不回滚当前方法的事务 */ NESTED(TransactionDefinition.PROPAGATION_NESTED); private final int value; Propagation(int value) &#123; this.value = value; &#125; public int value() &#123; return this.value; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day03）]]></title>
    <url>%2F2019%2F04%2F24%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day03%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摄影：Max van den Oetelaar，来自Unsplash 代理模式和分类 虚拟代理：根据余姚将资源消耗很大的对象进行延迟，真正需要的时候进行创建 智能引用代理：提供对目标对象额外的服务 远程代理：为不同地理的对象提供局域网代表对象 保护代理：控制对一个对象的访问权限 智能引用代理 静态代理：代理和被代理对象在代理之前是确定的，他们都实现相同的接口或者继承相同的抽象类 动态代理 继承和聚合实现静态代理继承会导致每添加一个功能就需要新建一个类，导致代码无限膨胀聚合代理每添加一个被代理对象就需要新建一个类，也会导致代码膨胀 JDK 动态代理动态代理（Dynamic Proxy）是这样一种class：它是在运行时产生的 class 对象该 class 需要实现一组 interface只用动态代理类是，必须实现 InvocationHandler 接口 实现步骤： 创建一个实现 InvocationHandler 的类，它必须实现 invoke 方法 创建被代理的类以及接口 调用 Proxy 的静态方法，创建一个代理类new ProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler handler) 通过代理调用方法 CGLIB 动态代理与 JDK 动态代理的区别： JDK 动态代理： 只能代理实现了接口的类 没有实现接口的类不能实现 JDK 的动态代理 CGLIB 动态代理： 针对类来代理的 队指定目标类产生一个子类，通过方法拦截技术拦截所有父类方法的调用 动态代理实现思路实现功能：通过 Proxy 的 newProxyInstance 返回代理对象 声明一段源码（动态产生代理） 编译源码（JDK Compiler API），产生新的代理类（代理类） 将这个类 load 到内存中，产生一个新的对象（代理对象） return 代理对象 AOP 术语和流程连接点（join point）： 对应的是具体没拦截的对象，因为 Spring 只能支持方法，所以被拦截的对象往往就是指特定的方法切点（point cut）： 有时候，我们的切面不单单应用于耽搁方法，也有可能是多个类的不同方法，这时，可以通过正则表达式和指示器的规则去定义，从而适配连接点。切点就是提供这样一个功能的概念通知（advice）： 就是按照约定的流程下的方法，分为前置通知（before advice）、后置通知（after advice）、环绕通知（around advice）、事后返回通知（afterReturningadvice）和异常通知（afterThrowing advice），它会根据约定织入流程中，需要弄明白它们在流程中的顺序和运行的条件目标对象（target）： 即被代理对象引入（introduction）： 是指引入新的类和方法，增强现有 Bean 的功能织入（weaving）： 它是通过动态代理技术，为原有服务对象生成代理对象，然后将切点定义匹配的连接点拦截，并按约定将各类通知织入约定流程的过程切面（aspect）： 是一个可以定义切点、各类通知和引入的内容，Spring AOP 将通过它的信息来增强 Bean 的功能或者将对应的方法织入流程 Spring AOP 流程约定 定义切面 切点1234567891011121314151617181920212223242526272829303132333435@Aspectpublic class MyAspect &#123; @Pointcut(&quot;execution(* cn.chentyit.chapter4.aspect.service.impl.UserServiceImpl.printUser(..))&quot;) public void pointCut() &#123; &#125; @Around(&quot;pointCut()&quot;) public void around(ProceedingJoinPoint jp) throws Throwable &#123; System.out.println(&quot;around before ......&quot;); // 回调目标对象的原有方法 jp.proceed(); System.out.println(&quot;around after ......&quot;); &#125; @Before(&quot;pointCut()&quot;) public void before() &#123; System.out.println(&quot;before ......&quot;); &#125; @After(&quot;pointCut()&quot;) public void after() &#123; System.out.println(&quot;after ......&quot;); &#125; @AfterReturning(&quot;pointCut()&quot;) public void afterReturning() &#123; System.out.println(&quot;afterReturning ......&quot;); &#125; @AfterThrowing(&quot;pointCut()&quot;) public void afterThrowing() &#123; System.out.println(&quot;afterThrowing ......&quot;); &#125;&#125; @Aspect 作为注解时，Spring 就会知道这是一个切面，我们就可以通过各类注解来定义各类的通知了@Before 前置通知@After 后置通知@AfterReturning 返回通知@AfterThrowing 异常通知 切点： 作用就是向 Spring 描述哪些类的哪些方法需要启用 AOP 编程@Pointcut 标志在 pointCut 方法上，则在后面的通知注解中就可以使用方法名来定义了 其他： execution：表示在执行的时候，拦截里面的正则匹配的方法 * 表示任意返回类型的方法 cn.chentyit.chapter4.aspect.service.impl.UserServiceImpl 指定目标对象的全限定名称 printUser 指定目标对象的方法 (..) 表示任意参数进行匹配]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day02）]]></title>
    <url>%2F2019%2F04%2F23%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day02%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摄影：Kellen Riggin，来自Unsplash 使用属性文件直接使用配置文件属性先在 pom.xml 文件中添加以下依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 这样就可以在代码中直接使用 .application 文件了再编写以下代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Component/** * @PropertySource(&quot;classpath:application.properties&quot;) * 这行代码是必要的，指定配置文件的路径，方便使用属性配置 */@PropertySource(&quot;classpath:application.properties&quot;)public class DataBaseProperties &#123; @Value(&quot;$&#123;database.driver&#125;&quot;) private String driverName = null; @Value(&quot;$&#123;database.url&#125;&quot;) private String url = null; private String username = null; private String password = null; public String getDriverName() &#123; return driverName; &#125; public void setDriverName(String driverName) &#123; System.out.println(driverName); this.driverName = driverName; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; System.out.println(url); this.url = url; &#125; public String getUsername() &#123; return username; &#125; @Value(&quot;$&#123;database.username&#125;&quot;) public void setUsername(String username) &#123; System.out.println(username); this.username = username; &#125; public String getPassword() &#123; return password; &#125; @Value(&quot;$&#123;database.password&#125;&quot;) public void setPassword(String password) &#123; System.out.println(password); this.password = password; &#125;&#125; 使用 @ConfigurationProperties123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Component@ConfigurationProperties(&quot;database&quot;)public class DataBaseProperties &#123; private String driverName = null; private String url = null; private String username = null; private String password = null; public String getDriverName() &#123; return driverName; &#125; public void setDriverName(String driverName) &#123; System.out.println(driverName); this.driverName = driverName; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; System.out.println(url); this.url = url; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; System.out.println(username); this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; System.out.println(password); this.password = password; &#125;&#125; 这里注解 @ConfigurationProperties 中配置的字符串 database 将于 POJO 的属性名组成属性的全限定名去配置文件里面查找 自定义配置文件将配置文件中的属性单独取出来放到新的 .properties 文件中（以 jdbc.properties为例）1234database.driver=com.mysql.jdbc.Driverdatabase.url=&quot;jdbc:mysql://127.0.0.1:3306/repository?characterEncoding=utf8&amp;useSSL=true&amp;serverTimezone=Asia/Shanghai&quot;database.username=rootdatabase.password=Chentyit123456 配置类代码不改动，并在 *Application 中添加 @PropertySource 注释12345678@SpringBootApplication@PropertySource(value = &#123;&quot;classpath:jdbc.properties&quot;&#125;, ignoreResourceNotFound = true)public class Chapter2Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Chapter2Application.class, args); &#125;&#125; ignoreResourceNotFound 是忽略配置文件找不到的问题，默认值为false，也就是没找到配置文件，就会报错；这里配置为true，忽略掉错误，不报错； Bean 的作用域 作用域类型 使用范围 作用域描述 singleton 所有 Spring 应用 默认值，IoC 容器只存在单例 prototype 所有 Spring 应用 每当从 IoC 容器中取出一个 Bean，则创建一个新的 Bean session Spring Web 应用 HTTP 会话 application Spring Web 应用 Web 工程生命周期 request Spring Web 应用 Web 工程单次请求（request） globalSession Spring Web 应用 在一个全局的 HTTp Session 中，一个 Bean 定义对应一个实例 可以使用 @Scope 定义单例或者原型（默认单例）1234@Component// @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)public class ScopeBean &#123;&#125; 以上代码注释了 @Scope，使用的是单例，但是取消注释后，就是原型了 ConfigurableBeanFactory 只能提供单例（SCOPE_SINGLETON）和原型（SCOPE_PROTOTYPE）两种作用域供选择 WebApplicationContext 提供了请求（SCOPE_REQUEST）、会话（SCOPE_SESSION）和应用（SCOPE_APPLICATION）]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot学习笔记（Day01）]]></title>
    <url>%2F2019%2F04%2F22%2FSpringBoot%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Day01%EF%BC%89%2F</url>
    <content type="text"><![CDATA[摄影：Matthew T Rader，来自Unsplash 装配Bean通过扫描装配Bean1234567891011@Component（&quot;user&quot;)public class User &#123; @Value(&quot;1&quot;) private Long id; @Value(&quot;user_name_1&quot;) private String userName; @Value(&quot;note_1&quot;) private String note; /** setter and getter **/&#125; @Component 是标明哪个类被扫描进入 Spring IoC 容器@ComponentScan 是标明采用何种策略去扫描装配Bean（默认扫描被标注类所在的当前包和其子包） @ComponentScan 源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Repeatable(ComponentScans.class)public @interface ComponentScan &#123; // 定义扫描的包 @AliasFor(&quot;basePackages&quot;) String[] value() default &#123;&#125;; // 定义扫描的包 @AliasFor(&quot;value&quot;) String[] basePackages() default &#123;&#125;; // 定义扫描的类 Class&lt;?&gt;[] basePackageClasses() default &#123;&#125;; // Bean name 生成器 Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; // 作用域解析器 Class&lt;? extends ScopeMetadataResolver&gt; scopeResolver() default AnnotationScopeMetadataResolver.class; // 作用域代理模式 ScopedProxyMode scopedProxy() default ScopedProxyMode.DEFAULT; // 资源匹配模式 String resourcePattern() default ClassPathScanningCandidateComponentProvider.DEFAULT_RESOURCE_PATTERN; // 是否启用默认的过滤器 boolean useDefaultFilters() default true; // 当满足过滤器的条件时扫描 Filter[] includeFilters() default &#123;&#125;; // 当不满足过滤器的条件时扫描 Filter[] excludeFilters() default &#123;&#125;; // 是否延迟初始化 boolean lazyInit() default false; // 定义过滤器 @Retention(RetentionPolicy.RUNTIME) @Target(&#123;&#125;) @interface Filter &#123; // 过滤器类型，可以按注解类型或者正则式等过滤 FilterType type() default FilterType.ANNOTATION; // 定义过滤的类 @AliasFor(&quot;classes&quot;) Class&lt;?&gt;[] value() default &#123;&#125;; // 定义过滤的类 @AliasFor(&quot;value&quot;) Class&lt;?&gt;[] classes() default &#123;&#125;; // 匹配方式 String[] pattern() default &#123;&#125;; &#125;&#125; @SpringBootApplication 源码1234567891011121314151617181920212223242526272829@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; // 通过类型排除自动配置类 @AliasFor(annotation = EnableAutoConfiguration.class) Class&lt;?&gt;[] exclude() default &#123;&#125;; // 通过名称排除自动配置类 @AliasFor(annotation = EnableAutoConfiguration.class) String[] excludeName() default &#123;&#125;; // 定义扫描包 @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackages&quot;) String[] scanBasePackages() default &#123;&#125;; // 定义被扫描的类 @AliasFor(annotation = ComponentScan.class, attribute = &quot;basePackageClasses&quot;) Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;;&#125; 注解 @Autowired注入机制：根据类型注入规则：首先会根据类型找到对应的 Bean，如果对应类型的 Bean 不是唯一的，那么他会根据其属性名称和 Bean 的名称进行匹配。如果匹配得上，就会使用该 Bean，如果还无法匹配，就会抛出异常。 消除歧义性 —— @Primary 和 @Qualifier@Primary：告诉 Spring IoC 容器，当发现有多个同样类型的 Bean 时，优先使用 @Primary 标注的 Bean 注入@Qualifier：配置项 value 需要一个字符串去定义，它将与 @Autowired 组合在一起，通过类型和名称一起找到 Bean 带有参数的构造方法类的装配12345678910111213141516171819@Componentpublic class BussinessPerson implements Person &#123; private Animal animal; public BussinessPerson(@Autowired @Qualifier(&quot;dog&quot;) Animal animal) &#123; this.animal = animal; &#125; @Override public void service() &#123; this.animal.use(); &#125; @Override public void setAnimal(Animal animal) &#123; this.animal = animal; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>自学笔记</tag>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot-1.x和SpringBoot-2.x区别]]></title>
    <url>%2F2019%2F04%2F16%2FSpringBoot-1-x%E5%92%8CSpringBoot-2-x%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[该博客用于更新SpingBoot 1.x 和 2.x 之间的区别（长期更新） 摄影：Garrett Patz，来自Unsplash 编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 SpringBoot 1.x 1234567891011@Bean //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; SpringBoot 2.x 123456789@Beanpublic ConfigurableServletWebServerFactory webServerFactory() &#123; return new TomcatServletWebServerFactory() &#123; @Override protected void customizeConnector(Connector connector) &#123; connector.setPort(8083); &#125; &#125;;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门]]></title>
    <url>%2F2019%2F04%2F08%2FSpringBoot%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring Boot 入门 内容如有侵权请告知删除 摄影：Matthew T Rader，来自Unsplash 1、Spring Boot 简介 简化Spring应用开发的一个框架； 整个Spring技术栈的一个大整合； J2EE开发的一站式解决方案； 2、微服务2014，martin fowler 微服务：架构风格（服务微化） 一个应用应该是一组小型服务；可以通过HTTP的方式进行互通； 单体应用：ALL IN ONE 微服务：每一个功能元素最终都是一个可独立替换和独立升级的软件单元； 详细参照微服务文档 3、环境准备环境约束 –jdk1.8：Spring Boot 推荐jdk1.7及以上；java version “1.8.0_112” –maven3.x：maven 3.3以上版本；Apache Maven 3.3.9 –IntelliJIDEA2017：IntelliJ IDEA 2017.2.2 x64、STS –SpringBoot 1.5.9.RELEASE：1.5.9； 统一环境； 1、MAVEN设置；给maven 的settings.xml配置文件的profiles标签添加 123456789101112&lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt;&lt;/profile&gt; 2、IDEA设置整合maven进来； 4、Spring Boot HelloWorld一个功能： 浏览器发送hello请求，服务器接受请求并处理，响应Hello World字符串； 1、创建一个maven工程；（jar）2、导入spring boot相关的依赖1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3、编写一个主程序；启动Spring Boot应用12345678910111213/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; 4、编写相关的Controller、Service123456789@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping("/hello") public String hello()&#123; return "Hello World!"; &#125;&#125; 5、运行主程序测试6、简化部署123456789&lt;!-- 这个插件，可以将应用打包成一个可执行的jar包；--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 将这个应用打成jar包，直接使用java -jar的命令进行执行； 5、Hello World探究1、POM文件1、父项目1234567891011121314&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt;&lt;/parent&gt;他的父项目是&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath&gt;../../spring-boot-dependencies&lt;/relativePath&gt;&lt;/parent&gt;他来真正管理Spring Boot应用里面的所有依赖版本； Spring Boot的版本仲裁中心； 以后我们导入依赖默认是不需要写版本；（没有在dependencies里面管理的依赖自然需要声明版本号） 2、启动器1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; spring-boot-starter-==web==： ​ spring-boot-starter：spring-boot场景启动器；帮我们导入了web模块正常运行所依赖的组件； Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter相关场景的所有依赖都会导入进来。要用什么功能就导入什么场景的启动器 2、主程序类，主入口类123456789101112/** * @SpringBootApplication 来标注一个主程序类，说明这是一个Spring Boot应用 */@SpringBootApplicationpublic class HelloWorldMainApplication &#123; public static void main(String[] args) &#123; // Spring应用启动起来 SpringApplication.run(HelloWorldMainApplication.class,args); &#125;&#125; @SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； 12345678910@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; @SpringBootConfiguration:Spring Boot的配置类； ​ 标注在某个类上，表示这是一个Spring Boot的配置类； ​ @Configuration:配置类上来标注这个注解； ​ 配置类 —– 配置文件；配置类也是容器中的一个组件；@Component @EnableAutoConfiguration：开启自动配置功能； ​ 以前我们需要配置的东西，Spring Boot帮我们自动配置；@EnableAutoConfiguration告诉SpringBoot开启自动配置功能；这样自动配置才能生效； 123@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ​ @AutoConfigurationPackage：自动配置包 ​ @Import(AutoConfigurationPackages.Registrar.class)： ​ Spring的底层注解@Import，给容器中导入一个组件；导入的组件由AutoConfigurationPackages.Registrar.class； ==将主配置类（@SpringBootApplication标注的类）的所在包及下面所有子包里面的所有组件扫描到Spring容器；== ​ @Import(EnableAutoConfigurationImportSelector.class)； ​ 给容器中导入组件？ ​ EnableAutoConfigurationImportSelector：导入哪些组件的选择器； ​ 将所有需要导入的组件以全类名的方式返回；这些组件就会被添加到容器中； ​ 会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件； 有了自动配置类，免去了我们手动编写配置注入功能组件等的工作； ​ SpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class,classLoader)； ==Spring Boot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；==以前我们需要自己配置的东西，自动配置类都帮我们； J2EE的整体整合解决方案和自动配置都在spring-boot-autoconfigure-1.5.9.RELEASE.jar； ​ ==Spring注解版（谷粒学院）== 6、使用Spring Initializer快速创建Spring Boot项目1、IDEA：使用 Spring Initializer快速创建项目IDE都支持使用Spring的项目创建向导快速创建一个Spring Boot项目； 选择我们需要的模块；向导会联网创建Spring Boot项目； 默认生成的Spring Boot项目； 主程序已经生成好了，我们只需要我们自己的逻辑 resources文件夹中目录结构 static：保存所有的静态资源； js css SpringBoot入门； templates：保存所有的模板页面；（Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面）；可以使用模板引擎（freemarker、thymeleaf）； application.properties：Spring Boot应用的配置文件；可以修改一些默认设置； 2、STS使用 Spring Starter Project快速创建项目 二、配置文件1、配置文件SpringBoot使用一个全局的配置文件，配置文件名是固定的； •application.properties •application.yml 配置文件的作用：修改SpringBoot自动配置的默认值；SpringBoot在底层都给我们自动配置好； YAML（YAML Ain’t Markup Language） ​ YAML A Markup Language：是一个标记语言 ​ YAML isn’t Markup Language：不是一个标记语言； 标记语言： ​ 以前的配置文件；大多都使用的是 xxxx.xml文件； ​ YAML：以数据为中心，比json、xml等更适合做配置文件； ​ YAML：配置例子 12server: port: 8081 ​ XML： 123&lt;server&gt; &lt;port&gt;8081&lt;/port&gt;&lt;/server&gt; 2、YAML语法：1、基本语法k:(空格)v：表示一对键值对（空格必须有）； 以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一个层级的 123server: port: 8081 path: /hello 属性和值也是大小写敏感； 2、值的写法字面量：普通的值（数字，字符串，布尔）​ k: v：字面直接来写； ​ 字符串默认不用加上单引号或者双引号； ​ “”：双引号；不会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思 ​ name: “zhangsan \n lisi”：输出；zhangsan 换行 lisi ​ ‘’：单引号；会转义特殊字符，特殊字符最终只是一个普通的字符串数据 ​ name: ‘zhangsan \n lisi’：输出；zhangsan \n lisi 对象、Map（属性和值）（键值对）：​ k: v：在下一行来写对象的属性和值的关系；注意缩进 ​ 对象还是k: v的方式 123friends: lastName: zhangsan age: 20 行内写法： 1friends: &#123;lastName: zhangsan,age: 18&#125; 数组（List、Set）：用- 值表示数组中的一个元素 1234pets: - cat - dog - pig 行内写法 1pets: [cat,dog,pig] 3、配置文件值注入配置文件 123456789101112person: lastName: hello age: 18 boss: false birth: 2017/12/12 maps: &#123;k1: v1,k2: 12&#125; lists: - lisi - zhaoliu dog: name: 小狗 age: 12 javaBean： 1234567891011121314151617181920/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = "person"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * */@Component@ConfigurationProperties(prefix = "person")public class Person &#123; private String lastName; private Integer age; private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 我们可以导入配置文件处理器，以后编写配置就有提示了 123456&lt;!--导入配置文件处理器，配置文件进行绑定就会有提示--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 1、properties配置文件在idea中默认utf-8可能会乱码调整 2、@Value获取值和@ConfigurationProperties获取值比较 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 配置文件yml还是properties他们都能获取到值； 如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value； 如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties； 3、配置文件注入值数据校验123456789101112131415161718192021222324@Component@ConfigurationProperties(prefix = "person")@Validatedpublic class Person &#123; /** * &lt;bean class="Person"&gt; * &lt;property name="lastName" value="字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 @Email //@Value("$&#123;person.last-name&#125;") private String lastName; //@Value("#&#123;11*2&#125;") private Integer age; //@Value("true") private Boolean boss; private Date birth; private Map&lt;String,Object&gt; maps; private List&lt;Object&gt; lists; private Dog dog; 4、@PropertySource&amp;@ImportResource&amp;@Bean@PropertySource：加载指定的配置文件； 1234567891011121314151617181920212223242526272829/** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * prefix = "person"：配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能容器提供的@ConfigurationProperties功能； * @ConfigurationProperties(prefix = "person")默认从全局配置文件中获取值； * */@PropertySource(value = &#123;"classpath:person.properties"&#125;)@Component@ConfigurationProperties(prefix = "person")//@Validatedpublic class Person &#123; /** * &lt;bean class="Person"&gt; * &lt;property name="lastName" value="字面量/$&#123;key&#125;从环境变量、配置文件中获取值/#&#123;SpEL&#125;"&gt;&lt;/property&gt; * &lt;bean/&gt; */ //lastName必须是邮箱格式 // @Email //@Value("$&#123;person.last-name&#125;") private String lastName; //@Value("#&#123;11*2&#125;") private Integer age; //@Value("true") private Boolean boss; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； Spring Boot里面没有Spring的配置文件，我们自己编写的配置文件，也不能自动识别； 想让Spring的配置文件生效，加载进来；@ImportResource标注在一个配置类上 12@ImportResource(locations = &#123;"classpath:beans.xml"&#125;)导入Spring的配置文件让其生效 不来编写Spring的配置文件 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="helloService" class="com.atguigu.springboot.service.HelloService"&gt;&lt;/bean&gt;&lt;/beans&gt; SpringBoot推荐给容器中添加组件的方式；推荐使用全注解的方式 1、配置类@Configuration——&gt;Spring配置文件 2、使用@Bean给容器中添加组件 12345678910111213141516/** * @Configuration：指明当前类是一个配置类；就是来替代之前的Spring配置文件 * * 在配置文件中用&lt;bean&gt;&lt;bean/&gt;标签添加组件 * */@Configurationpublic class MyAppConfig &#123; //将方法的返回值添加到容器中；容器中这个组件默认的id就是方法名 @Bean public HelloService helloService02()&#123; System.out.println("配置类@Bean给容器中添加组件了..."); return new HelloService(); &#125;&#125; ##4、配置文件占位符 1、随机数12$&#123;random.value&#125;、$&#123;random.int&#125;、$&#123;random.long&#125;$&#123;random.int(10)&#125;、$&#123;random.int[1024,65536]&#125; 2、占位符获取之前配置的值，如果没有可以是用:指定默认值123456789person.last-name=张三$&#123;random.uuid&#125;person.age=$&#123;random.int&#125;person.birth=2017/12/15person.boss=falseperson.maps.k1=v1person.maps.k2=14person.lists=a,b,cperson.dog.name=$&#123;person.hello:hello&#125;_dogperson.dog.age=15 5、Profile1、多Profile文件我们在主配置文件编写的时候，文件名可以是 application-{profile}.properties/yml 默认使用application.properties的配置； 2、yml支持多文档块方式1234567891011121314151617181920server: port: 8081spring: profiles: active: prod---server: port: 8083spring: profiles: dev---server: port: 8084spring: profiles: prod #指定属于哪个环境 3、激活指定profile​ 1、在配置文件中指定 spring.profiles.active=dev ​ 2、命令行： ​ java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar –spring.profiles.active=dev； ​ 可以直接在测试的时候，配置传入命令行参数 ​ 3、虚拟机参数； ​ -Dspring.profiles.active=dev 6、配置文件加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 –file:./config/ –file:./ –classpath:/config/ –classpath:/ 优先级由高到底，高优先级的配置会覆盖低优先级的配置； SpringBoot会从这四个位置全部加载主配置文件；互补配置； ==我们还可以通过spring.config.location来改变默认的配置文件位置== 项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置； java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –spring.config.location=G:/application.properties 7、外部配置加载顺序==SpringBoot也可以从以下位置加载配置； 优先级从高到低；高优先级的配置覆盖低优先级的配置，所有的配置会形成互补配置== 1.命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring-boot-02-config-02-0.0.1-SNAPSHOT.jar –server.port=8087 –server.context-path=/abc 多个配置用空格分开； –配置项=值 2.来自java:comp/env的JNDI属性 3.Java系统属性（System.getProperties()） 4.操作系统环境变量 5.RandomValuePropertySource配置的random.*属性值 ==由jar包外向jar包内进行寻找；== ==优先加载带profile== 6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 ==再来加载不带profile== 8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件 9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件 10.@Configuration注解类上的@PropertySource 11.通过SpringApplication.setDefaultProperties指定的默认属性 所有支持的配置加载来源； 参考官方文档 8、自动配置原理配置文件到底能写什么？怎么写？自动配置原理； 配置文件能配置的属性参照 1、自动配置原理：1）、SpringBoot启动的时候加载主配置类，开启了自动配置功能 ==@EnableAutoConfiguration== 2）、@EnableAutoConfiguration 作用： 利用EnableAutoConfigurationImportSelector给容器中导入一些组件？ 可以查看selectImports()方法的内容； List configurations = getCandidateConfigurations(annotationMetadata, attributes);获取候选的配置 1234SpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中 ​ ==将 类路径下 META-INF/spring.factories 里面配置的所有EnableAutoConfiguration的值加入到了容器中；== 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\org.springframework.boot.autoconfigure.cloud.CloudAutoConfiguration,\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.ldap.LdapDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.DeviceResolverAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.DeviceDelegatingViewResolverAutoConfiguration,\org.springframework.boot.autoconfigure.mobile.SitePreferenceAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\org.springframework.boot.autoconfigure.reactor.ReactorAutoConfiguration,\org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration,\org.springframework.boot.autoconfigure.security.SecurityFilterAutoConfiguration,\org.springframework.boot.autoconfigure.security.FallbackWebSecurityAutoConfiguration,\org.springframework.boot.autoconfigure.security.oauth2.OAuth2AutoConfiguration,\org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\org.springframework.boot.autoconfigure.social.SocialWebAutoConfiguration,\org.springframework.boot.autoconfigure.social.FacebookAutoConfiguration,\org.springframework.boot.autoconfigure.social.LinkedInAutoConfiguration,\org.springframework.boot.autoconfigure.social.TwitterAutoConfiguration,\org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\org.springframework.boot.autoconfigure.web.DispatcherServletAutoConfiguration,\org.springframework.boot.autoconfigure.web.EmbeddedServletContainerAutoConfiguration,\org.springframework.boot.autoconfigure.web.ErrorMvcAutoConfiguration,\org.springframework.boot.autoconfigure.web.HttpEncodingAutoConfiguration,\org.springframework.boot.autoconfigure.web.HttpMessageConvertersAutoConfiguration,\org.springframework.boot.autoconfigure.web.MultipartAutoConfiguration,\org.springframework.boot.autoconfigure.web.ServerPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.web.WebClientAutoConfiguration,\org.springframework.boot.autoconfigure.web.WebMvcAutoConfiguration,\org.springframework.boot.autoconfigure.websocket.WebSocketAutoConfiguration,\org.springframework.boot.autoconfigure.websocket.WebSocketMessagingAutoConfiguration,\org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration 每一个这样的 xxxAutoConfiguration类都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 3）、每一个自动配置类进行自动配置功能； 4）、以HttpEncodingAutoConfiguration（Http编码自动配置）为例解释自动配置原理； 12345678910111213141516171819202122232425262728@Configuration //表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpEncodingProperties.class) //启动指定类的ConfigurationProperties功能；将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncodingProperties加入到ioc容器中@ConditionalOnWebApplication //Spring底层@Conditional注解（Spring注解版），根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效； 判断当前应用是否是web应用，如果是，当前配置类生效@ConditionalOnClass(CharacterEncodingFilter.class) //判断当前项目有没有这个类CharacterEncodingFilter；SpringMVC中进行乱码解决的过滤器；@ConditionalOnProperty(prefix = "spring.http.encoding", value = "enabled", matchIfMissing = true) //判断配置文件中是否存在某个配置 spring.http.encoding.enabled；如果不存在，判断也是成立的//即使我们配置文件中不配置pring.http.encoding.enabled=true，也是默认生效的；public class HttpEncodingAutoConfiguration &#123; //他已经和SpringBoot的配置文件映射了 private final HttpEncodingProperties properties; //只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpEncodingProperties properties) &#123; this.properties = properties; &#125; @Bean //给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean(CharacterEncodingFilter.class) //判断容器没有这个组件？ public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 5）、所有在配置文件中能配置的属性都是在xxxxProperties类中封装者‘；配置文件能配置什么就可以参照某个功能对应的这个属性类 1234@ConfigurationProperties(prefix = "spring.http.encoding") //从配置文件中获取指定的值和bean的属性进行绑定public class HttpEncodingProperties &#123; public static final Charset DEFAULT_CHARSET = Charset.forName("UTF-8"); 精髓： ​ 1）、SpringBoot启动会加载大量的自动配置类 ​ 2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类； ​ 3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） ​ 4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； 2、细节1、@Conditional派生注解（Spring注解版原生的@Conditional作用）作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； ==我们可以通过启用 debug=true属性；来让控制台打印自动配置报告==，这样我们就可以很方便的知道哪些自动配置类生效； 1234567891011121314151617181920212223=========================AUTO-CONFIGURATION REPORT=========================Positive matches:（自动配置类启用的）----------------- DispatcherServletAutoConfiguration matched: - @ConditionalOnClass found required class 'org.springframework.web.servlet.DispatcherServlet'; @ConditionalOnMissingClass did not find unwanted class (OnClassCondition) - @ConditionalOnWebApplication (required) found StandardServletEnvironment (OnWebApplicationCondition) Negative matches:（没有启动，没有匹配成功的自动配置类）----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'javax.jms.ConnectionFactory', 'org.apache.activemq.ActiveMQConnectionFactory' (OnClassCondition) AopAutoConfiguration: Did not match: - @ConditionalOnClass did not find required classes 'org.aspectj.lang.annotation.Aspect', 'org.aspectj.lang.reflect.Advice' (OnClassCondition) 三、日志1、日志框架 小张；开发一个大型系统； ​ 1、System.out.println(“”)；将关键数据打印在控制台；去掉？写在一个文件？ ​ 2、框架来记录系统的一些运行时信息；日志框架 ； zhanglogging.jar； ​ 3、高大上的几个功能？异步模式？自动归档？xxxx？ zhanglogging-good.jar？ ​ 4、将以前框架卸下来？换上新的框架，重新修改之前相关的API；zhanglogging-prefect.jar； ​ 5、JDBC—数据库驱动； ​ 写了一个统一的接口层；日志门面（日志的一个抽象层）；logging-abstract.jar； ​ 给项目中导入具体的日志实现就行了；我们之前的日志框架都是实现的抽象层； 市面上的日志框架； JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j…. 日志门面 （日志的抽象层） 日志实现 JCL（Jakarta Commons Logging） SLF4j（Simple Logging Facade for Java） jboss-logging Log4j JUL（java.util.logging） Log4j2 Logback 左边选一个门面（抽象层）、右边来选一个实现； 日志门面： SLF4J； 日志实现：Logback； SpringBoot：底层是Spring框架，Spring框架默认是用JCL；‘ ​ ==SpringBoot选用 SLF4j和logback；== 2、SLF4j使用1、如何在系统中使用SLF4j https://www.slf4j.org以后开发的时候，日志记录方法的调用，不应该来直接调用日志的实现类，而是调用日志抽象层里面的方法； 给系统里面导入slf4j的jar和 logback的实现jar 123456789import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info("Hello World"); &#125;&#125; 图示； 每一个日志的实现框架都有自己的配置文件。使用slf4j以后，配置文件还是做成日志实现框架自己本身的配置文件； 2、遗留问题a（slf4j+logback）: Spring（commons-logging）、Hibernate（jboss-logging）、MyBatis、xxxx 统一日志记录，即使是别的框架和我一起统一使用slf4j进行输出？ 如何让系统中所有的日志都统一到slf4j； ==1、将系统中其他日志框架先排除出去；== ==2、用中间包来替换原有的日志框架；== ==3、我们导入slf4j其他的实现== 3、SpringBoot日志关系1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; SpringBoot使用它来做日志功能； 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; 底层依赖关系 总结： ​ 1）、SpringBoot底层也是使用slf4j+logback的方式进行日志记录 ​ 2）、SpringBoot也把其他的日志都替换成了slf4j； ​ 3）、中间替换包？ 123456@SuppressWarnings("rawtypes")public abstract class LogFactory &#123; static String UNSUPPORTED_OPERATION_IN_JCL_OVER_SLF4J = "http://www.slf4j.org/codes.html#unsupported_operation_in_jcl_over_slf4j"; static LogFactory logFactory = new SLF4JLogFactory(); ​ 4）、如果我们要引入其他框架？一定要把这个框架的默认日志依赖移除掉？ ​ Spring框架用的是commons-logging； 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; ==SpringBoot能自动适配所有的日志，而且底层使用slf4j+logback的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉即可；== 4、日志使用；1、默认配置SpringBoot默认帮我们配置好了日志； 123456789101112131415161718//记录器Logger logger = LoggerFactory.getLogger(getClass());@Testpublic void contextLoads() &#123; //System.out.println(); //日志的级别； //由低到高 trace&lt;debug&lt;info&lt;warn&lt;error //可以调整输出的日志级别；日志就只会在这个级别以以后的高级别生效 logger.trace("这是trace日志..."); logger.debug("这是debug日志..."); //SpringBoot默认给我们使用的是info级别的，没有指定级别的就用SpringBoot默认规定的级别；root级别 logger.info("这是info日志..."); logger.warn("这是warn日志..."); logger.error("这是error日志...");&#125; 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n SpringBoot修改日志的默认配置 123456789101112131415logging.level.com.atguigu=trace#logging.path=# 不指定路径在当前项目下生成springboot.log日志# 可以指定完整的路径；#logging.file=G:/springboot.log# 在当前磁盘的根路径下创建spring文件夹和里面的log文件夹；使用 spring.log 作为默认文件logging.path=/spring/log# 在控制台输出的日志的格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n# 指定文件中日志输出的格式logging.pattern.file=%d&#123;yyyy-MM-dd&#125; === [%thread] === %-5level === %logger&#123;50&#125; ==== %msg%n logging.file logging.path Example Description (none) (none) 只在控制台输出 指定文件名 (none) my.log 输出日志到my.log文件 (none) 指定目录 /var/log 输出到指定目录的 spring.log 文件中 2、指定配置给类路径下放上每个日志框架自己的配置文件即可；SpringBoot就不使用他默认配置的了 Logging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.groovy Log4j2 log4j2-spring.xml or log4j2.xml JDK (Java Util Logging) logging.properties logback.xml：直接就被日志框架识别了； logback-spring.xml：日志框架就不直接加载日志的配置项，由SpringBoot解析日志配置，可以使用SpringBoot的高级Profile功能 1234&lt;springProfile name="staging"&gt; &lt;!-- configuration to be enabled when the "staging" profile is active --&gt; 可以指定某段配置只在某个环境下生效&lt;/springProfile&gt; 如： 12345678910111213141516171819&lt;appender name="stdout" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger&#123;50&#125; 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class="ch.qos.logback.classic.PatternLayout"&gt; &lt;springProfile name="dev"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ----&gt; [%thread] ---&gt; %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name="!dev"&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; ==== [%thread] ==== %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; 如果使用logback.xml作为日志配置文件，还要使用profile功能，会有以下错误 no applicable action for [springProfile] 5、切换日志框架可以按照slf4j的日志适配图，进行相关的切换； slf4j+log4j的方式； 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;/dependency&gt; 切换为log4j2 123456789101112131415 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt;&lt;/dependency&gt; 四、Web开发1、简介使用SpringBoot； 1）、创建SpringBoot应用，选中我们需要的模块； 2）、SpringBoot已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来 3）、自己编写业务代码； 自动配置原理？ 这个场景SpringBoot帮我们配置了什么？能不能修改？能修改哪些配置？能不能扩展？xxx 12xxxxAutoConfiguration：帮我们给容器中自动配置组件；xxxxProperties:配置类来封装配置文件的内容； 2、SpringBoot对静态资源的映射规则；123@ConfigurationProperties(prefix = "spring.resources", ignoreUnknownFields = false)public class ResourceProperties implements ResourceLoaderAware &#123; //可以设置和静态资源有关的参数，缓存时间等 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364WebMvcAuotConfiguration： @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug("Default resource handling disabled"); return; &#125; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if (!registry.hasMappingForPattern("/webjars/**")) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler("/webjars/**") .addResourceLocations( "classpath:/META-INF/resources/webjars/") .setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); //静态资源文件夹映射 if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration( registry.addResourceHandler(staticPathPattern) .addResourceLocations( this.resourceProperties.getStaticLocations()) .setCachePeriod(cachePeriod)); &#125; &#125; //配置欢迎页映射 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping( ResourceProperties resourceProperties) &#123; return new WelcomePageHandlerMapping(resourceProperties.getWelcomePage(), this.mvcProperties.getStaticPathPattern()); &#125; //配置喜欢的图标 @Configuration @ConditionalOnProperty(value = "spring.mvc.favicon.enabled", matchIfMissing = true) public static class FaviconConfiguration &#123; private final ResourceProperties resourceProperties; public FaviconConfiguration(ResourceProperties resourceProperties) &#123; this.resourceProperties = resourceProperties; &#125; @Bean public SimpleUrlHandlerMapping faviconHandlerMapping() &#123; SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); //所有 **/favicon.ico mapping.setUrlMap(Collections.singletonMap("**/favicon.ico", faviconRequestHandler())); return mapping; &#125; @Bean public ResourceHttpRequestHandler faviconRequestHandler() &#123; ResourceHttpRequestHandler requestHandler = new ResourceHttpRequestHandler(); requestHandler .setLocations(this.resourceProperties.getFaviconLocations()); return requestHandler; &#125; &#125; ==1）、所有 /webjars/** ，都去 classpath:/META-INF/resources/webjars/ 找资源；== ​ webjars：以jar包的方式引入静态资源； http://www.webjars.org/ localhost:8080/webjars/jquery/3.3.1/jquery.js 123456&lt;!--引入jquery-webjar--&gt;在访问的时候只需要写webjars下面资源的名称即可 &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1&lt;/version&gt; &lt;/dependency&gt; ==2）、”/**” 访问当前项目的任何资源，都去（静态资源的文件夹）找映射== 12345&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径 localhost:8080/abc === 去静态资源文件夹里面找abc ==3）、欢迎页； 静态资源文件夹下的所有index.html页面；被”/**”映射；== ​ localhost:8080/ 找index页面 ==4）、所有的 **/favicon.ico 都是在静态资源文件下找；== 3、模板引擎JSP、Velocity、Freemarker、Thymeleaf SpringBoot推荐的Thymeleaf； 语法更简单，功能更强大； 1、引入thymeleaf；123456789101112 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; 2.1.6 &lt;/dependency&gt;切换thymeleaf版本&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.9.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;!-- thymeleaf2 layout1--&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt; &lt;/properties&gt; 2、Thymeleaf使用1234567891011@ConfigurationProperties(prefix = "spring.thymeleaf")public class ThymeleafProperties &#123; private static final Charset DEFAULT_ENCODING = Charset.forName("UTF-8"); private static final MimeType DEFAULT_CONTENT_TYPE = MimeType.valueOf("text/html"); public static final String DEFAULT_PREFIX = "classpath:/templates/"; public static final String DEFAULT_SUFFIX = ".html"; // 只要我们把HTML页面放在classpath:/templates/，thymeleaf就能自动渲染； 使用： 1、导入thymeleaf的名称空间 1&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt; 2、使用thymeleaf语法； 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;成功！&lt;/h1&gt; &lt;!--th:text 将div里面的文本内容设置为 --&gt; &lt;div th:text="$&#123;hello&#125;"&gt;这是显示欢迎信息&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3、语法规则1）、th:text；改变当前元素里面的文本内容； ​ th：任意html属性；来替换原生属性的值 2）、表达式？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869Simple expressions:（表达式语法） Variable Expressions: $&#123;...&#125;：获取变量值；OGNL； 1）、获取对象的属性、调用方法 2）、使用内置的基本对象： #ctx : the context object. #vars: the context variables. #locale : the context locale. #request : (only in Web Contexts) the HttpServletRequest object. #response : (only in Web Contexts) the HttpServletResponse object. #session : (only in Web Contexts) the HttpSession object. #servletContext : (only in Web Contexts) the ServletContext object. $&#123;session.foo&#125; 3）、内置的一些工具对象：#execInfo : information about the template being processed.#messages : methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #&#123;…&#125; syntax.#uris : methods for escaping parts of URLs/URIs#conversions : methods for executing the configured conversion service (if any).#dates : methods for java.util.Date objects: formatting, component extraction, etc.#calendars : analogous to #dates , but for java.util.Calendar objects.#numbers : methods for formatting numeric objects.#strings : methods for String objects: contains, startsWith, prepending/appending, etc.#objects : methods for objects in general.#bools : methods for boolean evaluation.#arrays : methods for arrays.#lists : methods for lists.#sets : methods for sets.#maps : methods for maps.#aggregates : methods for creating aggregates on arrays or collections.#ids : methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). Selection Variable Expressions: *&#123;...&#125;：选择表达式：和$&#123;&#125;在功能上是一样； 补充：配合 th:object=&quot;$&#123;session.user&#125;： &lt;div th:object=&quot;$&#123;session.user&#125;&quot;&gt; &lt;p&gt;Name: &lt;span th:text=&quot;*&#123;firstName&#125;&quot;&gt;Sebastian&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Surname: &lt;span th:text=&quot;*&#123;lastName&#125;&quot;&gt;Pepper&lt;/span&gt;.&lt;/p&gt; &lt;p&gt;Nationality: &lt;span th:text=&quot;*&#123;nationality&#125;&quot;&gt;Saturn&lt;/span&gt;.&lt;/p&gt; &lt;/div&gt; Message Expressions: #&#123;...&#125;：获取国际化内容 Link URL Expressions: @&#123;...&#125;：定义URL； @&#123;/order/process(execId=$&#123;execId&#125;,execType=&apos;FAST&apos;)&#125; Fragment Expressions: ~&#123;...&#125;：片段引用表达式 &lt;div th:insert=&quot;~&#123;commons :: main&#125;&quot;&gt;...&lt;/div&gt; Literals（字面量） Text literals: &apos;one text&apos; , &apos;Another one!&apos; ,… Number literals: 0 , 34 , 3.0 , 12.3 ,… Boolean literals: true , false Null literal: null Literal tokens: one , sometext , main ,…Text operations:（文本操作） String concatenation: + Literal substitutions: |The name is $&#123;name&#125;|Arithmetic operations:（数学运算） Binary operators: + , - , * , / , % Minus sign (unary operator): -Boolean operations:（布尔运算） Binary operators: and , or Boolean negation (unary operator): ! , notComparisons and equality:（比较运算） Comparators: &gt; , &lt; , &gt;= , &lt;= ( gt , lt , ge , le ) Equality operators: == , != ( eq , ne )Conditional operators:条件运算（三元运算符） If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue)Special tokens: No-Operation: _ 4、SpringMVC自动配置https://docs.spring.io/spring-boot/docs/1.5.10.RELEASE/reference/htmlsingle/#boot-features-developing-web-applications 1. Spring MVC auto-configurationSpring Boot 自动配置好了SpringMVC 以下是SpringBoot对SpringMVC的默认配置:==（WebMvcAutoConfiguration）== Inclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans. 自动配置了ViewResolver（视图解析器：根据方法的返回值得到视图对象（View），视图对象决定如何渲染（转发？重定向？）） ContentNegotiatingViewResolver：组合所有的视图解析器的； ==如何定制：我们可以自己给容器中添加一个视图解析器；自动的将其组合进来；== Support for serving static resources, including support for WebJars (see below).静态资源文件夹路径,webjars Static index.html support. 静态首页访问 Custom Favicon support (see below). favicon.ico ​ 自动注册了 of Converter, GenericConverter, Formatter beans. Converter：转换器； public String hello(User user)：类型转换使用Converter Formatter 格式化器； 2017.12.17===Date； 12345@Bean@ConditionalOnProperty(prefix = "spring.mvc", name = "date-format")//在文件中配置日期格式化的规则public Formatter&lt;Date&gt; dateFormatter() &#123; return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件&#125; ​ ==自己添加的格式化器转换器，我们只需要放在容器中即可== Support for HttpMessageConverters (see below). HttpMessageConverter：SpringMVC用来转换Http请求和响应的；User—Json； HttpMessageConverters 是从容器中确定；获取所有的HttpMessageConverter； ==自己给容器中添加HttpMessageConverter，只需要将自己的组件注册容器中（@Bean,@Component）== ​ Automatic registration of MessageCodesResolver (see below).定义错误代码生成规则 Automatic use of a ConfigurableWebBindingInitializer bean (see below). ==我们可以配置一个ConfigurableWebBindingInitializer来替换默认的；（添加到容器）== 12初始化WebDataBinder；请求数据=====JavaBean； org.springframework.boot.autoconfigure.web：web的所有自动场景； If you want to keep Spring Boot MVC features, and you just want to add additional MVC configuration (interceptors, formatters, view controllers etc.) you can add your own @Configuration class of type WebMvcConfigurerAdapter, but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter or ExceptionHandlerExceptionResolver you can declare a WebMvcRegistrationsAdapter instance providing such components. If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc. 2、扩展SpringMVC1234567&lt;mvc:view-controller path="/hello" view-name="success"/&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/hello"/&gt; &lt;bean&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; ==编写一个配置类（@Configuration），是WebMvcConfigurerAdapter类型；不能标注@EnableWebMvc==; 既保留了所有的自动配置，也能用我们扩展的配置； 1234567891011//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125;&#125; 原理： ​ 1）、WebMvcAutoConfiguration是SpringMVC的自动配置类 ​ 2）、在做其他自动配置时会导入；@Import(EnableWebMvcConfiguration.class) 123456789101112131415161718 @Configurationpublic static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration &#123; private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); //从容器中获取所有的WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) &#123; if (!CollectionUtils.isEmpty(configurers)) &#123; this.configurers.addWebMvcConfigurers(configurers); //一个参考实现；将所有的WebMvcConfigurer相关配置都来一起调用； @Override // public void addViewControllers(ViewControllerRegistry registry) &#123; // for (WebMvcConfigurer delegate : this.delegates) &#123; // delegate.addViewControllers(registry); // &#125; &#125; &#125;&#125; ​ 3）、容器中所有的WebMvcConfigurer都会一起起作用； ​ 4）、我们的配置类也会被调用； ​ 效果：SpringMVC的自动配置和我们的扩展配置都会起作用； 3、全面接管SpringMVC；SpringBoot对SpringMVC的自动配置不需要了，所有都是我们自己配置；所有的SpringMVC的自动配置都失效了 我们需要在配置类中添加@EnableWebMvc即可； 123456789101112//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能@EnableWebMvc@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125;&#125; 原理： 为什么@EnableWebMvc自动配置就失效了； 1）@EnableWebMvc的核心 12@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123; 2）、 12@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; 3）、 12345678910@Configuration@ConditionalOnWebApplication@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurerAdapter.class &#125;)//容器中没有这个组件的时候，这个自动配置类才生效@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; 4）、@EnableWebMvc将WebMvcConfigurationSupport组件导入进来； 5）、导入的WebMvcConfigurationSupport只是SpringMVC最基本的功能； 5、如何修改SpringBoot的默认配置模式： ​ 1）、SpringBoot在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean、@Component）如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（ViewResolver）将用户配置的和自己默认的组合起来； ​ 2）、在SpringBoot中会有非常多的xxxConfigurer帮助我们进行扩展配置 ​ 3）、在SpringBoot中会有很多的xxxCustomizer帮助我们进行定制配置 6、RestfulCRUD1）、默认访问首页1234567891011121314151617181920212223242526//使用WebMvcConfigurerAdapter可以来扩展SpringMVC的功能//@EnableWebMvc 不要接管SpringMVC@Configurationpublic class MyMvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; // super.addViewControllers(registry); //浏览器发送 /atguigu 请求来到 success registry.addViewController("/atguigu").setViewName("success"); &#125; //所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/").setViewName("login"); registry.addViewController("/index.html").setViewName("login"); &#125; &#125;; return adapter; &#125;&#125; 2）、国际化1）、编写国际化配置文件； 2）、使用ResourceBundleMessageSource管理国际化资源文件 3）、在页面使用fmt:message取出国际化内容 步骤： 1）、编写国际化配置文件，抽取页面需要显示的国际化消息 2）、SpringBoot自动配置好了管理国际化资源文件的组件； 12345678910111213141516171819202122232425262728@ConfigurationProperties(prefix = "spring.messages")public class MessageSourceAutoConfiguration &#123; /** * Comma-separated list of basenames (essentially a fully-qualified classpath * location), each following the ResourceBundle convention with relaxed support for * slash based locations. If it doesn't contain a package qualifier (such as * "org.mypackage"), it will be resolved from the classpath root. */ private String basename = "messages"; //我们的配置文件可以直接放在类路径下叫messages.properties； @Bean public MessageSource messageSource() &#123; ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); if (StringUtils.hasText(this.basename)) &#123; //设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils.commaDelimitedListToStringArray( StringUtils.trimAllWhitespace(this.basename))); &#125; if (this.encoding != null) &#123; messageSource.setDefaultEncoding(this.encoding.name()); &#125; messageSource.setFallbackToSystemLocale(this.fallbackToSystemLocale); messageSource.setCacheSeconds(this.cacheSeconds); messageSource.setAlwaysUseMessageFormat(this.alwaysUseMessageFormat); return messageSource; &#125; 3）、去页面获取国际化的值； 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"&gt; &lt;meta name="description" content=""&gt; &lt;meta name="author" content=""&gt; &lt;title&gt;Signin Template for Bootstrap&lt;/title&gt; &lt;!-- Bootstrap core CSS --&gt; &lt;link href="asserts/css/bootstrap.min.css" th:href="@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;" rel="stylesheet"&gt; &lt;!-- Custom styles for this template --&gt; &lt;link href="asserts/css/signin.css" th:href="@&#123;/asserts/css/signin.css&#125;" rel="stylesheet"&gt; &lt;/head&gt; &lt;body class="text-center"&gt; &lt;form class="form-signin" action="dashboard.html"&gt; &lt;img class="mb-4" th:src="@&#123;/asserts/img/bootstrap-solid.svg&#125;" src="asserts/img/bootstrap-solid.svg" alt="" width="72" height="72"&gt; &lt;h1 class="h3 mb-3 font-weight-normal" th:text="#&#123;login.tip&#125;"&gt;Please sign in&lt;/h1&gt; &lt;label class="sr-only" th:text="#&#123;login.username&#125;"&gt;Username&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="Username" th:placeholder="#&#123;login.username&#125;" required="" autofocus=""&gt; &lt;label class="sr-only" th:text="#&#123;login.password&#125;"&gt;Password&lt;/label&gt; &lt;input type="password" class="form-control" placeholder="Password" th:placeholder="#&#123;login.password&#125;" required=""&gt; &lt;div class="checkbox mb-3"&gt; &lt;label&gt; &lt;input type="checkbox" value="remember-me"/&gt; [[#&#123;login.remember&#125;]] &lt;/label&gt; &lt;/div&gt; &lt;button class="btn btn-lg btn-primary btn-block" type="submit" th:text="#&#123;login.btn&#125;"&gt;Sign in&lt;/button&gt; &lt;p class="mt-5 mb-3 text-muted"&gt;© 2017-2018&lt;/p&gt; &lt;a class="btn btn-sm"&gt;中文&lt;/a&gt; &lt;a class="btn btn-sm"&gt;English&lt;/a&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 效果：根据浏览器语言设置的信息切换了国际化； 原理： ​ 国际化Locale（区域信息对象）；LocaleResolver（获取区域信息对象）； 12345678910111213 @Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = "spring.mvc", name = "locale") public LocaleResolver localeResolver() &#123; if (this.mvcProperties .getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123; return new FixedLocaleResolver(this.mvcProperties.getLocale()); &#125; AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver; &#125;默认的就是根据请求头带来的区域信息获取Locale进行国际化 4）、点击链接切换国际化 12345678910111213141516171819202122232425262728/** * 可以在连接上携带区域信息 */public class MyLocaleResolver implements LocaleResolver &#123; @Override public Locale resolveLocale(HttpServletRequest request) &#123; String l = request.getParameter("l"); Locale locale = Locale.getDefault(); if(!StringUtils.isEmpty(l))&#123; String[] split = l.split("_"); locale = new Locale(split[0],split[1]); &#125; return locale; &#125; @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123; &#125;&#125; @Bean public LocaleResolver localeResolver()&#123; return new MyLocaleResolver(); &#125;&#125; 3）、登陆开发期间模板引擎页面修改以后，要实时生效 1）、禁用模板引擎的缓存 12# 禁用缓存spring.thymeleaf.cache=false 2）、页面修改完成以后ctrl+f9：重新编译； 登陆错误消息的显示 1&lt;p style="color: red" th:text="$&#123;msg&#125;" th:if="$&#123;not #strings.isEmpty(msg)&#125;"&gt;&lt;/p&gt; 4）、拦截器进行登陆检查拦截器 12345678910111213141516171819202122232425262728293031/** * 登陆检查， */public class LoginHandlerInterceptor implements HandlerInterceptor &#123; //目标方法执行之前 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; Object user = request.getSession().getAttribute("loginUser"); if(user == null)&#123; //未登陆，返回登陆页面 request.setAttribute("msg","没有权限请先登陆"); request.getRequestDispatcher("/index.html").forward(request,response); return false; &#125;else&#123; //已登陆，放行请求 return true; &#125; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 注册拦截器 1234567891011121314151617181920212223//所有的WebMvcConfigurerAdapter组件都会一起起作用 @Bean //将组件注册在容器 public WebMvcConfigurerAdapter webMvcConfigurerAdapter()&#123; WebMvcConfigurerAdapter adapter = new WebMvcConfigurerAdapter() &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/").setViewName("login"); registry.addViewController("/index.html").setViewName("login"); registry.addViewController("/main.html").setViewName("dashboard"); &#125; //注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) &#123; //super.addInterceptors(registry); //静态资源； *.css , *.js //SpringBoot已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns("/**") .excludePathPatterns("/index.html","/","/user/login"); &#125; &#125;; return adapter; &#125; 5）、CRUD-员工列表实验要求： 1）、RestfulCRUD：CRUD满足Rest风格； URI： /资源名称/资源标识 HTTP请求方式区分对资源CRUD操作 普通CRUD（uri来区分操作） RestfulCRUD 查询 getEmp emp—GET 添加 addEmp?xxx emp—POST 修改 updateEmp?id=xxx&amp;xxx=xx emp/{id}—PUT 删除 deleteEmp?id=1 emp/{id}—DELETE 2）、实验的请求架构; 实验功能 请求URI 请求方式 查询所有员工 emps GET 查询某个员工(来到修改页面) emp/1 GET 来到添加页面 emp GET 添加员工 emp POST 来到修改页面（查出员工进行信息回显） emp/1 GET 修改员工 emp PUT 删除员工 emp/1 DELETE 3）、员工列表： thymeleaf公共页面元素抽取12345678910111213141、抽取公共片段&lt;div th:fragment="copy"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt;2、引入公共片段&lt;div th:insert="~&#123;footer :: copy&#125;"&gt;&lt;/div&gt;~&#123;templatename::selector&#125;：模板名::选择器~&#123;templatename::fragmentname&#125;:模板名::片段名3、默认效果：insert的公共片段在div标签中如果使用th:insert等属性进行引入，可以不用写~&#123;&#125;：行内写法可以加上：[[~&#123;&#125;]];[(~&#123;&#125;)]； 三种引入公共片段的th属性： th:insert：将公共片段整个插入到声明引入的元素中 th:replace：将声明引入的元素替换为公共片段 th:include：将被引入的片段的内容包含进这个标签中 1234567891011121314151617181920212223&lt;footer th:fragment="copy"&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;引入方式&lt;div th:insert="footer :: copy"&gt;&lt;/div&gt;&lt;div th:replace="footer :: copy"&gt;&lt;/div&gt;&lt;div th:include="footer :: copy"&gt;&lt;/div&gt;效果&lt;div&gt; &lt;footer&gt; &amp;copy; 2011 The Good Thymes Virtual Grocery &lt;/footer&gt;&lt;/div&gt;&lt;footer&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/footer&gt;&lt;div&gt;&amp;copy; 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入片段的时候传入参数： 123456789101112131415161718&lt;nav class="col-md-2 d-none d-md-block bg-light sidebar" id="sidebar"&gt; &lt;div class="sidebar-sticky"&gt; &lt;ul class="nav flex-column"&gt; &lt;li class="nav-item"&gt; &lt;a class="nav-link active" th:class="$&#123;activeUri=='main.html'?'nav-link active':'nav-link'&#125;" href="#" th:href="@&#123;/main.html&#125;"&gt; &lt;svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-home"&gt; &lt;path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"&gt;&lt;/path&gt; &lt;polyline points="9 22 9 12 15 12 15 22"&gt;&lt;/polyline&gt; &lt;/svg&gt; Dashboard &lt;span class="sr-only"&gt;(current)&lt;/span&gt; &lt;/a&gt; &lt;/li&gt;&lt;!--引入侧边栏;传入参数--&gt;&lt;div th:replace="commons/bar::#sidebar(activeUri='emps')"&gt;&lt;/div&gt; 6）、CRUD-员工添加添加页面 123456789101112131415161718192021222324252627282930313233343536&lt;form&gt; &lt;div class="form-group"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="zhangsan"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input type="email" class="form-control" placeholder="zhangsan@atguigu.com"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="1"&gt; &lt;label class="form-check-label"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="0"&gt; &lt;label class="form-check-label"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;department&lt;/label&gt; &lt;select class="form-control"&gt; &lt;option&gt;1&lt;/option&gt; &lt;option&gt;2&lt;/option&gt; &lt;option&gt;3&lt;/option&gt; &lt;option&gt;4&lt;/option&gt; &lt;option&gt;5&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input type="text" class="form-control" placeholder="zhangsan"&gt; &lt;/div&gt; &lt;button type="submit" class="btn btn-primary"&gt;添加&lt;/button&gt;&lt;/form&gt; 提交的数据格式不对：生日：日期； 2017-12-12；2017/12/12；2017.12.12； 日期的格式化；SpringMVC将页面提交的值需要转换为指定的类型; 2017-12-12—Date； 类型转换，格式化; 默认日期是按照/的方式； 7）、CRUD-员工修改修改添加二合一表单 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!--需要区分是员工修改还是添加；--&gt;&lt;form th:action="@&#123;/emp&#125;" method="post"&gt; &lt;!--发送put请求修改员工数据--&gt; &lt;!--1、SpringMVC中配置HiddenHttpMethodFilter;（SpringBoot自动配置好的）2、页面创建一个post表单3、创建一个input项，name="_method";值就是我们指定的请求方式--&gt; &lt;input type="hidden" name="_method" value="put" th:if="$&#123;emp!=null&#125;"/&gt; &lt;input type="hidden" name="id" th:if="$&#123;emp!=null&#125;" th:value="$&#123;emp.id&#125;"&gt; &lt;div class="form-group"&gt; &lt;label&gt;LastName&lt;/label&gt; &lt;input name="lastName" type="text" class="form-control" placeholder="zhangsan" th:value="$&#123;emp!=null&#125;?$&#123;emp.lastName&#125;"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Email&lt;/label&gt; &lt;input name="email" type="email" class="form-control" placeholder="zhangsan@atguigu.com" th:value="$&#123;emp!=null&#125;?$&#123;emp.email&#125;"&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Gender&lt;/label&gt;&lt;br/&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="1" th:checked="$&#123;emp!=null&#125;?$&#123;emp.gender==1&#125;"&gt; &lt;label class="form-check-label"&gt;男&lt;/label&gt; &lt;/div&gt; &lt;div class="form-check form-check-inline"&gt; &lt;input class="form-check-input" type="radio" name="gender" value="0" th:checked="$&#123;emp!=null&#125;?$&#123;emp.gender==0&#125;"&gt; &lt;label class="form-check-label"&gt;女&lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;department&lt;/label&gt; &lt;!--提交的是部门的id--&gt; &lt;select class="form-control" name="department.id"&gt; &lt;option th:selected="$&#123;emp!=null&#125;?$&#123;dept.id == emp.department.id&#125;" th:value="$&#123;dept.id&#125;" th:each="dept:$&#123;depts&#125;" th:text="$&#123;dept.departmentName&#125;"&gt;1&lt;/option&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label&gt;Birth&lt;/label&gt; &lt;input name="birth" type="text" class="form-control" placeholder="zhangsan" th:value="$&#123;emp!=null&#125;?$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;"&gt; &lt;/div&gt; &lt;button type="submit" class="btn btn-primary" th:text="$&#123;emp!=null&#125;?'修改':'添加'"&gt;添加&lt;/button&gt;&lt;/form&gt; 8）、CRUD-员工删除123456789101112131415161718192021&lt;tr th:each="emp:$&#123;emps&#125;"&gt; &lt;td th:text="$&#123;emp.id&#125;"&gt;&lt;/td&gt; &lt;td&gt;[[$&#123;emp.lastName&#125;]]&lt;/td&gt; &lt;td th:text="$&#123;emp.email&#125;"&gt;&lt;/td&gt; &lt;td th:text="$&#123;emp.gender&#125;==0?'女':'男'"&gt;&lt;/td&gt; &lt;td th:text="$&#123;emp.department.departmentName&#125;"&gt;&lt;/td&gt; &lt;td th:text="$&#123;#dates.format(emp.birth, 'yyyy-MM-dd HH:mm')&#125;"&gt;&lt;/td&gt; &lt;td&gt; &lt;a class="btn btn-sm btn-primary" th:href="@&#123;/emp/&#125;+$&#123;emp.id&#125;"&gt;编辑&lt;/a&gt; &lt;button th:attr="del_uri=@&#123;/emp/&#125;+$&#123;emp.id&#125;" class="btn btn-sm btn-danger deleteBtn"&gt;删除&lt;/button&gt; &lt;/td&gt;&lt;/tr&gt;&lt;script&gt; $(".deleteBtn").click(function()&#123; //删除当前员工的 $("#deleteEmpForm").attr("action",$(this).attr("del_uri")).submit(); return false; &#125;);&lt;/script&gt; 7、错误处理机制1）、SpringBoot默认的错误处理机制默认效果： ​ 1）、浏览器，返回一个默认的错误页面 浏览器发送请求的请求头： ​ 2）、如果是其他客户端，默认响应一个json数据 ​ 原理： ​ 可以参照ErrorMvcAutoConfiguration；错误处理的自动配置； 给容器中添加了以下组件 ​ 1、DefaultErrorAttributes： 1234567891011帮我们在页面共享信息；@Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;String, Object&gt;(); errorAttributes.put("timestamp", new Date()); addStatus(errorAttributes, requestAttributes); addErrorDetails(errorAttributes, requestAttributes, includeStackTrace); addPath(errorAttributes, requestAttributes); return errorAttributes; &#125; ​ 2、BasicErrorController：处理默认/error请求 12345678910111213141516171819202122232425@Controller@RequestMapping("$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;")public class BasicErrorController extends AbstractErrorController &#123; @RequestMapping(produces = "text/html")//产生html类型的数据；浏览器发送的请求来到这个方法处理 public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; HttpStatus status = getStatus(request); Map&lt;String, Object&gt; model = Collections.unmodifiableMap(getErrorAttributes( request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); //去哪个页面作为错误页面；包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView == null ? new ModelAndView("error", model) : modelAndView); &#125; @RequestMapping @ResponseBody //产生json数据，其他客户端来到这个方法处理； public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); return new ResponseEntity&lt;Map&lt;String, Object&gt;&gt;(body, status); &#125; ​ 3、ErrorPageCustomizer： 12@Value("$&#123;error.path:/error&#125;")private String path = "/error"; 系统出现错误以后来到error请求进行处理；（web.xml注册的错误页面规则） ​ 4、DefaultErrorViewResolver： 123456789101112131415161718192021222324@Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) &#123; ModelAndView modelAndView = resolve(String.valueOf(status), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123; modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); &#125; return modelAndView; &#125; private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认SpringBoot可以去找到一个页面？ error/404 String errorViewName = "error/" + viewName; //模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders .getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); &#125; //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model); &#125; ​ 步骤： ​ 一但系统出现4xx或者5xx之类的错误；ErrorPageCustomizer就会生效（定制错误的响应规则）；就会来到/error请求；就会被BasicErrorController处理； ​ 1）响应页面；去哪个页面是由DefaultErrorViewResolver解析得到的； 1234567891011protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map&lt;String, Object&gt; model) &#123; //所有的ErrorViewResolver得到ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) &#123; ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) &#123; return modelAndView; &#125; &#125; return null;&#125; 2）、如果定制错误响应：1）、如何定制错误的页面；​ 1）、有模板引擎的情况下；error/状态码; 【将错误页面命名为 错误状态码.html 放在模板引擎文件夹里面的 error文件夹下】，发生此状态码的错误就会来到 对应的页面； ​ 我们可以使用4xx和5xx作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确的状态码.html）； ​ 页面能获取的信息； ​ timestamp：时间戳 ​ status：状态码 ​ error：错误提示 ​ exception：异常对象 ​ message：异常消息 ​ errors：JSR303数据校验的错误都在这里 ​ 2）、没有模板引擎（模板引擎找不到这个错误页面），静态资源文件夹下找； ​ 3）、以上都没有错误页面，就是默认来到SpringBoot默认的错误提示页面； 2）、如何定制错误的json数据；​ 1）、自定义异常处理&amp;返回定制json数据； 12345678910111213@ControllerAdvicepublic class MyExceptionHandler &#123; @ResponseBody @ExceptionHandler(UserNotExistException.class) public Map&lt;String,Object&gt; handleException(Exception e)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); map.put("code","user.notexist"); map.put("message",e.getMessage()); return map; &#125;&#125;//没有自适应效果... ​ 2）、转发到/error进行自适应响应效果处理 1234567891011121314@ExceptionHandler(UserNotExistException.class) public String handleException(Exception e, HttpServletRequest request)&#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); //传入我们自己的错误状态码 4xx 5xx，否则就不会进入定制错误页面的解析流程 /** * Integer statusCode = (Integer) request .getAttribute("javax.servlet.error.status_code"); */ request.setAttribute("javax.servlet.error.status_code",500); map.put("code","user.notexist"); map.put("message",e.getMessage()); //转发到/error return "forward:/error"; &#125; 3）、将我们的定制数据携带出去；出现错误以后，会来到/error请求，会被BasicErrorController处理，响应出去可以获取的数据是由getErrorAttributes得到的（是AbstractErrorController（ErrorController）规定的方法）； ​ 1、完全来编写一个ErrorController的实现类【或者是编写AbstractErrorController的子类】，放在容器中； ​ 2、页面上能用的数据，或者是json返回能用的数据都是通过errorAttributes.getErrorAttributes得到； ​ 容器中DefaultErrorAttributes.getErrorAttributes()；默认进行数据处理的； 自定义ErrorAttributes 1234567891011//给容器中加入我们自己定义的ErrorAttributes@Componentpublic class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(RequestAttributes requestAttributes, boolean includeStackTrace) &#123; Map&lt;String, Object&gt; map = super.getErrorAttributes(requestAttributes, includeStackTrace); map.put("company","atguigu"); return map; &#125;&#125; 最终的效果：响应是自适应的，可以通过定制ErrorAttributes改变需要返回的内容， 8、配置嵌入式Servlet容器SpringBoot默认使用Tomcat作为嵌入式的Servlet容器； 问题？ 1）、如何定制和修改Servlet容器的相关配置；1、修改和server有关的配置（ServerProperties【也是EmbeddedServletContainerCustomizer】）； 123456789server.port=8081server.context-path=/crudserver.tomcat.uri-encoding=UTF-8//通用的Servlet容器设置server.xxx//Tomcat的设置server.tomcat.xxx 2、编写一个EmbeddedServletContainerCustomizer：嵌入式的Servlet容器的定制器；来修改Servlet容器的配置 1234567891011@Bean //一定要将这个定制器加入到容器中public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer()&#123; return new EmbeddedServletContainerCustomizer() &#123; //定制嵌入式的Servlet容器相关的规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; container.setPort(8083); &#125; &#125;;&#125; 2）、注册Servlet三大组件【Servlet、Filter、Listener】由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动SpringBoot的web应用，没有web.xml文件。 注册三大组件用以下方式 ServletRegistrationBean 123456//注册三大组件@Beanpublic ServletRegistrationBean myServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),"/myServlet"); return registrationBean;&#125; FilterRegistrationBean 1234567@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList("/hello","/myServlet")); return registrationBean;&#125; ServletListenerRegistrationBean 12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; SpringBoot帮我们自动SpringMVC的时候，自动的注册SpringMVC的前端控制器；DIspatcherServlet； DispatcherServletAutoConfiguration中： 1234567891011121314151617@Bean(name = DEFAULT_DISPATCHER_SERVLET_REGISTRATION_BEAN_NAME)@ConditionalOnBean(value = DispatcherServlet.class, name = DEFAULT_DISPATCHER_SERVLET_BEAN_NAME)public ServletRegistrationBean dispatcherServletRegistration( DispatcherServlet dispatcherServlet) &#123; ServletRegistrationBean registration = new ServletRegistrationBean( dispatcherServlet, this.serverProperties.getServletMapping()); //默认拦截： / 所有请求；包静态资源，但是不拦截jsp请求； /*会拦截jsp //可以通过server.servletPath来修改SpringMVC前端控制器默认拦截的请求路径 registration.setName(DEFAULT_DISPATCHER_SERVLET_BEAN_NAME); registration.setLoadOnStartup( this.webMvcProperties.getServlet().getLoadOnStartup()); if (this.multipartConfig != null) &#123; registration.setMultipartConfig(this.multipartConfig); &#125; return registration;&#125; 2）、SpringBoot能不能支持其他的Servlet容器； 3）、替换为其他嵌入式Servlet容器 默认支持： Tomcat（默认使用） 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; 引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器；&lt;/dependency&gt; Jetty 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; Undertow 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; 4）、嵌入式Servlet容器自动配置原理；EmbeddedServletContainerAutoConfiguration：嵌入式的Servlet容器自动配置？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)@Configuration@ConditionalOnWebApplication@Import(BeanPostProcessorsRegistrar.class)//导入BeanPostProcessorsRegistrar：Spring注解版；给容器中导入一些组件//导入了EmbeddedServletContainerCustomizerBeanPostProcessor：//后置处理器：bean初始化前后（创建完对象，还没赋值赋值）执行初始化工作public class EmbeddedServletContainerAutoConfiguration &#123; @Configuration @ConditionalOnClass(&#123; Servlet.class, Tomcat.class &#125;)//判断当前是否引入了Tomcat依赖； @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT)//判断当前容器没有用户自己定义EmbeddedServletContainerFactory：嵌入式的Servlet容器工厂；作用：创建嵌入式的Servlet容器 public static class EmbeddedTomcat &#123; @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() &#123; return new TomcatEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() &#123; return new JettyEmbeddedServletContainerFactory(); &#125; &#125; /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() &#123; return new UndertowEmbeddedServletContainerFactory(); &#125; &#125; 1）、EmbeddedServletContainerFactory（嵌入式Servlet容器工厂） 1234567public interface EmbeddedServletContainerFactory &#123; //获取嵌入式的Servlet容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers);&#125; 2）、EmbeddedServletContainer：（嵌入式的Servlet容器） 3）、以TomcatEmbeddedServletContainerFactory为例 123456789101112131415161718192021222324@Overridepublic EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) &#123; //创建一个Tomcat Tomcat tomcat = new Tomcat(); //配置Tomcat的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir("tomcat")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) &#123; tomcat.getService().addConnector(additionalConnector); &#125; prepareContext(tomcat.getHost(), initializers); //将配置好的Tomcat传入进去，返回一个EmbeddedServletContainer；并且启动Tomcat服务器 return getTomcatEmbeddedServletContainer(tomcat);&#125; 4）、我们对嵌入式容器的配置修改是怎么生效？ 1ServerProperties、EmbeddedServletContainerCustomizer EmbeddedServletContainerCustomizer：定制器帮我们修改了Servlet容器的配置？ 怎么修改的原理？ 5）、容器中导入了EmbeddedServletContainerCustomizerBeanPostProcessor 12345678910111213141516171819202122232425262728293031323334353637//初始化之前@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; //如果当前初始化的是一个ConfigurableEmbeddedServletContainer类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) &#123; // postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); &#125; return bean;&#125;private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) &#123; //获取所有的定制器，调用每一个定制器的customize方法来给Servlet容器进行属性赋值； for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) &#123; customizer.customize(bean); &#125;&#125;private Collection&lt;EmbeddedServletContainerCustomizer&gt; getCustomizers() &#123; if (this.customizers == null) &#123; // Look up does not include the parent context this.customizers = new ArrayList&lt;EmbeddedServletContainerCustomizer&gt;( this.beanFactory //从容器中获取所有这葛类型的组件：EmbeddedServletContainerCustomizer //定制Servlet容器，给容器中可以添加一个EmbeddedServletContainerCustomizer类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); &#125; return this.customizers;&#125;ServerProperties也是定制器 步骤： 1）、SpringBoot根据导入的依赖情况，给容器中添加相应的EmbeddedServletContainerFactory【TomcatEmbeddedServletContainerFactory】 2）、容器中某个组件要创建对象就会惊动后置处理器；EmbeddedServletContainerCustomizerBeanPostProcessor； 只要是嵌入式的Servlet容器工厂，后置处理器就工作； 3）、后置处理器，从容器中获取所有的EmbeddedServletContainerCustomizer，调用定制器的定制方法 ###5）、嵌入式Servlet容器启动原理； 什么时候创建嵌入式的Servlet容器工厂？什么时候获取嵌入式的Servlet容器并启动Tomcat； 获取嵌入式的Servlet容器工厂： 1）、SpringBoot应用启动运行run方法 2）、refreshContext(context);SpringBoot刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】；如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则：AnnotationConfigApplicationContext 3）、refresh(context);刷新刚才创建好的ioc容器； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125;&#125; 4）、 onRefresh(); web的ioc容器重写了onRefresh方法 5）、webioc容器会创建嵌入式的Servlet容器；createEmbeddedServletContainer(); 6）、获取嵌入式的Servlet容器工厂： EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory(); ​ 从ioc容器中获取EmbeddedServletContainerFactory 组件；TomcatEmbeddedServletContainerFactory创建对象，后置处理器一看是这个对象，就获取所有的定制器来先定制Servlet容器的相关配置； 7）、使用容器工厂获取嵌入式的Servlet容器：this.embeddedServletContainer = containerFactory .getEmbeddedServletContainer(getSelfInitializer()); 8）、嵌入式的Servlet容器创建对象并启动Servlet容器； 先启动嵌入式的Servlet容器，再将ioc容器中剩下没有创建出的对象获取出来； ==IOC容器启动创建嵌入式的Servlet容器== 9、使用外置的Servlet容器嵌入式Servlet容器：应用打成可执行的jar ​ 优点：简单、便携； ​ 缺点：默认不支持JSP、优化定制比较复杂（使用定制器【ServerProperties、自定义EmbeddedServletContainerCustomizer】，自己编写嵌入式Servlet容器的创建工厂【EmbeddedServletContainerFactory】）； 外置的Servlet容器：外面安装Tomcat—应用war包的方式打包； 步骤1）、必须创建一个war项目；（利用idea创建好目录结构） 2）、将嵌入式的Tomcat指定为provided； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 3）、必须编写一个SpringBootServletInitializer的子类，并调用configure方法 123456789public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //传入SpringBoot应用的主程序 return application.sources(SpringBoot04WebJspApplication.class); &#125;&#125; 4）、启动服务器就可以使用； 原理jar包：执行SpringBoot主类的main方法，启动ioc容器，创建嵌入式的Servlet容器； war包：启动服务器，服务器启动SpringBoot应用【SpringBootServletInitializer】，启动ioc容器； servlet3.0（Spring注解版）： 8.2.4 Shared libraries / runtimes pluggability： 规则： ​ 1）、服务器启动（web应用启动）会创建当前web应用里面每一个jar包里面ServletContainerInitializer实例： ​ 2）、ServletContainerInitializer的实现放在jar包的META-INF/services文件夹下，有一个名为javax.servlet.ServletContainerInitializer的文件，内容就是ServletContainerInitializer的实现类的全类名 ​ 3）、还可以使用@HandlesTypes，在应用启动的时候加载我们感兴趣的类； 流程： 1）、启动Tomcat 2）、org\springframework\spring-web\4.3.14.RELEASE\spring-web-4.3.14.RELEASE.jar!\META-INF\services\javax.servlet.ServletContainerInitializer： Spring的web模块里面有这个文件：org.springframework.web.SpringServletContainerInitializer 3）、SpringServletContainerInitializer将@HandlesTypes(WebApplicationInitializer.class)标注的所有这个类型的类都传入到onStartup方法的Set&lt;Class&lt;?&gt;&gt;；为这些WebApplicationInitializer类型的类创建实例； 4）、每一个WebApplicationInitializer都调用自己的onStartup； 5）、相当于我们的SpringBootServletInitializer的类会被创建对象，并执行onStartup方法 6）、SpringBootServletInitializer实例执行onStartup的时候会createRootApplicationContext；创建容器 1234567891011121314151617181920212223242526272829303132333435363738protected WebApplicationContext createRootApplicationContext( ServletContext servletContext) &#123; //1、创建SpringApplicationBuilder SpringApplicationBuilder builder = createSpringApplicationBuilder(); StandardServletEnvironment environment = new StandardServletEnvironment(); environment.initPropertySources(servletContext, null); builder.environment(environment); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) &#123; this.logger.info("Root context already created (using as parent)."); servletContext.setAttribute( WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); &#125; builder.initializers( new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigEmbeddedWebApplicationContext.class); //调用configure方法，子类重写了这个方法，将SpringBoot的主程序类传入了进来 builder = configure(builder); //使用builder创建一个Spring应用 SpringApplication application = builder.build(); if (application.getSources().isEmpty() &amp;&amp; AnnotationUtils .findAnnotation(getClass(), Configuration.class) != null) &#123; application.getSources().add(getClass()); &#125; Assert.state(!application.getSources().isEmpty(), "No SpringApplication sources have been defined. Either override the " + "configure method or add an @Configuration annotation"); // Ensure error pages are registered if (this.registerErrorPageFilter) &#123; application.getSources().add(ErrorPageFilterConfiguration.class); &#125; //启动Spring应用 return run(application);&#125; 7）、Spring的应用就启动并且创建IOC容器 1234567891011121314151617181920212223242526272829303132333435public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); Banner printedBanner = printBanner(environment); context = createApplicationContext(); analyzers = new FailureAnalyzers(context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新IOC容器 refreshContext(context); afterRefresh(context, applicationArguments); listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; ==启动Servlet容器，再启动SpringBoot应用== 五、Docker1、简介Docker是一个开源的应用容器引擎；是一个轻量级容器技术； Docker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像； 运行中的这个镜像称为容器，容器启动是非常快速的。 2、核心概念docker主机(Host)：安装了Docker程序的机器（Docker直接安装在操作系统之上）； docker客户端(Client)：连接docker主机进行操作； docker仓库(Registry)：用来保存各种打包好的软件镜像； docker镜像(SpringBoot入门)：软件打包好的镜像；放在docker仓库中； docker容器(Container)：镜像启动后的实例称为一个容器；容器是独立运行的一个或一组应用 使用Docker的步骤： 1）、安装Docker 2）、去Docker仓库找到这个软件对应的镜像； 3）、使用Docker运行这个镜像，这个镜像就会生成一个Docker容器； 4）、对容器的启动停止就是对软件的启动停止； 3、安装Docker1）、安装linux虚拟机​ 1）、VMWare、VirtualBox（安装）； ​ 2）、导入虚拟机文件centos7-atguigu.ova； ​ 3）、双击启动linux虚拟机;使用 root/ 123456登陆 ​ 4）、使用客户端连接linux服务器进行命令操作； ​ 5）、设置虚拟机网络； ​ 桥接网络===选好网卡====接入网线； ​ 6）、设置好网络以后使用命令重启虚拟机的网络 1service network restart ​ 7）、查看linux的ip地址 1ip addr ​ 8）、使用客户端连接linux； 2）、在linux虚拟机上安装docker步骤： 12345678910111213141、检查内核版本，必须是3.10及以上uname -r2、安装dockeryum install docker3、输入y确认安装4、启动docker[root@localhost ~]# systemctl start docker[root@localhost ~]# docker -vDocker version 1.12.6, build 3e8e77d/1.12.65、开机启动docker[root@localhost ~]# systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.6、停止dockersystemctl stop docker 4、Docker常用命令&amp;操作1）、镜像操作 操作 命令 说明 检索 docker search 关键字 eg：docker search redis 我们经常去docker hub上检索镜像的详细信息，如镜像的TAG。 拉取 docker pull 镜像名:tag :tag是可选的，tag表示标签，多为软件的版本，默认是latest 列表 docker SpringBoot入门 查看所有本地镜像 删除 docker rmi image-id 删除指定的本地镜像 https://hub.docker.com/ 2）、容器操作软件镜像（QQ安装程序）—-运行镜像—-产生一个容器（正在运行的软件，运行的QQ）； 步骤： 1234567891011121314151617181920212223242526272829301、搜索镜像[root@localhost ~]# docker search tomcat2、拉取镜像[root@localhost ~]# docker pull tomcat3、根据镜像启动容器docker run --name mytomcat -d tomcat:latest4、docker ps 查看运行中的容器5、 停止运行中的容器docker stop 容器的id6、查看所有的容器docker ps -a7、启动容器docker start 容器id8、删除一个容器 docker rm 容器id9、启动一个做了端口映射的tomcat[root@localhost ~]# docker run -d -p 8888:8080 tomcat-d：后台运行-p: 将主机的端口映射到容器的一个端口 主机端口:容器内部的端口10、为了演示简单关闭了linux的防火墙service firewalld status ；查看防火墙状态service firewalld stop：关闭防火墙11、查看容器的日志docker logs container-name/container-id更多命令参看https://docs.docker.com/engine/reference/commandline/docker/可以参考每一个镜像的文档 3）、安装MySQL示例1docker pull mysql 错误的启动 1234567891011121314151617[root@localhost ~]# docker run --name mysql01 -d mysql42f09819908bb72dd99ae19e792e0a5d03c48638421fa64cce5f8ba0f40f5846mysql退出了[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES42f09819908b mysql "docker-entrypoint.sh" 34 seconds ago Exited (1) 33 seconds ago mysql01538bde63e500 tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago compassionate_goldstinec4f1ac60b3fc tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago lonely_fermi81ec743a5271 tomcat "catalina.sh run" About an hour ago Exited (143) About an hour ago sick_ramanujan//错误日志[root@localhost ~]# docker logs 42f09819908berror: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD；这个三个参数必须指定一个 正确的启动 12345[root@localhost ~]# docker run --name mysql01 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlb874c56bec49fb43024b3805ab51e9097da779f2f572c22c695305dedd684c5f[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb874c56bec49 mysql "docker-entrypoint.sh" 4 seconds ago Up 3 seconds 3306/tcp mysql01 做了端口映射 12345[root@localhost ~]# docker run -p 3306:3306 --name mysql02 -e MYSQL_ROOT_PASSWORD=123456 -d mysqlad10e4bc5c6a0f61cbad43898de71d366117d120e39db651844c0e73863b9434[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESad10e4bc5c6a mysql "docker-entrypoint.sh" 4 seconds ago Up 2 seconds 0.0.0.0:3306-&gt;3306/tcp mysql02 几个其他的高级操作 123456docker run --name mysql03 -v /conf/mysql:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag把主机的/conf/mysql文件夹挂载到 mysqldocker容器的/etc/mysql/conf.d文件夹里面改mysql的配置文件就只需要把mysql配置文件放在自定义的文件夹下（/conf/mysql）docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci指定mysql的一些配置参数 六、SpringBoot与数据访问1、JDBC123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; 123456spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver 效果： ​ 默认是用org.apache.tomcat.jdbc.pool.DataSource作为数据源； ​ 数据源的相关配置都在DataSourceProperties里面； 自动配置原理： org.springframework.boot.autoconfigure.jdbc： 1、参考DataSourceConfiguration，根据配置创建数据源，默认使用Tomcat连接池；可以使用spring.datasource.type指定自定义的数据源类型； 2、SpringBoot默认可以支持； 1org.apache.tomcat.jdbc.pool.DataSource、HikariDataSource、BasicDataSource、 3、自定义数据源类型 1234567891011121314/** * Generic DataSource configuration. */@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(name = "spring.datasource.type")static class Generic &#123; @Bean public DataSource dataSource(DataSourceProperties properties) &#123; //使用DataSourceBuilder创建数据源，利用反射创建响应type的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); &#125;&#125; 4、DataSourceInitializer：ApplicationListener； ​ 作用： ​ 1）、runSchemaScripts();运行建表语句； ​ 2）、runDataScripts();运行插入数据的sql语句； 默认只需要将文件命名为： 123456schema-*.sql、data-*.sql默认规则：schema.sql，schema-all.sql；可以使用 schema: - classpath:department.sql 指定位置 5、操作数据库：自动配置了JdbcTemplate操作数据库 2、整合Druid数据源12345678910111213141516171819202122232425262728293031323334353637383940414243导入druid数据源@Configurationpublic class DruidConfig &#123; @ConfigurationProperties(prefix = "spring.datasource") @Bean public DataSource druid()&#123; return new DruidDataSource(); &#125; //配置Druid的监控 //1、配置一个管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), "/druid/*"); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put("loginUsername","admin"); initParams.put("loginPassword","123456"); initParams.put("allow","");//默认就是允许所有访问 initParams.put("deny","192.168.15.21"); bean.setInitParameters(initParams); return bean; &#125; //2、配置一个web监控的filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map&lt;String,String&gt; initParams = new HashMap&lt;&gt;(); initParams.put("exclusions","*.js,*.css,/druid/*"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList("/*")); return bean; &#125;&#125; 3、整合MyBatis12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt;&lt;/dependency&gt; 步骤： ​ 1）、配置数据源相关属性（见上一节Druid） ​ 2）、给数据库建表 ​ 3）、创建JavaBean 4）、注解版1234567891011121314151617//指定这是一个操作数据库的mapper@Mapperpublic interface DepartmentMapper &#123; @Select("select * from department where id=#&#123;id&#125;") public Department getDeptById(Integer id); @Delete("delete from department where id=#&#123;id&#125;") public int deleteDeptById(Integer id); @Options(useGeneratedKeys = true,keyProperty = "id") @Insert("insert into department(departmentName) values(#&#123;departmentName&#125;)") public int insertDept(Department department); @Update("update department set departmentName=#&#123;departmentName&#125; where id=#&#123;id&#125;") public int updateDept(Department department);&#125; 问题： 自定义MyBatis的配置规则；给容器中添加一个ConfigurationCustomizer； 1234567891011121314@org.springframework.context.annotation.Configurationpublic class MyBatisConfig &#123; @Bean public ConfigurationCustomizer configurationCustomizer()&#123; return new ConfigurationCustomizer()&#123; @Override public void customize(Configuration configuration) &#123; configuration.setMapUnderscoreToCamelCase(true); &#125; &#125;; &#125;&#125; 123456789使用MapperScan批量扫描所有的Mapper接口；@MapperScan(value = "com.atguigu.springboot.mapper")@SpringBootApplicationpublic class SpringBoot06DataMybatisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBoot06DataMybatisApplication.class, args); &#125;&#125; 5）、配置文件版123mybatis: config-location: classpath:mybatis/mybatis-config.xml 指定全局配置文件的位置 mapper-locations: classpath:mybatis/mapper/*.xml 指定sql映射文件的位置 更多使用参照 http://www.mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/ 4、整合SpringData JPA1）、SpringData简介 2）、整合SpringData JPAJPA:ORM（Object Relational Mapping）； 1）、编写一个实体类（bean）和数据表进行映射，并且配置好映射关系； 12345678910111213//使用JPA注解配置映射关系@Entity //告诉JPA这是一个实体类（和数据表映射的类）@Table(name = "tbl_user") //@Table来指定和哪个数据表对应;如果省略默认表名就是user；public class User &#123; @Id //这是一个主键 @GeneratedValue(strategy = GenerationType.IDENTITY)//自增主键 private Integer id; @Column(name = "last_name",length = 50) //这是和数据表对应的一个列 private String lastName; @Column //省略默认列名就是属性名 private String email; 2）、编写一个Dao接口来操作实体类对应的数据表（Repository） 123//继承JpaRepository来完成对数据库的操作public interface UserRepository extends JpaRepository&lt;User,Integer&gt; &#123;&#125; 3）、基本的配置JpaProperties 1234567spring: jpa: hibernate:# 更新或者创建数据表结构 ddl-auto: update# 控制台显示SQL show-sql: true 七、启动配置原理几个重要的事件回调机制 配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner CommandLineRunner 启动流程： 1、创建SpringApplication对象12345678910111213141516initialize(sources);private void initialize(Object[] sources) &#123; //保存主配置类 if (sources != null &amp;&amp; sources.length &gt; 0) &#123; this.sources.addAll(Arrays.asList(sources)); &#125; //判断当前是否一个web应用 this.webEnvironment = deduceWebEnvironment(); //从类路径下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；然后保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); //从类路径下找到ETA-INF/spring.factories配置的所有ApplicationListener setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); //从多个配置类中找到有main方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass();&#125; 2、运行run方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; configureHeadlessProperty(); //获取SpringApplicationRunListeners；从类路径下META-INF/spring.factories SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); //准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); //创建环境完成后回调SpringApplicationRunListener.environmentPrepared()；表示环境准备完成 Banner printedBanner = printBanner(environment); //创建ApplicationContext；决定创建web的ioc还是普通的ioc context = createApplicationContext(); analyzers = new FailureAnalyzers(context); //准备上下文环境;将environment保存到ioc中；而且applyInitializers()； //applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 //回调所有的SpringApplicationRunListener的contextPrepared()； // prepareContext(context, environment, listeners, applicationArguments, printedBanner); //prepareContext运行完成以后回调所有的SpringApplicationRunListener的contextLoaded（）； //s刷新容器；ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat）；Spring注解版 //扫描，创建，加载所有组件的地方；（配置类，组件，自动配置） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调 //ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); //所有的SpringApplicationRunListener回调finished方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; //整个SpringBoot应用启动完成以后返回启动的ioc容器； return context; &#125; catch (Throwable ex) &#123; handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); &#125;&#125; 3、事件监听机制配置在META-INF/spring.factories ApplicationContextInitializer 123456public class HelloApplicationContextInitializer implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt; &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println("ApplicationContextInitializer...initialize..."+applicationContext); &#125;&#125; SpringApplicationRunListener 123456789101112131415161718192021222324252627282930313233public class HelloSpringApplicationRunListener implements SpringApplicationRunListener &#123; //必须有的构造器 public HelloSpringApplicationRunListener(SpringApplication application, String[] args)&#123; &#125; @Override public void starting() &#123; System.out.println("SpringApplicationRunListener...starting..."); &#125; @Override public void environmentPrepared(ConfigurableEnvironment environment) &#123; Object o = environment.getSystemProperties().get("os.name"); System.out.println("SpringApplicationRunListener...environmentPrepared.."+o); &#125; @Override public void contextPrepared(ConfigurableApplicationContext context) &#123; System.out.println("SpringApplicationRunListener...contextPrepared..."); &#125; @Override public void contextLoaded(ConfigurableApplicationContext context) &#123; System.out.println("SpringApplicationRunListener...contextLoaded..."); &#125; @Override public void finished(ConfigurableApplicationContext context, Throwable exception) &#123; System.out.println("SpringApplicationRunListener...finished..."); &#125;&#125; 配置（META-INF/spring.factories） 12345org.springframework.context.ApplicationContextInitializer=\com.atguigu.springboot.listener.HelloApplicationContextInitializerorg.springframework.boot.SpringApplicationRunListener=\com.atguigu.springboot.listener.HelloSpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner 1234567@Componentpublic class HelloApplicationRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; System.out.println("ApplicationRunner...run...."); &#125;&#125; CommandLineRunner 1234567@Componentpublic class HelloCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println("CommandLineRunner...run..."+ Arrays.asList(args)); &#125;&#125; 八、自定义starterstarter： ​ 1、这个场景需要使用到的依赖是什么？ ​ 2、如何编写自动配置 12345678910111213@Configuration //指定这个类是一个配置类@ConditionalOnXXX //在指定条件成立的情况下自动配置类生效@AutoConfigureAfter //指定自动配置类的顺序@Bean //给容器中添加组件@ConfigurationPropertie结合相关xxxProperties类来绑定相关的配置@EnableConfigurationProperties //让xxxProperties生效加入到容器中自动配置类要能加载将需要启动就加载的自动配置类，配置在META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\ ​ 3、模式： 启动器只用来做依赖导入； 专门来写一个自动配置模块； 启动器依赖自动配置；别人只需要引入启动器（starter） mybatis-spring-boot-starter；自定义启动器名-spring-boot-starter 步骤： 1）、启动器模块 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--启动器--&gt; &lt;dependencies&gt; &lt;!--引入自动配置模块--&gt; &lt;dependency&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2）、自动配置模块 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.atguigu.starter&lt;/groupId&gt; &lt;artifactId&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;atguigu-spring-boot-starter-autoconfigurer&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.10.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--引入spring-boot-starter；所有starter的基本配置--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 1234567891011121314151617181920212223242526package com.atguigu.starter;import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix = "atguigu.hello")public class HelloProperties &#123; private String prefix; private String suffix; public String getPrefix() &#123; return prefix; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public String getSuffix() &#123; return suffix; &#125; public void setSuffix(String suffix) &#123; this.suffix = suffix; &#125;&#125; 123456789101112131415161718package com.atguigu.starter;public class HelloService &#123; HelloProperties helloProperties; public HelloProperties getHelloProperties() &#123; return helloProperties; &#125; public void setHelloProperties(HelloProperties helloProperties) &#123; this.helloProperties = helloProperties; &#125; public String sayHellAtguigu(String name)&#123; return helloProperties.getPrefix()+"-" +name + helloProperties.getSuffix(); &#125;&#125; 12345678910111213141516171819202122package com.atguigu.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration@ConditionalOnWebApplication //web应用才生效@EnableConfigurationProperties(HelloProperties.class)public class HelloServiceAutoConfiguration &#123; @Autowired HelloProperties helloProperties; @Bean public HelloService helloService()&#123; HelloService service = new HelloService(); service.setHelloProperties(helloProperties); return service; &#125;&#125; 更多SpringBoot整合示例https://github.com/spring-projects/spring-boot/tree/master/spring-boot-samples]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Spring框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[苏州Vlog（01）]]></title>
    <url>%2F2019%2F04%2F05%2F%E8%8B%8F%E5%B7%9EVlog%EF%BC%8801%EF%BC%89%2F</url>
    <content type="text"><![CDATA[清明苏州游Vlog（第一弹）游玩景点： 诚品书店 桃花眷村 月光码头 拍摄于月光码头 难得一次节假日，溜出来和同学来苏州游玩一番，大学三年，我差不多宅了三年，在毕业之前，蹭着这次机会出来看看世界，看看祖国的大好河山（强行升华主题） 从学校出发话说过节真的很难打车，我用滴滴等了好久没来车，就直接坐了学校北门的私家车（极不推荐）毕竟不安全，但是赶时间，就上车了，等到了车站，进了候车厅，我服了 这人，太！多！了！我想起来我去年去北京在地铁站等地铁的时候看到的情景 我更坚定了以后节假日要少出来，好好宅起来（真香警告） 我坐车做了一个半小时终于到苏州了，同学从南京出发，比我先到一个小时，后面还堵车缓行，磨磨蹭蹭最后还是落脚苏州，可是除了车站后才发现我们两个的车站离了差不多20分钟车程的距离，原本商量直接去原先定好的民宿，可是司机说那个民宿的地方都快出苏州了，我就凌乱了，果断退掉然后重新定了酒店，其中各种烦心事就懒得说了。到了新酒店，入住放包，休息了一下就出去玩了。 第一站：诚品书店关于诚品书店，我今天也才知道，不知道的请参照下图（手动滑稽） 发现诚品书店里面的书真多，但是吧，没有能够吸引我的，不是我眼光太高，实在是提不起兴趣，这里面的书大多数都是和艺术，设计，美学有关的，像我这种写个 APP 界面都要被吐槽的，逗比细胞反噬艺术细胞的直男，真心无感。。。。。。 但是感觉这个书店真的很不错的，也建议大家来看看，就算没有看上的书，来感受一波也是极好的 第二站：桃花眷村逛完书店后，嘴馋了，就到楼下的 “桃花眷村” 吃了一小顿，点了一个豆花（不是我吃的），点了一个饭团和一份冷豆浆，一不小心就吃的有点饱了 第三站：月光码头第三站我们走到了金鸡湖边的一个广场，拍了点照片，这篇博客首页的图片就是在那拍的，逛了绕着湖边，我们走了半圈就返程了，回到酒店休息了一下，就点了份外卖（毕竟太累就不想出去吃了）然后写了这篇博客。 最后今天的的日志也差不多就是这些了，没什么可以在多描述的了，明天再去玩玩新的地方，再去看看风景，OK 收工，睡觉了，在发一张买的东西]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>旅游</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven的Web工程中获取相对路径无效]]></title>
    <url>%2F2019%2F03%2F26%2FMaven%E7%9A%84Web%E5%B7%A5%E7%A8%8B%E4%B8%AD%E8%8E%B7%E5%8F%96%E7%9B%B8%E5%AF%B9%E8%B7%AF%E5%BE%84%E6%97%A0%E6%95%88%2F</url>
    <content type="text"><![CDATA[Maven的Web工程中${pageContext.request.contextPath}获取相对路径无效 开发环境：Maven 3.6.0 || jdk 1.8 || Spring 4 摄影：Zahrin Lukman，来自Unsplash 解决方案一（亲测有效）将 web.xml 文件中的 标签的版本修改高一些 &lt;web-app version=&quot;3.0&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot;&gt; &lt;/web-app&gt; &lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot; version=&quot;3.1&quot; metadata-complete=&quot;true&quot;&gt; &lt;/web-app&gt; 原 web.xml &lt;web-app&gt;&lt;/web-app&gt; 方案二（亲测无效且有毒）这种方法由于没成功我就不详细介绍了，大概说一下，因为用 maven 创建的 webapp 项目是模板的，这第二种方法直接就是去修改模板了，但是这个模板藏得很深，而且我修改了之后，我的 maven 直接用不了了，导致我直接重装的 maven，重装之后每次在命令行运行 mvn 命令就会报错，目前还无法解决，但还不至于影响我在 IDEA 中开发，说来也怪，在 IDEA 中一点事都没有，但是一旦执行 mvn -V 还是会报错，所以这个方法谨慎使用，最好别用，虽然每次都要改一次 web.xml 文件，但不至于把自己的软件搞坏，如果报错解决了再来更新 找到为什么出错了，不好意思，命令打错了，是 mvn -version 不是 mvn -V 丢脸丢大发了，但是这个方法任然不可用！！！]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>开发问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven项目加载不到Mybatis的xml文件报异常的解决方案]]></title>
    <url>%2F2019%2F03%2F24%2FMaven%E9%A1%B9%E7%9B%AE%E5%8A%A0%E8%BD%BD%E4%B8%8D%E5%88%B0Mybatis%E7%9A%84xml%E6%96%87%E4%BB%B6%E6%8A%A5%E5%BC%82%E5%B8%B8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[Maven项目加载不到Mybatis的xml文件报异常的解决方案 这是第一篇解决开发问题的博客，以后也会按照这种格式来书写，并不断改进（这条仅本条博客存在） 开发环境：Maven 3.6 || jdk 1.8 || Spring 4 （解决方案亲测有效） 摄影：Christian Lambert，来自Unsplash 解决方案一&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; 在 Maven 的 pom.xml 配置文件下添加如上配置代码（用于 Mapper 自动扫描） 原因： Maven编译项目的时候只会把src/main/java下所有的.java和src/main/resources里的文件编译放入target/classes文件夹，所以位于src/main/java下的xml文件就被忽略了。此时只需要在项目的pom文件中加入resources，把src/main/java下所有的.xml也编译放入target/classes然后启动项目就可以了。 作者：暗夜黑光链接：https://www.jianshu.com/p/42725b277611来源：简书 解决方案二在工程中创建 resource 目录，将 ***Mapper.xml 文件放到该目录下，并在 sqlMapConfig.xml 文件中配置 &lt;mappers&gt; &lt;mapper resource=&quot;***Mapper.xml&quot; /&gt; &lt;/mappers&gt; 该方法用于指定 ***Mapper.xml 文件]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>开发问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指Offer（二）]]></title>
    <url>%2F2019%2F03%2F10%2F%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[面试题目录 找出数组中重复的数字 不修改数组找出重复的数字 摄影：Roberto Nickson，来自Unsplash 找出数组中重复的数字(P39)题目 在一个长度为 n 的数组里的所有数字都在 0~n-1 的范围内，数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次，请找出数组中任意一个重复的数字。例如，如果输入长度为7，的数组 {2, 3, 1, 0, 2, 5, 3} ，那么对应的输出是重复的数字2和或者3。 解题思路 从头到位依次扫描这个数字中的每个数字，当扫描到下标为 i 的数字时，首先比较这个数字（用 m 表示）是不是等于 i，如果是，则接着扫描下一个数字；如果不是，则再拿它和第 m 个数字进行比较。如果它和第 m 个数字相等，就找到了一个重复的数字（该数字在下标为 i 和 m 的位置都出现了）；如果它和第 m 个数字不相等，就把第 i 个数字和第 m 个数字交换，把 m 个数字交换，把 m 放到属于它的位置。接下来，再重复比较、交换的过程，知道发现一个重复的数字。 代码 12345678910111213141516171819202122232425262728293031public class Test3_1 &#123; private static boolean duplicate(int[] arr) &#123; if (arr.length &lt;= 0) &#123; return false; &#125; for (int i1 : arr) &#123; if (i1 &lt; 0 || i1 &gt; arr.length - 1) &#123; return false; &#125; &#125; for (int i = 0; i &lt; arr.length; i++) &#123; while (arr[i] != i) &#123; if (arr[i] == arr[arr[i]]) &#123; return true; &#125; int temp = arr[i]; arr[i] = arr[temp]; arr[temp] = temp; &#125; &#125; return false; &#125; public static void main(String[] args) &#123; int[] arr = new int[]&#123;2, 3, 1, 0, 2, 5, 3&#125;; System.out.println(duplicate(arr)); &#125;&#125; 不修改数组找出重复的数字(P41)题目 在一个长度为 n+1 的数组里的所有数字都在 1~n 的范围内，所以数组中至少有一个数字是重复的，请找出数组中任意一个重复的数字，但不能修改输入的数组。例如，如果输入长度为 8 的数组 {2, 3, 5, 4, 3, 2, 6, 7}，那么对应的输出是重复的数字2或者3 解题思路 把从 1~n 的数字从中间的数字m分为两部分，前面一半为 1~m，后面一半为 m+1~n。如果 1~m 的数字的数目超过 m，那么这一班的区间里一定包含重复的数字；否则，另一半 m+1~n 的区间里一定包含重复的数字。 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Test3_2 &#123; private static int getDuplication(int[] arr) &#123; if (arr.length &lt;= 0) &#123; return -1; &#125; int start = 1; int end = arr.length - 1; while (end &gt;= start) &#123; int middle = ((end - start) &gt;&gt; 1) + start; int count = countRange(arr, start, middle); if (end == start) &#123; if (count &gt; 1) &#123; return start; &#125; else &#123; break; &#125; &#125; if (count &gt; (middle - start + 1)) &#123; end = middle; &#125; else &#123; start = middle + 1; &#125; &#125; return -1; &#125; private static int countRange(int[] arr, int start, int end) &#123; if (arr == null) &#123; return 0; &#125; int count = 0; for (int i : arr) &#123; if (i &gt;= start &amp;&amp; i &lt;= end) &#123; count++; &#125; &#125; return count; &#125; public static void main(String[] args) &#123; int[] arr = new int[] &#123;2, 3, 5, 4, 3, 2, 6, 7&#125;; System.out.println(getDuplication(arr)); &#125;&#125; 注：该方法无法找到全部重复数字，总时间复杂度为O(nlogn)，空间复杂度为O(1)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指Offer（一）]]></title>
    <url>%2F2019%2F03%2F09%2F%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[知识点目录 赋值运算符 C++ 中的 struct 和 class 的区别 摄影：Ernest Ojeh，来自Unsplash 赋值运算符(P25)有以下类型CMyString的声明，添加赋值运算符函数 123456789class CMyString &#123; public: CMyString(char* pData = nullptr); CMyString(const CMyString&amp; str); ~CMyString(void); private: char* m_pData;&#125; 考点 是否发返回值的类型声明为该类型的引用，并在函数结束前返回实例自身的引用（*this) 是否把传入的参数声明为常量引用 是否释放实例自身已有的内存 判断传入的参数和当前的实例（*this）是不是同一个实例 经典解法 - 初级程序员 12345678910111213CMyString&amp; CMyString::operator = (const CMyString &amp;str) &#123; if (this == &amp;str) &#123; return *this; &#125; delete []m_pData; m_pData = nullptr; m_pData = new char[strlen(str.m_pData) + 1]; strcpy(m_pData, str.m_pData); return *this;&#125; 考虑异常安全性的解法 - 高级程序员 123456789101112131415CMyString&amp; CMyString::operator = (const CMyString &amp;str) &#123; if (this != &amp;str) &#123; CMyString strTemp(str); // 创建一个临时实例 /** * 以下三行是将临时实例与自身实例进行交换 */ char* pTemp = strTemp.m_pData; strTemp.m_pData = m_pData; m_pData = pTemp; &#125; // 到该作用域外后，临时实例将会调用析构函数，销毁内存 // 因为临时实例交换后就是之前的实例自身，析构后便可以达到销毁原实例内存的目的 return *this;&#125; 源码地址 C++ 中的 struct 和 class 的区别 如果没有标明成员函数或者变量的访问权限级别，在 struct 中默认的是 public，而在class中默认的是private struct 定义的是值类型，值类型的实例在栈上分配内存；而 class 定义的是引用类型，引用类型的实例在堆上分配内存]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>剑指Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程知识点（第三篇）]]></title>
    <url>%2F2019%2F03%2F06%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E7%AC%AC%E4%B8%89%E7%AF%87%EF%BC%89%2F</url>
    <content type="text"><![CDATA[知识点目录 什么是并发容器的实现？ 多线程同步和互斥实现方法 什么是竞争条件 为什么调用 start() 方法时会执行 run() 方法，为什么不直接调用 run() 方法 Java 中怎样唤醒一个阻塞地线程 CycliBarriar 和 CountdownLatch 有什么区别？ 什么是不可变对象，它对写并发应用有什么帮助？ 图片来自第三方 Unsplash 什么是并发容器的实现？何为同步容器：可以简单地理解为通过 synchronized 来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如 Vector、Hashtable、Collections.synchronizedSet、synchronizedList 等方法返回的容器。 可以通过查看 Vector，Hashtable 等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字synchronized。 并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在 ConcurrentHashMap 中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问 map，同时允许一定数量的写操作线程并发地修改 map，所以它可以在并发环境下实现更高的吞吐量。 多线程同步和互斥实现方法线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。 线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。 线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。 用户模式下的方法有：原子操作、临界区。内核模式下的方法有：事件、信号量、互斥量。 什么是竞争条件当多个进程都企图对共享数据进行某种处理，而最后的结果又取决于进程运行的顺序时，则我们认为这发生了竞争条件。 为什么调用 start() 方法时会执行 run() 方法，为什么不直接调用 run() 方法当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。 但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码，只会把run方法当作普通方法去执行。 Java 中怎样唤醒一个阻塞地线程在 Java 发展史上曾经使用 suspend()、resume() 方法对于线程进行阻塞唤醒，但随之出现很多问题，比较典型的还是死锁问题。 解决方案可以使用以对象为目标的阻塞，即利用 Object 类的 wait() 和 notify() 方法实现线程阻塞。 首先，wait、notify 方法是针对对象的，调用任意对象的 wait() 方法都将导致线程阻塞，阻塞的同时也将释放该对象的锁，相应地，调用任意对象的 notify() 方法则将随机解除该对象阻塞的线程，但它需要重新获取改对象的锁，直到获取成功才能往下执行；其次，wait、notify 方法必须在 synchronized 块或方法中被调用，并且要保证同步块或方法的锁对象与调用 wait、notify 方法的对象是同一个，如此一来在调用 wait 之前当前线程就已经成功获取某对象的锁，执行 wait 阻塞后当前线程就将之前获取的对象锁释放。 CycliBarriar 和 CountdownLatch 有什么区别？CyclicBarrier 可以重复使用，而CountdownLatch不能重复使用。 Java 的 concurrent 包里面的 CountDownLatch 其实可以把它看作一个计数器，只不过这个计数器的操作是原子操作，同时只能有一个线程去操作这个计数器，也就是同时只能有一个线程去减这个计数器里面的值。 你可以向 CountDownLatch 对象设置一个初始的数字作为计数值，任何调用这个对象上的 await() 方法都会阻塞，直到这个计数器的计数值被其他的线程减为0为止。 所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await 的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。 CountDownLatch 的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个 CountDownLatch 对象的 await ()方法，其他的任务执行完自己的任务后调用同一个 CountDownLatch 对象上的 countDown() 方法，这个调用 await() 方法的任务将一直阻塞等待，直到这个 CountDownLatch 对象的计数值减到0为止 CyclicBarrier 一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 什么是不可变对象，它对写并发应用有什么帮助？不可变对象即对象一旦被创建它的状态就不能改变，反之即为可变对象。 不可变对象的类即为不可变类。Java 平台类库中包含许多不可变类，如 String、基本类型的包装类、BigInteger 和 BigDecimal 等。 不可变对象天生是线程安全的。它们的常量（域）是在构造函数中创建的。既然它们的状态无法修改，这些常量永远不会变。 不可变对象永远是线程安全的。 只有满足如下状态，一个对象才是不可变的； 它的状态不能在创建后再被修改； 所有域都是 final 类型；并且， 它被正确创建（创建期间没有发生this引用的逸出）。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程知识点（第二篇）]]></title>
    <url>%2F2019%2F03%2F04%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E7%AC%AC%E4%BA%8C%E7%AF%87%EF%BC%89%2F</url>
    <content type="text"><![CDATA[知识点目录 在 Java 中 Executor 和 Executors 的区别 原子操作 Java Concurrency API 中的 Lock 接口是什么？对比同步有什么优势？ Executors 框架 什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者 - 消费者模型？ 什么是 Callable 和 Future ？ 什么是 FutureTask ？ 图片来自第三方 Unsplash 在 Java 中 Executor 和 Executors 的区别 Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求 Executor 接口对象能执行我们的线程任务 ExecutorService 接口继承了 Executor 接口并进行了扩展，提供了更多的方法，能获得任务的执行状态并且可以获取任务的返回值 使用 ThreadPoolExecutor 可以穿件自定义线程池 Future 表示异步计算的结果，他提供了检查计算是否完成的方法，以等待计算的完成，并可以使用get()方法获取计算的结果 原子操作原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。 处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作 在 Java 中可以通过锁和循环 CAS 的方式来实现原子操作。CAS 操作 —— Compare &amp; Set，或是 Compare &amp; Swap，现在几乎所有的CPU指令都支持 CAS 的原子操作 int++ 并不是一个原子操作，所以当一个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误 为了解决这个问题，必须保证增加操作是原子的，在JDK1.5之前我们可以使用同步技术来做到这一点。到JDK1.5之后，java.util.concurrent.automic 包提供了int和long类型的原子包装类，它们可以自动的保证对于它们的操作是原子的并且不需要使用同步 java.util.concurrent 这个包里面提供了一组原子类。其基本方法的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令的时候，不会被其他线程打断，而别的线程就像自旋锁一样，一致等到该方法执行完成，才由 JVM 从等待队列中选择一个线程进入。 Java Concurrency API 中的 Lock 接口是什么？对比同步有什么优势？Lock 接口比同步方法和同步块提供了更具扩展性的锁操作 他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关的条件对象 优势有： 可以使锁更公平 可以使线程在等待锁的时候响应中断 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间 可以在不同的范围，以不同的顺序获取和释放锁 整体上来说，Lock 是 synchronize 的扩展版，Lock提供了无条件的，可轮询的，定时的，可中断的，可多条件队列的锁操作。另外 Lock 的实现类都基本支持非公平锁和公平锁，synchronize 只支持非公平锁，但大部分情况下，非公平锁是高效的选择 Executors 框架Executor 框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架 无限制的创建线程或引起应用程序内存溢出。所以创建一个线程池是个更好的解决方案，因为可以限制线程的数量，并且可以回收再利用这些线程。利用 Executors 开那个价可以非常方便的创建一个线程池 什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者 - 消费者模型？阻塞队列是一个支持两个附加操作的队列。在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。 阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿出元素 JDK7 提供了7个阻塞队列： ArrayBlockingQueue：一个由数组结构组成的游街阻塞队列 LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列 PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列 DelayQueue：一个使用优先级队列实现的无界阻塞队列 SynchronousQueue：一个不存储元素的阻塞队列 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列 Java5 之前实现同步存取时，可以使用普通的一个集合，然后在使用线程的协作和线程同步可以实现生产者，消费者模式，主要技术就是用 wait，notify，notifyAll，synchronized 这些关键字。在 Java5 之后，可以使用阻塞队列来实现，此方式大大减少了代码量，是的多线程编程更加容易，安全方面也有保障。 BlockingQueue 接口是 Queue 的子接口，它的主要用途并不是作为容器，而是作为线程同步的工具，因此他具有一个很明显的特征，当生产者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，正是因为他所具有这个特性，所以在程序中多个线程交替向 BlockingQueue 中放入元素，取出元素，他可以很好的控制线程之间的通信 阻塞队列使用最经典的场景就是 socket 客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程，不断从队列取数据解析 什么是 Callable 和 Future ？Callable 接口类似于 Runnable，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而 Callable 功能更强大一些，被线程执行后，可以返回值，这个返回值可以被 Future 拿到，也就是说 Future 可以拿到异步执行任务的返回值 可以认为是带有回调的 Runnable Future 接口表示异步任务，是还没有完成的任务给出的未来结果。所以所 Callable 用于产生结果，Future 用于获取结果 什么是 FutureTask ？在 Java 并发程序中 FutureTask 表示一个可以取消的异步运算。他有启动和取消运算、查询运算是否完成和取回运算结果等方法 只有当运算完成的时候结果才能取回，如果运算尚未完成 get 方法将会阻塞。一个 FutureTask 对象可以对调用了 Callable 和 Runnable 的对象进行包装，由于 FutureTask 也是调用了 Runnabel 接口，所以它可以提交给 Executor 来执行]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程知识点（第一篇）]]></title>
    <url>%2F2019%2F03%2F03%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E7%AC%AC%E4%B8%80%E7%AF%87%EF%BC%89%2F</url>
    <content type="text"><![CDATA[知识点目录 在java中守护线程和本地线程的区别 线程与进程的区别 多线程的上下文切换 死锁与活锁的区别，死锁与饥饿的区别 Java中用到的线程调度算法 什么是线程组，为什么在Java中不推荐使用 为什么使用Executor框架 图片来自第三方 Unsplash 在java中守护线程和本地线程的区别java中的线程分为两种：守护线程（Daemon）和用户线程（User） 任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(boolean)；true则把该线程设置为守护线程，反之则为用户抛出异常。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常 两者的区别：虚拟机（JVM）何时离开，Daemon是为其他线程提供服务，如果全部的UserThread已经撤离，Daemon没有可服务的线程，JVM撤离。也可以理解为守护线程是JVM自动创建的线程（但不一定），用户线程是程序创建的线程，守护线程就没有工作继续执行，当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动离开 扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程，可能会有：服务守护进程、编译守护进程、windows下的监听Ctrl+break的守护进程、Finalizer守护进程、引用处理守护进程、GC守护进程 线程与进程的区别进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。一个程序至少有一个进程，一个进程至少有一个线程 多线程的上下文切换多线程会共同使用一组计算机的CPU，二线程数大于给程序分配的CPU数是，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换 死锁与活锁的区别，死锁与饥饿的区别死锁：是指两个或两个以上的进程（或线程）在指定过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去 产生死锁的必要条件： 互斥条件：所谓互斥就是进程在某一时间内独占资源 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不剥夺条件：进程已获得资源，在未使用完之前不能强行剥夺 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系 活锁：任务或执行者没有阻塞，由于某些条件没有满足，导致一直重复尝试、失败、尝试、失败 活锁和死锁的区别：处于活锁的实体是在不断的改变状态，所谓的“活”，而处于是死锁的实体表现为等待，活锁可能自己解开，死锁不能 饥饿：一个或多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态 Java中导致饥饿的原因： 高优先级线程吞噬所有低优先级线程的资源 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在他之前持续对该同步块进行访问 线程在等待一个本身也处于永久等待完成的对象（比如调用这个对象的wait方法），因为其他线程总是被持续地获得唤醒 Java中用到的线程调度算法采用时间片轮转的方式，可以设置线程的优先级，会映射到下层的系统上面的优先级上，如非特别需要，尽量不要用，防止线程饥饿 什么是线程组，为什么在Java中不推荐使用ThreadGroup类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构类似于树，有安全隐患，推荐使用线程池 为什么使用Executor框架每次执行任务创建线程 new Thread() 比较消耗性能，创建一个线程是比较耗时的、耗资源的 调用 new Thread() 创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的互相竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源 直接使用 new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[白蛇缘起影评]]></title>
    <url>%2F2019%2F02%2F14%2F%E7%99%BD%E8%9B%87%E7%BC%98%E8%B5%B7%E5%BD%B1%E8%AF%84%2F</url>
    <content type="text"><![CDATA[这篇影评是我再三斟酌后决定发出来，只是为了表达我对于这部国漫单纯的喜爱，它并没有那么不堪（本文没有大篇幅去评价剧情，画面，台词等等，只是想表达一名该电影粉丝的想法） 先来说说看我这篇文章的三种人群，一类是《白蛇：缘起》这部动漫的粉丝，一类是《白蛇：缘起》的喷子，一类是持有保留意见的路人，我并不会去针对某一类人群说一些有失偏颇的话，这样做既没有意义，也违背了我这篇文章的初衷，但我之所以分开这三类人群，旨在希望各位能认真看完文章，它适合所有人 在农历新年之前，有两部电影都被我自己誉为我自己的打脸真香电影，一部是《海王》，另一部就是本文主题《白蛇：缘起》，在电影上映前，我都没抱着多大的期望值，但是观影后心中默认两字“牛逼”，对于看过不少科幻电影的我来说，《海王》是完全超乎我预料之外的好，很大程度归功于它的导演——温子仁，好了，回到我们的话题，相对于动漫，我看的就比较少了，日本动漫就看过《火影忍者》和《名侦探柯南》后者甚至只看过剧场版，而国漫相对多一些，比如《秦时明月》，画江湖系列的《侠岚》《风语咒》《灵主》《不良人》《换世门生》，还有《镇魂街》，有些估计也看过，想不起来了，虽然看过国漫，也挺喜欢，但一直处于喜欢的程度，并没有到达热爱，甚至成为自来水向身边的人疯狂安利，我看了四次《缘起》，每次看我都想不明白为什么我还愿意走进电影院再次观看，一点不觉得腻歪，知道最近我才觉得我找到了答案 在说答案之前，我想说说能让我四次走进电影院的一些原因，对于一场电影，看一遍基本就满足了，二刷就已经是热爱了，刷以上难免会觉得有点过分，甚至会让别人觉得看这么多次难道不觉的腻？我不是一个专业的影评人，没有丰富的词汇去描绘评论整个电影的剧情，但是作为一名观影者，我觉得我还是可以说一说自己的感受。《缘起》全程剧情十分紧凑，对于我来说，一个电影个情节衔接得好不好，可以用在你看电影时，有没有产生右划快进的欲望来恒定，这部电影完全没有，恐怕也正因为这个原因，在几次观影下来我发现了电影中很多地方剧情节奏太快不太符合逻辑。可是，整部电影的逻辑没有问题，四次《何须问》都让我身临其境，四次小白拉许宣魂魄都能触动到我，同样的剧情，能触动我四次的恐怕目前就只有《缘起》了。 但是仅仅只剧情触动的话，那我为我四刷的行为感到不值和奇怪了，接下来，我要说的仅仅代表我个人的观点：在我看来，无论是电影，电视剧，书，或者以任何媒介传播到我大脑里的信息都是可以分类的，但所有类别中有一类，是我认为最最重要的，很多人称之为情怀，我也认，但往往就是情怀能触碰到我内心深处最纯洁，单纯的向往，有同学跟我说过，现在社会变化太快了，有些东西已将变得不一样了，要试图适应，去改变自己。这句话没错，可是，任然有些东西在我心中，我愿意为它留下一方净土，希望在这净土上，能结出我期望的果实，在我没有找到合适的种子，我愿意继续守护它，我有过动摇，有过反思，我不能说这电影带给我什么珍贵的东西，可是剧情中许宣和小白的那种奋不顾身的爱情，的的确确触碰了我心中的这方净土，触及到了我自己对爱情的向往，就算这种爱情不存在，我也愿意相信它。可能会有人说我幼稚，什么都没经历，谈何如此这般，那我反问一句，你何尝没有为自己心中放弃的那一方净土感到后悔，惋惜，悲哀吗？人之初，我们本有着一片纯净的天地，逐渐成长，我们总是在用“无奈”来掩盖自己的妥协，用“放弃”掩盖自己的无能，用“现实”掩盖自己的退缩，这一片天地最终就留下了那一方可怜的土地，能不令人痛心。如果连最后这一点可怜的净土都没了，那我们还能找到自己最初所盼望的东西吗？我不想把“情怀”二字说的如何高大上，但至少，这玩意儿，能在你失落的时候给你一丝安慰，哪怕只有一丝光亮，你也会奋不顾身的往前跑，它不会为你指明任何方向，但是，至少在你行走的过程中，让你保持幸福感。 以上仅仅是我个人的观点，也是自己想了很久总结的话，所以在文章开头说了再三斟酌，并没想针对任何人，我仅仅想表达我为何爱这部电影之深，我也没有要故意抬杠捧高《缘起》的价值观，因为最终它只是一部电影，只是一个商业产物，一千个读者就有一千个哈姆雷特，我仅仅只是那千分之一，所以我尊重任何人的意见，就算是故意甚至恶意诋毁的人，我也愿意接纳，至少你们也是那“一千”中的一个。 全篇文章不长，恐怕还有些许矫情，看电影是我这个程序员业余最大的爱好之一了，我会愿意为自己喜欢的电影打call，好的电影我也会认认真真欣赏，如果有必要，我仍然会写成博客与诸位分享。]]></content>
      <categories>
        <category>观剧后感</category>
      </categories>
      <tags>
        <tag>电影</tag>
      </tags>
  </entry>
</search>
